{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([5,2])\n",
    "y = torch.Tensor([1,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5., 10.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7606, 0.0788, 0.3944, 0.0967, 0.8403, 0.1354, 0.4073, 0.2112, 0.4005,\n",
       "         0.0529]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand([2,5]).view([1,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: Deep Learning 2\n",
    "https://www.youtube.com/watch?v=i2yPxY2rOzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(is_train: bool=True):\n",
    "    return datasets.MNIST(\"\", train=is_train, download=True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "    \n",
    "def get_data_loader(dataset, **kwargs):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=kwargs[\"batch_size\"], shuffle=kwargs[\"shuffle\"])\n",
    "\n",
    "    \n",
    "train = get_data(True)\n",
    "test = get_data(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_params = dict(batch_size=16, shuffle=True)\n",
    "\n",
    "trainset = get_data_loader(train, **data_loader_params)\n",
    "testset = get_data_loader(test, **data_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data[0][0], data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(data: Tensor):\n",
    "    plt.imshow(data[0][0].view([28,28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=48, bias=True)\n",
      "  (fc3): Linear(in_features=48, out_features=24, bias=True)\n",
      "  (fc4): Linear(in_features=24, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 48)\n",
    "        self.fc3 = nn.Linear(48, 24)\n",
    "        self.fc4 = nn.Linear(24, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0254, -0.0157,  0.0196,  ...,  0.0343, -0.0259,  0.0015],\n",
      "        [-0.0114, -0.0187, -0.0106,  ...,  0.0168, -0.0011, -0.0011],\n",
      "        [-0.0056, -0.0209, -0.0124,  ..., -0.0340, -0.0340,  0.0075],\n",
      "        ...,\n",
      "        [-0.0187,  0.0256, -0.0280,  ...,  0.0095, -0.0257, -0.0342],\n",
      "        [ 0.0301, -0.0007, -0.0003,  ..., -0.0081, -0.0070,  0.0014],\n",
      "        [-0.0124, -0.0339, -0.0261,  ..., -0.0187, -0.0100, -0.0338]],\n",
      "       requires_grad=True),\n",
      " Parameter containing:\n",
      "tensor([ 2.7688e-02,  5.3619e-03,  3.3348e-02,  1.5431e-03, -2.5041e-02,\n",
      "         1.5713e-02,  1.2356e-02,  1.9706e-02, -9.3098e-03, -9.4962e-03,\n",
      "        -2.8502e-02,  7.5788e-03,  1.0501e-02,  1.8855e-02, -2.9711e-02,\n",
      "         3.0150e-02,  9.7010e-03,  1.6860e-03,  2.5122e-02,  1.9529e-02,\n",
      "         4.5132e-04,  2.1641e-02, -2.2963e-02,  3.0670e-02,  3.1724e-02,\n",
      "        -2.7925e-02, -2.8065e-02,  1.0258e-02, -1.8373e-02,  2.5526e-02,\n",
      "         2.0439e-02, -6.8608e-03,  1.4730e-02, -3.0746e-02,  1.8660e-02,\n",
      "         4.8690e-03,  6.0167e-03,  2.0865e-02, -3.2839e-02, -2.8867e-05,\n",
      "        -1.2176e-02,  2.0212e-02,  3.2448e-02,  2.5861e-03,  1.8243e-02,\n",
      "         7.0473e-03, -2.9619e-02, -3.0435e-02, -1.2961e-02,  1.9758e-02,\n",
      "        -3.2546e-02,  2.3517e-02,  1.3615e-02, -7.5423e-03,  2.3190e-02,\n",
      "        -1.8607e-02, -2.1682e-02, -2.4814e-02,  5.2821e-03,  1.9588e-02,\n",
      "        -2.3997e-02,  2.7950e-02,  6.1397e-03,  7.8501e-03],\n",
      "       requires_grad=True),\n",
      " Parameter containing:\n",
      "tensor([[-2.5243e-02,  7.2841e-02,  7.4442e-02,  ..., -9.0694e-02,\n",
      "         -1.0633e-01,  1.2441e-01],\n",
      "        [ 4.9741e-02,  1.1106e-01, -5.5685e-02,  ..., -1.7810e-02,\n",
      "          2.4691e-02,  1.0741e-01],\n",
      "        [-2.4033e-02,  1.1709e-01, -5.2303e-05,  ..., -1.2494e-01,\n",
      "          8.6917e-02, -8.2884e-02],\n",
      "        ...,\n",
      "        [-7.1105e-02, -1.0099e-01,  1.4296e-02,  ...,  4.3342e-02,\n",
      "         -4.1593e-02,  2.5740e-02],\n",
      "        [-8.8006e-02,  9.7121e-03,  5.9595e-02,  ...,  3.1252e-02,\n",
      "         -1.1796e-01, -2.0771e-02],\n",
      "        [ 6.6813e-02,  9.4906e-02, -3.1729e-02,  ...,  5.3980e-02,\n",
      "         -7.0086e-02, -1.0416e-01]], requires_grad=True),\n",
      " Parameter containing:\n",
      "tensor([-0.0977,  0.0984, -0.0387, -0.0593,  0.0689,  0.1114, -0.0044, -0.0966,\n",
      "        -0.0275, -0.0821,  0.0950, -0.0531,  0.1155,  0.0611, -0.0402,  0.0101,\n",
      "        -0.0867,  0.0763,  0.0743,  0.1201,  0.1114, -0.0794,  0.1171,  0.0306,\n",
      "         0.1101,  0.0737,  0.0265,  0.0476,  0.0728, -0.0999, -0.0374,  0.1170,\n",
      "        -0.0898,  0.0108,  0.0850, -0.1018,  0.1127,  0.0101, -0.0580,  0.0319,\n",
      "        -0.0755, -0.0219, -0.0312,  0.0359, -0.1062,  0.1102,  0.0872,  0.1045],\n",
      "       requires_grad=True),\n",
      " Parameter containing:\n",
      "tensor([[-0.0308,  0.0019, -0.0054,  ..., -0.0727,  0.0440, -0.0505],\n",
      "        [ 0.1152,  0.0429, -0.0979,  ..., -0.0833, -0.0917, -0.1258],\n",
      "        [-0.0981,  0.1303, -0.0087,  ..., -0.1128, -0.0921,  0.1246],\n",
      "        ...,\n",
      "        [-0.0605, -0.0402, -0.0776,  ..., -0.0514,  0.1050, -0.0371],\n",
      "        [ 0.0294,  0.0871,  0.0268,  ...,  0.0805,  0.1090,  0.1110],\n",
      "        [-0.0742, -0.0671,  0.0264,  ..., -0.0586,  0.0675,  0.1432]],\n",
      "       requires_grad=True),\n",
      " Parameter containing:\n",
      "tensor([ 0.0043,  0.1035,  0.1182, -0.1293, -0.1224,  0.1323,  0.1370, -0.1299,\n",
      "         0.1316,  0.1329,  0.0048,  0.0012, -0.1163, -0.1293,  0.1018, -0.0812,\n",
      "        -0.1213,  0.0105, -0.1207,  0.0986,  0.0665,  0.0257, -0.0719, -0.1067],\n",
      "       requires_grad=True),\n",
      " Parameter containing:\n",
      "tensor([[-0.0264,  0.0637, -0.0316,  0.1675,  0.1554,  0.1947, -0.1428, -0.1174,\n",
      "         -0.0043,  0.0779, -0.0590,  0.0286, -0.0587,  0.1593,  0.1964,  0.1486,\n",
      "          0.1974, -0.1783,  0.0404,  0.1881,  0.1283, -0.0691, -0.0600,  0.1638],\n",
      "        [-0.1497, -0.0683,  0.1052, -0.0244,  0.0030,  0.0797,  0.0538, -0.1434,\n",
      "          0.1568,  0.1333, -0.0437, -0.0696, -0.0899, -0.0196,  0.1605,  0.0323,\n",
      "         -0.1958, -0.0862,  0.0986,  0.0248,  0.0709, -0.1545,  0.0610,  0.0459],\n",
      "        [ 0.1215,  0.1871, -0.0558, -0.1602, -0.1454, -0.0360,  0.1248, -0.0201,\n",
      "          0.1657,  0.0233, -0.1412,  0.0291, -0.0281,  0.0297, -0.1076,  0.0704,\n",
      "         -0.1874,  0.1119, -0.1753, -0.1910, -0.0116, -0.1795,  0.0183, -0.0688],\n",
      "        [ 0.1532,  0.1795,  0.1676, -0.2015,  0.1392, -0.1587,  0.0079,  0.1089,\n",
      "         -0.0933,  0.0401, -0.1948, -0.1637, -0.1679,  0.1018,  0.1776,  0.0702,\n",
      "          0.0781, -0.0328, -0.2038, -0.1690, -0.1983,  0.0126, -0.1206,  0.0154],\n",
      "        [-0.1940, -0.0338, -0.0864, -0.1549, -0.0274, -0.0081, -0.1626, -0.1929,\n",
      "         -0.0231, -0.0572,  0.1778,  0.0906,  0.1090,  0.0829,  0.1669, -0.0672,\n",
      "         -0.1026, -0.0819, -0.1338, -0.0231,  0.0441,  0.1706,  0.0689, -0.0264],\n",
      "        [ 0.0058,  0.0062,  0.1949,  0.1348, -0.0324, -0.0767,  0.0171, -0.2027,\n",
      "         -0.1873,  0.1821,  0.0178,  0.0381, -0.1993, -0.1210,  0.0073, -0.0865,\n",
      "         -0.0355, -0.0473,  0.1731, -0.0733,  0.0706,  0.1028, -0.0329,  0.1375],\n",
      "        [ 0.1997, -0.0372, -0.0036,  0.1075, -0.0424, -0.0029,  0.1748,  0.0044,\n",
      "          0.0081, -0.0923, -0.0985,  0.1550, -0.1607,  0.0136,  0.1386, -0.1772,\n",
      "          0.1610, -0.1659,  0.1157, -0.1751,  0.0928, -0.0733,  0.0747, -0.1679],\n",
      "        [-0.0449, -0.0283, -0.0417,  0.0409,  0.0183, -0.2035,  0.1215,  0.1943,\n",
      "          0.0790,  0.0071,  0.1216, -0.1043, -0.0067, -0.1178,  0.0878,  0.0546,\n",
      "          0.0642, -0.2026, -0.1337,  0.1603, -0.1267,  0.0533, -0.0340,  0.1540],\n",
      "        [-0.0769, -0.1982,  0.1106, -0.0170, -0.1104,  0.0657, -0.1477,  0.0990,\n",
      "          0.1033, -0.0539,  0.0298,  0.0186,  0.0728, -0.0983, -0.1245, -0.1628,\n",
      "          0.0587,  0.1236,  0.1658, -0.1868, -0.0880, -0.0402,  0.0872,  0.0758],\n",
      "        [ 0.1720,  0.1012, -0.1815,  0.1678, -0.0272, -0.1149, -0.0215, -0.0047,\n",
      "          0.1963,  0.1829, -0.1355, -0.0258,  0.0084, -0.1575, -0.1029,  0.1845,\n",
      "          0.1080, -0.1128,  0.1383,  0.0922, -0.0461,  0.0954, -0.2003,  0.1386]],\n",
      "       requires_grad=True),\n",
      " Parameter containing:\n",
      "tensor([ 0.0208,  0.1119, -0.1239,  0.0601, -0.0566,  0.1654,  0.1088,  0.0718,\n",
      "         0.1902, -0.1486], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "pprint(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax\n",
    "* softmax placed at output layer of nn\n",
    "* one-of-K class problems\n",
    "* compute for the normalized exponential function of all units in the layer\n",
    "* softmax squashes vector of size K, between 1 and 0\n",
    "* because of normalization, the sum of whole vector is 1\n",
    "\n",
    "Negative Log-Likelihood (NLL or nll_loss)\n",
    "* nll is unhappy at smaller values\n",
    "* because we sum the loss function to all correct classes, is when network assigns high confidence to correct class, unhappiness is low, vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2183, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0181, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0938, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0238, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    for x, y in trainset:\n",
    "        net.zero_grad()\n",
    "        output = net(x.view(-1,28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When trying to evaluate how good network is/data is... don't calculate gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.99\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in trainset:\n",
    "        output = net(x.view(-1,784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(f\"Acc: {round(correct/total, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20630846630>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[0].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(x[0].view(-1,784))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('venv': venv)",
   "language": "python",
   "name": "python36864bitvenvvenvde732d14108942bbb31ce0e20fd51544"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
