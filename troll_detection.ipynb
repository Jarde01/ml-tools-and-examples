{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "troll-detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jarde01/ml-tools-and-examples/blob/master/troll_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZemLitfjmYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd5af67f-555e-4204-e879-f739d473361e"
      },
      "source": [
        "pip install wandb pytorch-transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/f2/050281be017eb6a9b95354c988d3e9fa1ef7264a99afcd03572e67fb996c/wandb-0.8.6-py2.py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 3.4MB/s \n",
            "\u001b[?25hCollecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/b5/2d78e74001af0152ee61d5ad4e290aec9a1e43925b21df2dc74ec100f1ab/pytorch_transformers-1.0.0-py3-none-any.whl (137kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 51.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Collecting gql>=0.1.0 (from wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/9c/2933b7791210e00f5c26a6243198cc03af9132c29cf85e4c22cb007f171e/gql-0.1.0.tar.gz\n",
            "Collecting python-dateutil>=2.6.1 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n",
            "Collecting sentry-sdk>=0.4.0 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/38/7f691570ed9e85479dbe4e0959ae223d364693708ba6d293d850b657f1a0/sentry_sdk-0.10.2-py2.py3-none-any.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 33.0MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 32.9MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0 (from wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/80/d7/2bfc9332e68d3e15ea97b9b1588b3899ad565120253d3fd71c8f7f13b4fe/shortuuid-0.5.0.tar.gz\n",
            "Collecting watchdog>=0.8.3 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/e3/5a55d48a29300160779f0a0d2776d17c1b762a2039b36de528b093b87d5b/watchdog-0.9.0.tar.gz (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 28.8MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d3/aecfe42163233de6071248ea7565e97ba1c51e345a9e1dcc128dd1e46c1e/GitPython-2.1.13-py2.py3-none-any.whl (452kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 50.1MB/s \n",
            "\u001b[?25hCollecting regex (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.9.199)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.16.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Collecting sentencepiece (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/95/7f357995d5eb1131aa2092096dca14a6fc1b1d2860bd99c22a612e1d1019/sentencepiece-0.1.82-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.1.0)\n",
            "Collecting graphql-core>=0.5.0 (from gql>=0.1.0->wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/11/bc4a7eb440124271289d93e4d208bd07d94196038fabbe2a52435a07d3d3/graphql_core-2.2.1-py2.py3-none-any.whl (250kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 61.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from gql>=0.1.0->wandb) (2.2.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2019.6.16)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (3.13)\n",
            "Collecting argh>=0.24.1 (from watchdog>=0.8.3->wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/06/1c/e667a7126f0b84aaa1c56844337bf0ac12445d1beb9c8a6199a7314944bf/argh-0.26.2-py2.py3-none-any.whl\n",
            "Collecting pathtools>=0.1.1 (from watchdog>=0.8.3->wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting gitdb2>=2.0.0 (from GitPython>=1.0.0->wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/30/a407568aa8d8f25db817cf50121a958722f3fc5f87e3a6fba1f40c0633e3/gitdb2-2.0.5-py2.py3-none-any.whl (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 32.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.199 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.12.199)\n",
            "Collecting rx<3,>=1.6 (from graphql-core>=0.5.0->gql>=0.1.0->wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/0f/5ef4ac78e2a538cc1b054eb86285fe0bf7a5dbaeaac2c584757c300515e2/Rx-1.6.1-py2.py3-none-any.whl (179kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 57.3MB/s \n",
            "\u001b[?25hCollecting smmap2>=2.0.0 (from gitdb2>=2.0.0->GitPython>=1.0.0->wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.199->boto3->pytorch-transformers) (0.14)\n",
            "Building wheels for collected packages: gql, subprocess32, shortuuid, watchdog, regex, pathtools\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.1.0-cp36-none-any.whl size=5540 sha256=b6f95219951b87021461f9e4c9ed1ab8e67609d8fc100e86f6aa91107db290e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/8d/65/a3247f500d675d80a01e4d2f0ee44fe99f1faef575bc2a1664\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6488 sha256=bd0058494b37eb0d45060160bf99a92b3db9837a26e8618f1bc83226b7b24683\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for shortuuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shortuuid: filename=shortuuid-0.5.0-cp36-none-any.whl size=5499 sha256=8f66e097729d00f2251e95881e2c4c74b52de34385bb099774128ce5cddfafee\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/eb/fd/69e5177f67b505e44acbd1aedfbe44b91768ee0c4cd5636576\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.9.0-cp36-none-any.whl size=73652 sha256=bbe76b6f589d5025a1f163befc71c56c4c095f06f9b09f0b54be2e5c8328691b\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/1d/d0/04cfe495619be2095eb8d89a31c42adb4e42b76495bc8f784c\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.6.8-cp36-cp36m-linux_x86_64.whl size=604158 sha256=990c8a6f077b9b62cb24090675943ddf537515ba323bd7a92fb186d02bcc4cfb\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=377c4b49069e3d06ec1ab601450b73660d5abf02b21a478f9aee93b21af20821\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built gql subprocess32 shortuuid watchdog regex pathtools\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: rx, graphql-core, gql, python-dateutil, sentry-sdk, subprocess32, shortuuid, argh, pathtools, watchdog, docker-pycreds, smmap2, gitdb2, GitPython, wandb, regex, sentencepiece, pytorch-transformers\n",
            "  Found existing installation: python-dateutil 2.5.3\n",
            "    Uninstalling python-dateutil-2.5.3:\n",
            "      Successfully uninstalled python-dateutil-2.5.3\n",
            "Successfully installed GitPython-2.1.13 argh-0.26.2 docker-pycreds-0.4.0 gitdb2-2.0.5 gql-0.1.0 graphql-core-2.2.1 pathtools-0.1.2 python-dateutil-2.8.0 pytorch-transformers-1.0.0 regex-2019.6.8 rx-1.6.1 sentencepiece-0.1.82 sentry-sdk-0.10.2 shortuuid-0.5.0 smmap2-2.0.5 subprocess32-3.5.4 wandb-0.8.6 watchdog-0.9.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxAddgXqjdj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkR1MT6KjhlO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "08bde8d6-913a-4a0b-b275-d4f4cecd1cc5"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Lambda, Dense, Dropout, Activation, Embedding, GlobalMaxPooling1D\n",
        "from keras.optimizers import SGD\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.text import *\n",
        "from keras.preprocessing import *\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, MultiLabelBinarizer, LabelEncoder"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po36nSWpjEK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "e65a59ef-919d-46f1-9481-e4138f3ce53c"
      },
      "source": [
        "!wandb login 2295caae2022fe6a431a755f74d1e9e8605848eb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "wandb.init(project=\"troll-detection\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection/runs/4iosw9h1\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "W&B Run: https://app.wandb.ai/jeremy/troll-detection/runs/4iosw9h1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TezD9MYr84Nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from pytorch_transformers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp62YP8_87Wr",
        "colab_type": "code",
        "outputId": "7f2a4714-d6ac-4269-c8f6-72bbbb23b40a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 2621849.12B/s]\n",
            "100%|██████████| 313/313 [00:00<00:00, 104390.68B/s]\n",
            "100%|██████████| 440473133/440473133 [00:06<00:00, 69042634.16B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or3KLPfv_JFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e51dabe3-c023-4fad-89f5-816a88d74f0a"
      },
      "source": [
        "input_ids = torch.tensor([bert_tokenizer.encode(\"some words here ./ and some punctuation..\")])\n",
        "# last_hidden_states = bert_model(input_ids)[0]  # Models outputs are now tuples\n",
        "last_hidden_states = bert_model(input_ids)[0]  # Models outputs are now tuples\n",
        "vectors = last_hidden_states.detach().numpy()[0]\n",
        "vectors.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDx8Kcpo0Tm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sentence(sentence:str, length:int=15, fill:str='word'):\n",
        "  tokens = sentence.split()\n",
        "  num_tokens = len(tokens)\n",
        "  \n",
        "  if num_tokens < length:\n",
        "    for i in range(0, length-num_tokens):\n",
        "      tokens.append(fill)\n",
        "  else:\n",
        "    tokens = tokens[:length]\n",
        "#   assert(len(sentence)) == length\n",
        "  \n",
        "  return \" \".join(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-pC15XmoSjP",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlEIBhJmoS5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "feea2f33-9546-4841-d1a7-bb1e435e1e29"
      },
      "source": [
        "df = pd.read_json(\"/content/Dataset for Detection of Cyber-Trolls.json\", lines=True)\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotation</th>\n",
              "      <th>content</th>\n",
              "      <th>extras</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'notes': '', 'label': ['1']}</td>\n",
              "      <td>Get fucking real dude.</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'notes': '', 'label': ['1']}</td>\n",
              "      <td>She is as dirty as they come  and that crook ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'notes': '', 'label': ['1']}</td>\n",
              "      <td>why did you fuck it up. I could do it all day...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'notes': '', 'label': ['1']}</td>\n",
              "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'notes': '', 'label': ['1']}</td>\n",
              "      <td>WTF are you talking about Men? No men thats n...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      annotation  ... extras\n",
              "0  {'notes': '', 'label': ['1']}  ...    NaN\n",
              "1  {'notes': '', 'label': ['1']}  ...    NaN\n",
              "2  {'notes': '', 'label': ['1']}  ...    NaN\n",
              "3  {'notes': '', 'label': ['1']}  ...    NaN\n",
              "4  {'notes': '', 'label': ['1']}  ...    NaN\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZVa5wvjsiyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = df['annotation']\n",
        "labels = labels.apply(lambda x: x['label'][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlSxx_OhQidc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# labels_processed = labels.tolist()\n",
        "# le = LabelEncoder()\n",
        "# labels_processed = le.fit_transform(labels_processed)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "labels_processed = to_categorical(labels.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9-toz8ZMpdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "inputs = df['content'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dI12fq7i1FV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bert_layer(x):\n",
        "  input_ids = torch.tensor([bert_tokenizer.encode(x)])\n",
        "  last_hidden_states = bert_model(input_ids)[0]\n",
        "  final = last_hidden_states.detach().numpy()\n",
        "  return final\n",
        "\n",
        "# processed = fixed_sent.apply(lambda x: bert_layer(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3raYRcx8IMA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import *\n",
        "\n",
        "tok = text.Tokenizer()\n",
        "tok.fit_on_texts(inputs)\n",
        "\n",
        "sequences = tok.texts_to_sequences(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtmXspFMNC2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_inputs = sequence.pad_sequences(sequences, maxlen=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbwyxtVWNQdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b2d2d5d9-4004-418e-f0c2-af7c6507aead"
      },
      "source": [
        "padded_inputs.shape"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20001, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCJQR8K_OmfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "4790c945-e53a-4e65-f99c-c434c2db70ae"
      },
      "source": [
        "num_words = len(tok.word_counts)\n",
        "\n",
        "print(padded_inputs[:5])\n",
        "print(labels_processed[:5])"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0   37   38  293  151]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0  105   10\n",
            "    62  818   62   48  188    7    6 4897 4898    3 4899   31   30   38\n",
            "  3333   61    4  787  108 3904  175   27]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0   80   92    2   25    8   45    1  121\n",
            "    20    8   41  127   54  622   20    8   50    2   22   91  551 2111\n",
            "    17  584    5 4900  861    4  450  109]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0  151   48  113 1258 4901    3   38 1939    1    9  424 3905 1078\n",
            "   438    3 4902  941    8  230   40  691]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0  360   31    2  365   52  819   40\n",
            "   819  163   33    4 4903   99   32   66]]\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7NCwVbWPw3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(padded_inputs, labels_processed, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF_a_qfKZAuX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "245878f6-7dce-4bdd-a215-f35a6ebcee11"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16000, 50)\n",
            "(4001, 50)\n",
            "(16000, 2)\n",
            "(4001, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t7kas0l_x9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def get_model(num_words, embed_out=128, dense_1_nodes=32, dropout_1=0.5):\n",
        "\n",
        "# keras.layers.InputLayer(..., ragged=True)\n",
        "  \n",
        "#   inputs = Input(ragged=true) \n",
        "# #   inputs = Lambda(lambda x: bert_layer(x), output_shape=(768,))\n",
        "#   x = Lambda(lambda x: bert_layer(x), output_shape=(768,))(inputs)\n",
        "\n",
        "# #   inputs = Lambda(lambda x: bert_layer(x), input_shape=(30,), dtype=tf.string)\n",
        "\n",
        "#   x = Dense(64, activation='relu')(inputs)\n",
        "#   outputs = Dense(2, activation='softmax')(x)  \n",
        "  #   model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  \n",
        "  # This is the sequential model version\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(num_words, embed_out))\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dense(dense_1_nodes, activation='relu', name='dense_1'))\n",
        "  model.add(Dropout(dropout_1))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "  return model            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJfDXQkkWw8C",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mBx3zFGPLFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw5qiJJQ5Rg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def run_trials_single():\n",
        "  import random\n",
        "\n",
        "  run_name = \"\" # what are you testing with this run\n",
        "  notes = \"\"\n",
        "\n",
        "  #hyperparams\n",
        "  hyperparams = dict(\n",
        "    embed_out =random.randint(10,500),\n",
        "    dense_1_nodes = random.randint(10,128),\n",
        "    dropout_1=random.uniform(0.0, 0.9),\n",
        "  )\n",
        "\n",
        "  config= {\n",
        "      \"epochs\": 50,\n",
        "  #     \"num_classes\":num_classes,\n",
        "      \"num_words\": num_words,\n",
        "      \"batch_size\":1024,\n",
        "      **hyperparams\n",
        "  }\n",
        "\n",
        "  model = get_model(num_words, **hyperparams)\n",
        "\n",
        "  wandb.init(project=\"troll-detection \", name=run_name, config=config, notes=notes)\n",
        "\n",
        "  history = model.fit(x_train, y_train, batch_size=config['batch_size'], epochs=config['epochs'], \n",
        "            validation_split=0.2, callbacks=[WandbCallback()])\n",
        "\n",
        "  scores = model.evaluate(x_test, y_test)\n",
        "  wandb.log({'test_'+metric: scores[index] for index, metric in enumerate(model.metrics_names)})\n",
        "  print(\"\\n*** Finished! ***\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaK4E22IJQ3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ba6f170-5cda-4177-c960-9473aeb48e81"
      },
      "source": [
        "%%wandb\n",
        "for x in range(0,100):\n",
        "  run_trials_single()"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0099 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4812 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0101 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5046 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0094 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4947 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0099 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5058 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5042 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0100 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5003 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0097 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5119 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0100 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5193 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0098 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5122 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0096 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5301 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0096 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5176 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0096 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5288 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "4001/4001 [==============================] - 0s 55us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/j3cxtrpa\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 1s 83us/step - loss: 0.6754 - acc: 0.5974 - f1_m: 0.5974 - precision_m: 0.5974 - recall_m: 0.5974 - val_loss: 0.6675 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6610 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6533 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.6375 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6258 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.5893 - acc: 0.6255 - f1_m: 0.6255 - precision_m: 0.6255 - recall_m: 0.6255 - val_loss: 0.5777 - val_acc: 0.6497 - val_f1_m: 0.6497 - val_precision_m: 0.6497 - val_recall_m: 0.6497\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.5146 - acc: 0.7465 - f1_m: 0.7465 - precision_m: 0.7465 - recall_m: 0.7465 - val_loss: 0.5223 - val_acc: 0.7478 - val_f1_m: 0.7478 - val_precision_m: 0.7478 - val_recall_m: 0.7478\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.4298 - acc: 0.8389 - f1_m: 0.8389 - precision_m: 0.8389 - recall_m: 0.8389 - val_loss: 0.4635 - val_acc: 0.7906 - val_f1_m: 0.7906 - val_precision_m: 0.7906 - val_recall_m: 0.7906\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.3388 - acc: 0.8938 - f1_m: 0.8937 - precision_m: 0.8938 - recall_m: 0.8938 - val_loss: 0.4113 - val_acc: 0.8172 - val_f1_m: 0.8172 - val_precision_m: 0.8172 - val_recall_m: 0.8172\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.2534 - acc: 0.9265 - f1_m: 0.9265 - precision_m: 0.9265 - recall_m: 0.9265 - val_loss: 0.3747 - val_acc: 0.8337 - val_f1_m: 0.8337 - val_precision_m: 0.8337 - val_recall_m: 0.8337\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1850 - acc: 0.9488 - f1_m: 0.9488 - precision_m: 0.9488 - recall_m: 0.9488 - val_loss: 0.3527 - val_acc: 0.8478 - val_f1_m: 0.8478 - val_precision_m: 0.8478 - val_recall_m: 0.8478\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1352 - acc: 0.9648 - f1_m: 0.9648 - precision_m: 0.9648 - recall_m: 0.9648 - val_loss: 0.3395 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0962 - acc: 0.9784 - f1_m: 0.9784 - precision_m: 0.9784 - recall_m: 0.9784 - val_loss: 0.3325 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0729 - acc: 0.9847 - f1_m: 0.9847 - precision_m: 0.9847 - recall_m: 0.9847 - val_loss: 0.3420 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0563 - acc: 0.9877 - f1_m: 0.9877 - precision_m: 0.9877 - recall_m: 0.9877 - val_loss: 0.3519 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0453 - acc: 0.9903 - f1_m: 0.9903 - precision_m: 0.9903 - recall_m: 0.9903 - val_loss: 0.3508 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0375 - acc: 0.9919 - f1_m: 0.9919 - precision_m: 0.9919 - recall_m: 0.9919 - val_loss: 0.3574 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0305 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9932 - recall_m: 0.9932 - val_loss: 0.3794 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0270 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3778 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0238 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.3911 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0217 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.3971 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0187 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4110 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0183 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4117 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0173 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4342 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0164 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4248 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0154 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4360 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0153 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4502 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0136 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4451 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0132 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4659 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0126 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4590 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0127 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4654 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0136 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4771 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0123 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4751 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0126 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4810 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0114 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4871 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0117 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5026 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0113 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4929 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0113 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5034 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0112 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5134 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0117 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5092 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0103 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5122 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0112 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5168 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0103 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5254 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5306 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0104 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5391 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5361 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0102 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5275 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0101 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5389 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0101 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5493 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0101 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5560 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0099 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5542 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0098 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5457 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "4001/4001 [==============================] - 0s 49us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/p2ah1a42\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 1s 95us/step - loss: 0.6754 - acc: 0.6027 - f1_m: 0.6025 - precision_m: 0.6026 - recall_m: 0.6025 - val_loss: 0.6626 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6579 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6486 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6343 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6267 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6020 - acc: 0.6072 - f1_m: 0.6072 - precision_m: 0.6072 - recall_m: 0.6072 - val_loss: 0.5962 - val_acc: 0.6119 - val_f1_m: 0.6119 - val_precision_m: 0.6119 - val_recall_m: 0.6119\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.5557 - acc: 0.6527 - f1_m: 0.6527 - precision_m: 0.6527 - recall_m: 0.6527 - val_loss: 0.5524 - val_acc: 0.7281 - val_f1_m: 0.7281 - val_precision_m: 0.7281 - val_recall_m: 0.7281\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.4913 - acc: 0.7700 - f1_m: 0.7700 - precision_m: 0.7700 - recall_m: 0.7700 - val_loss: 0.5026 - val_acc: 0.7744 - val_f1_m: 0.7744 - val_precision_m: 0.7744 - val_recall_m: 0.7744\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.4225 - acc: 0.8453 - f1_m: 0.8453 - precision_m: 0.8453 - recall_m: 0.8453 - val_loss: 0.4568 - val_acc: 0.8050 - val_f1_m: 0.8050 - val_precision_m: 0.8050 - val_recall_m: 0.8050\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3477 - acc: 0.8882 - f1_m: 0.8882 - precision_m: 0.8882 - recall_m: 0.8882 - val_loss: 0.4138 - val_acc: 0.8216 - val_f1_m: 0.8216 - val_precision_m: 0.8216 - val_recall_m: 0.8216\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.2847 - acc: 0.9188 - f1_m: 0.9188 - precision_m: 0.9188 - recall_m: 0.9188 - val_loss: 0.3818 - val_acc: 0.8381 - val_f1_m: 0.8381 - val_precision_m: 0.8381 - val_recall_m: 0.8381\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2298 - acc: 0.9387 - f1_m: 0.9387 - precision_m: 0.9387 - recall_m: 0.9387 - val_loss: 0.3553 - val_acc: 0.8488 - val_f1_m: 0.8487 - val_precision_m: 0.8488 - val_recall_m: 0.8488\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1857 - acc: 0.9554 - f1_m: 0.9554 - precision_m: 0.9554 - recall_m: 0.9554 - val_loss: 0.3392 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1523 - acc: 0.9652 - f1_m: 0.9652 - precision_m: 0.9652 - recall_m: 0.9652 - val_loss: 0.3281 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1262 - acc: 0.9726 - f1_m: 0.9726 - precision_m: 0.9726 - recall_m: 0.9726 - val_loss: 0.3227 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1017 - acc: 0.9798 - f1_m: 0.9798 - precision_m: 0.9798 - recall_m: 0.9798 - val_loss: 0.3252 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0862 - acc: 0.9830 - f1_m: 0.9830 - precision_m: 0.9830 - recall_m: 0.9830 - val_loss: 0.3238 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0739 - acc: 0.9849 - f1_m: 0.9849 - precision_m: 0.9849 - recall_m: 0.9849 - val_loss: 0.3277 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0637 - acc: 0.9874 - f1_m: 0.9874 - precision_m: 0.9874 - recall_m: 0.9874 - val_loss: 0.3334 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0558 - acc: 0.9908 - f1_m: 0.9908 - precision_m: 0.9908 - recall_m: 0.9908 - val_loss: 0.3400 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0495 - acc: 0.9912 - f1_m: 0.9912 - precision_m: 0.9912 - recall_m: 0.9912 - val_loss: 0.3437 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0455 - acc: 0.9913 - f1_m: 0.9913 - precision_m: 0.9913 - recall_m: 0.9913 - val_loss: 0.3554 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0431 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.3592 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0379 - acc: 0.9927 - f1_m: 0.9927 - precision_m: 0.9927 - recall_m: 0.9927 - val_loss: 0.3635 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0334 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.3781 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0315 - acc: 0.9938 - f1_m: 0.9938 - precision_m: 0.9938 - recall_m: 0.9938 - val_loss: 0.3845 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0283 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.4006 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0272 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4036 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0254 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4092 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0246 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.4129 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0241 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.4238 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0213 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4296 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0211 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4402 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0207 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4501 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0187 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4597 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0184 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4620 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0181 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4720 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0185 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4851 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0184 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4799 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0164 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4937 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0177 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5004 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0162 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5002 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0154 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5087 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0159 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5208 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0159 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5286 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0145 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5406 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0142 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5285 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0131 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5354 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0131 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5483 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0142 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.5635 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0142 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5684 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0130 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5634 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "4001/4001 [==============================] - 0s 58us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/puov7mg0\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 1s 115us/step - loss: 0.6688 - acc: 0.5989 - f1_m: 0.5989 - precision_m: 0.5989 - recall_m: 0.5989 - val_loss: 0.6536 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.6355 - acc: 0.6117 - f1_m: 0.6117 - precision_m: 0.6117 - recall_m: 0.6117 - val_loss: 0.6194 - val_acc: 0.6128 - val_f1_m: 0.6128 - val_precision_m: 0.6128 - val_recall_m: 0.6128\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.5760 - acc: 0.6956 - f1_m: 0.6956 - precision_m: 0.6956 - recall_m: 0.6956 - val_loss: 0.5588 - val_acc: 0.7231 - val_f1_m: 0.7231 - val_precision_m: 0.7231 - val_recall_m: 0.7231\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.4854 - acc: 0.8059 - f1_m: 0.8059 - precision_m: 0.8059 - recall_m: 0.8059 - val_loss: 0.4897 - val_acc: 0.7784 - val_f1_m: 0.7784 - val_precision_m: 0.7784 - val_recall_m: 0.7784\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.3851 - acc: 0.8591 - f1_m: 0.8591 - precision_m: 0.8591 - recall_m: 0.8591 - val_loss: 0.4320 - val_acc: 0.8016 - val_f1_m: 0.8016 - val_precision_m: 0.8016 - val_recall_m: 0.8016\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2914 - acc: 0.9032 - f1_m: 0.9032 - precision_m: 0.9032 - recall_m: 0.9032 - val_loss: 0.3869 - val_acc: 0.8216 - val_f1_m: 0.8216 - val_precision_m: 0.8216 - val_recall_m: 0.8216\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2094 - acc: 0.9420 - f1_m: 0.9420 - precision_m: 0.9420 - recall_m: 0.9420 - val_loss: 0.3559 - val_acc: 0.8422 - val_f1_m: 0.8422 - val_precision_m: 0.8422 - val_recall_m: 0.8422\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1475 - acc: 0.9645 - f1_m: 0.9645 - precision_m: 0.9645 - recall_m: 0.9645 - val_loss: 0.3376 - val_acc: 0.8494 - val_f1_m: 0.8494 - val_precision_m: 0.8494 - val_recall_m: 0.8494\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1063 - acc: 0.9755 - f1_m: 0.9755 - precision_m: 0.9755 - recall_m: 0.9755 - val_loss: 0.3298 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0774 - acc: 0.9850 - f1_m: 0.9850 - precision_m: 0.9850 - recall_m: 0.9850 - val_loss: 0.3207 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0576 - acc: 0.9888 - f1_m: 0.9888 - precision_m: 0.9888 - recall_m: 0.9888 - val_loss: 0.3233 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0455 - acc: 0.9918 - f1_m: 0.9918 - precision_m: 0.9918 - recall_m: 0.9918 - val_loss: 0.3288 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0374 - acc: 0.9925 - f1_m: 0.9925 - precision_m: 0.9925 - recall_m: 0.9925 - val_loss: 0.3462 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0313 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.3520 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0258 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3579 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0237 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3715 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0202 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3838 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0195 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3818 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0179 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3932 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0174 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4063 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0162 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4075 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0153 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4171 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0164 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4183 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0140 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4422 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0135 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4231 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0134 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4503 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0128 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4323 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0119 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4517 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0122 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4626 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0118 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4551 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0120 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4644 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0120 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4754 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0119 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4750 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0116 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4829 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0108 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4801 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0110 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4964 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4858 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0109 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5089 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0112 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4999 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0109 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5023 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0107 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5220 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0103 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5065 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0100 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5142 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0103 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5200 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0101 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5126 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0096 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5363 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0103 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5320 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0102 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5249 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0098 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5462 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0100 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5512 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "4001/4001 [==============================] - 0s 56us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/dc83kpx0\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 1s 93us/step - loss: 0.6721 - acc: 0.6059 - f1_m: 0.6059 - precision_m: 0.6059 - recall_m: 0.6059 - val_loss: 0.6637 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6580 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6490 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.6331 - acc: 0.6082 - f1_m: 0.6082 - precision_m: 0.6082 - recall_m: 0.6082 - val_loss: 0.6200 - val_acc: 0.6141 - val_f1_m: 0.6141 - val_precision_m: 0.6141 - val_recall_m: 0.6141\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.5839 - acc: 0.6800 - f1_m: 0.6800 - precision_m: 0.6800 - recall_m: 0.6800 - val_loss: 0.5707 - val_acc: 0.6950 - val_f1_m: 0.6950 - val_precision_m: 0.6950 - val_recall_m: 0.6950\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.5085 - acc: 0.7768 - f1_m: 0.7768 - precision_m: 0.7768 - recall_m: 0.7768 - val_loss: 0.5123 - val_acc: 0.7678 - val_f1_m: 0.7678 - val_precision_m: 0.7678 - val_recall_m: 0.7678\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.4202 - acc: 0.8414 - f1_m: 0.8414 - precision_m: 0.8414 - recall_m: 0.8414 - val_loss: 0.4617 - val_acc: 0.7906 - val_f1_m: 0.7906 - val_precision_m: 0.7906 - val_recall_m: 0.7906\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.3362 - acc: 0.8837 - f1_m: 0.8837 - precision_m: 0.8837 - recall_m: 0.8837 - val_loss: 0.4203 - val_acc: 0.8063 - val_f1_m: 0.8062 - val_precision_m: 0.8063 - val_recall_m: 0.8063\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.2605 - acc: 0.9186 - f1_m: 0.9186 - precision_m: 0.9186 - recall_m: 0.9186 - val_loss: 0.3870 - val_acc: 0.8209 - val_f1_m: 0.8209 - val_precision_m: 0.8209 - val_recall_m: 0.8209\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.1954 - acc: 0.9448 - f1_m: 0.9448 - precision_m: 0.9448 - recall_m: 0.9448 - val_loss: 0.3627 - val_acc: 0.8356 - val_f1_m: 0.8356 - val_precision_m: 0.8356 - val_recall_m: 0.8356\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.1480 - acc: 0.9602 - f1_m: 0.9602 - precision_m: 0.9602 - recall_m: 0.9602 - val_loss: 0.3541 - val_acc: 0.8334 - val_f1_m: 0.8334 - val_precision_m: 0.8334 - val_recall_m: 0.8334\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.1127 - acc: 0.9706 - f1_m: 0.9706 - precision_m: 0.9706 - recall_m: 0.9706 - val_loss: 0.3477 - val_acc: 0.8450 - val_f1_m: 0.8450 - val_precision_m: 0.8450 - val_recall_m: 0.8450\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0867 - acc: 0.9797 - f1_m: 0.9797 - precision_m: 0.9797 - recall_m: 0.9797 - val_loss: 0.3396 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0688 - acc: 0.9841 - f1_m: 0.9841 - precision_m: 0.9841 - recall_m: 0.9841 - val_loss: 0.3458 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0564 - acc: 0.9876 - f1_m: 0.9876 - precision_m: 0.9876 - recall_m: 0.9876 - val_loss: 0.3527 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0445 - acc: 0.9908 - f1_m: 0.9908 - precision_m: 0.9908 - recall_m: 0.9908 - val_loss: 0.3575 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0383 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.3671 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0322 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3679 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0287 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3821 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0252 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3781 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0232 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3933 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0214 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3950 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0202 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4047 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0183 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4157 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0170 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4172 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0167 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4308 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0159 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4289 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0153 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4376 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0142 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4375 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0146 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4583 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0138 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4462 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0128 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4590 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0130 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4625 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4666 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0125 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4620 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4830 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4736 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0113 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4848 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4896 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4934 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0112 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4966 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0108 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5017 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5004 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0104 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5119 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0108 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5033 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0099 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5131 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0108 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5154 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5189 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0103 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5257 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0101 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5339 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0097 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5309 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "4001/4001 [==============================] - 0s 53us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/v94dx3z8\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 1s 113us/step - loss: 0.6676 - acc: 0.6064 - f1_m: 0.6064 - precision_m: 0.6064 - recall_m: 0.6064 - val_loss: 0.6528 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6319 - acc: 0.6087 - f1_m: 0.6087 - precision_m: 0.6087 - recall_m: 0.6087 - val_loss: 0.6125 - val_acc: 0.6228 - val_f1_m: 0.6228 - val_precision_m: 0.6228 - val_recall_m: 0.6228\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5615 - acc: 0.6948 - f1_m: 0.6948 - precision_m: 0.6948 - recall_m: 0.6948 - val_loss: 0.5427 - val_acc: 0.7447 - val_f1_m: 0.7447 - val_precision_m: 0.7447 - val_recall_m: 0.7447\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.4558 - acc: 0.8237 - f1_m: 0.8237 - precision_m: 0.8237 - recall_m: 0.8237 - val_loss: 0.4719 - val_acc: 0.7841 - val_f1_m: 0.7841 - val_precision_m: 0.7841 - val_recall_m: 0.7841\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3498 - acc: 0.8807 - f1_m: 0.8807 - precision_m: 0.8807 - recall_m: 0.8807 - val_loss: 0.4160 - val_acc: 0.8109 - val_f1_m: 0.8109 - val_precision_m: 0.8109 - val_recall_m: 0.8109\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2578 - acc: 0.9211 - f1_m: 0.9211 - precision_m: 0.9211 - recall_m: 0.9211 - val_loss: 0.3730 - val_acc: 0.8297 - val_f1_m: 0.8297 - val_precision_m: 0.8297 - val_recall_m: 0.8297\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1801 - acc: 0.9530 - f1_m: 0.9530 - precision_m: 0.9530 - recall_m: 0.9530 - val_loss: 0.3476 - val_acc: 0.8419 - val_f1_m: 0.8419 - val_precision_m: 0.8419 - val_recall_m: 0.8419\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1238 - acc: 0.9711 - f1_m: 0.9711 - precision_m: 0.9711 - recall_m: 0.9711 - val_loss: 0.3292 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0868 - acc: 0.9816 - f1_m: 0.9816 - precision_m: 0.9816 - recall_m: 0.9816 - val_loss: 0.3265 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0626 - acc: 0.9872 - f1_m: 0.9872 - precision_m: 0.9872 - recall_m: 0.9872 - val_loss: 0.3307 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0481 - acc: 0.9913 - f1_m: 0.9913 - precision_m: 0.9913 - recall_m: 0.9913 - val_loss: 0.3359 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0378 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.3470 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0316 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3542 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0259 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3659 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0230 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.3729 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0200 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3804 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0180 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3859 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0171 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3971 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0155 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3978 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0151 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4138 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0142 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4176 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0137 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4194 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0135 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4288 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0128 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4350 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0122 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4504 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0119 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4433 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0124 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4526 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0119 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4530 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0113 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4675 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0114 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4562 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0112 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.4710 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0104 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4736 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4821 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0106 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4736 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0107 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4916 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0113 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4987 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0105 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4815 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0097 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5045 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0105 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5003 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0102 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5032 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0105 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5075 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0108 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5118 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0100 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5137 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0099 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5276 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0107 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5087 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0106 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5357 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0101 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5291 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0098 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5210 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0094 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5316 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0094 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5387 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "4001/4001 [==============================] - 0s 53us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/m1speu0w\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 1s 110us/step - loss: 0.6765 - acc: 0.6013 - f1_m: 0.6012 - precision_m: 0.6013 - recall_m: 0.6013 - val_loss: 0.6656 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6608 - acc: 0.6069 - f1_m: 0.6069 - precision_m: 0.6069 - recall_m: 0.6069 - val_loss: 0.6515 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6387 - acc: 0.6147 - f1_m: 0.6147 - precision_m: 0.6147 - recall_m: 0.6147 - val_loss: 0.6251 - val_acc: 0.6138 - val_f1_m: 0.6137 - val_precision_m: 0.6138 - val_recall_m: 0.6138\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.5943 - acc: 0.6624 - f1_m: 0.6624 - precision_m: 0.6624 - recall_m: 0.6624 - val_loss: 0.5798 - val_acc: 0.7034 - val_f1_m: 0.7034 - val_precision_m: 0.7034 - val_recall_m: 0.7034\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.5274 - acc: 0.7594 - f1_m: 0.7594 - precision_m: 0.7594 - recall_m: 0.7594 - val_loss: 0.5228 - val_acc: 0.7588 - val_f1_m: 0.7587 - val_precision_m: 0.7588 - val_recall_m: 0.7588\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.4493 - acc: 0.8196 - f1_m: 0.8196 - precision_m: 0.8196 - recall_m: 0.8196 - val_loss: 0.4691 - val_acc: 0.7853 - val_f1_m: 0.7853 - val_precision_m: 0.7853 - val_recall_m: 0.7853\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.3693 - acc: 0.8644 - f1_m: 0.8644 - precision_m: 0.8644 - recall_m: 0.8644 - val_loss: 0.4258 - val_acc: 0.8084 - val_f1_m: 0.8084 - val_precision_m: 0.8084 - val_recall_m: 0.8084\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.2974 - acc: 0.9006 - f1_m: 0.9006 - precision_m: 0.9006 - recall_m: 0.9006 - val_loss: 0.3899 - val_acc: 0.8247 - val_f1_m: 0.8247 - val_precision_m: 0.8247 - val_recall_m: 0.8247\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.2363 - acc: 0.9309 - f1_m: 0.9309 - precision_m: 0.9309 - recall_m: 0.9309 - val_loss: 0.3618 - val_acc: 0.8387 - val_f1_m: 0.8387 - val_precision_m: 0.8387 - val_recall_m: 0.8387\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.1880 - acc: 0.9500 - f1_m: 0.9500 - precision_m: 0.9500 - recall_m: 0.9500 - val_loss: 0.3436 - val_acc: 0.8472 - val_f1_m: 0.8472 - val_precision_m: 0.8472 - val_recall_m: 0.8472\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1451 - acc: 0.9677 - f1_m: 0.9677 - precision_m: 0.9677 - recall_m: 0.9677 - val_loss: 0.3305 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.1144 - acc: 0.9756 - f1_m: 0.9756 - precision_m: 0.9756 - recall_m: 0.9756 - val_loss: 0.3281 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0940 - acc: 0.9802 - f1_m: 0.9802 - precision_m: 0.9802 - recall_m: 0.9802 - val_loss: 0.3265 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0773 - acc: 0.9848 - f1_m: 0.9848 - precision_m: 0.9848 - recall_m: 0.9848 - val_loss: 0.3303 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0638 - acc: 0.9880 - f1_m: 0.9880 - precision_m: 0.9880 - recall_m: 0.9880 - val_loss: 0.3333 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0543 - acc: 0.9901 - f1_m: 0.9901 - precision_m: 0.9901 - recall_m: 0.9901 - val_loss: 0.3375 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0453 - acc: 0.9907 - f1_m: 0.9907 - precision_m: 0.9907 - recall_m: 0.9907 - val_loss: 0.3496 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0382 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.3543 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0362 - acc: 0.9918 - f1_m: 0.9918 - precision_m: 0.9918 - recall_m: 0.9918 - val_loss: 0.3634 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0325 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.3802 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0279 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3844 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0251 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3989 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0235 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4001 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0223 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4066 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0217 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4203 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0203 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4231 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0186 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4453 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0178 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4473 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0174 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4598 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0169 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4575 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0150 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4677 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0155 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4841 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0145 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4769 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0138 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4886 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0139 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4998 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0137 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4927 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0135 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5033 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0128 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5309 - val_acc: 0.8516 - val_f1_m: 0.8516 - val_precision_m: 0.8516 - val_recall_m: 0.8516\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0128 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5243 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0123 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5351 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0125 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5397 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0119 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5358 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0118 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5533 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0115 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5442 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0118 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5577 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0110 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5620 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0118 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5649 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0111 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5791 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0110 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5798 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5849 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "4001/4001 [==============================] - 0s 58us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/06dcauvu\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 2s 124us/step - loss: 0.6712 - acc: 0.6033 - f1_m: 0.6033 - precision_m: 0.6033 - recall_m: 0.6033 - val_loss: 0.6567 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6429 - acc: 0.6148 - f1_m: 0.6148 - precision_m: 0.6148 - recall_m: 0.6148 - val_loss: 0.6284 - val_acc: 0.6150 - val_f1_m: 0.6150 - val_precision_m: 0.6150 - val_recall_m: 0.6150\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.5959 - acc: 0.6552 - f1_m: 0.6552 - precision_m: 0.6552 - recall_m: 0.6552 - val_loss: 0.5806 - val_acc: 0.7144 - val_f1_m: 0.7144 - val_precision_m: 0.7144 - val_recall_m: 0.7144\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.5177 - acc: 0.7784 - f1_m: 0.7784 - precision_m: 0.7784 - recall_m: 0.7784 - val_loss: 0.5160 - val_acc: 0.7700 - val_f1_m: 0.7700 - val_precision_m: 0.7700 - val_recall_m: 0.7700\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.4252 - acc: 0.8439 - f1_m: 0.8439 - precision_m: 0.8439 - recall_m: 0.8439 - val_loss: 0.4605 - val_acc: 0.7934 - val_f1_m: 0.7934 - val_precision_m: 0.7934 - val_recall_m: 0.7934\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3390 - acc: 0.8826 - f1_m: 0.8826 - precision_m: 0.8826 - recall_m: 0.8826 - val_loss: 0.4140 - val_acc: 0.8075 - val_f1_m: 0.8075 - val_precision_m: 0.8075 - val_recall_m: 0.8075\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2605 - acc: 0.9179 - f1_m: 0.9179 - precision_m: 0.9179 - recall_m: 0.9179 - val_loss: 0.3775 - val_acc: 0.8256 - val_f1_m: 0.8256 - val_precision_m: 0.8256 - val_recall_m: 0.8256\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1937 - acc: 0.9459 - f1_m: 0.9459 - precision_m: 0.9459 - recall_m: 0.9459 - val_loss: 0.3516 - val_acc: 0.8397 - val_f1_m: 0.8397 - val_precision_m: 0.8397 - val_recall_m: 0.8397\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1410 - acc: 0.9656 - f1_m: 0.9656 - precision_m: 0.9656 - recall_m: 0.9656 - val_loss: 0.3336 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1012 - acc: 0.9777 - f1_m: 0.9777 - precision_m: 0.9777 - recall_m: 0.9777 - val_loss: 0.3219 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0762 - acc: 0.9848 - f1_m: 0.9848 - precision_m: 0.9848 - recall_m: 0.9848 - val_loss: 0.3260 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0583 - acc: 0.9891 - f1_m: 0.9891 - precision_m: 0.9891 - recall_m: 0.9891 - val_loss: 0.3266 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0461 - acc: 0.9911 - f1_m: 0.9911 - precision_m: 0.9911 - recall_m: 0.9911 - val_loss: 0.3368 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0385 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.3412 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0322 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.3488 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0275 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.3445 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0257 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.3668 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0219 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3611 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0195 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.3784 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0179 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.3794 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0173 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3882 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0157 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3893 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0158 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3991 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0149 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4021 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0141 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4181 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0141 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4128 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0139 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4215 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0125 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4213 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0128 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4252 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0128 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4370 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0128 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4318 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0118 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4421 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0114 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4479 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0117 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4488 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0117 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4524 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0119 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4551 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0118 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4667 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0109 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4635 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0109 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4634 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0107 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4696 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0108 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4751 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0112 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4770 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0111 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4763 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0101 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4828 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0101 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4901 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0102 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4820 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0100 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4880 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0101 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4954 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0099 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4948 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0102 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5061 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "4001/4001 [==============================] - 0s 57us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/zd87m9qv\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 2s 129us/step - loss: 0.6765 - acc: 0.5991 - f1_m: 0.5991 - precision_m: 0.5991 - recall_m: 0.5991 - val_loss: 0.6623 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6562 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6455 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6281 - acc: 0.6070 - f1_m: 0.6070 - precision_m: 0.6070 - recall_m: 0.6070 - val_loss: 0.6159 - val_acc: 0.6144 - val_f1_m: 0.6144 - val_precision_m: 0.6144 - val_recall_m: 0.6144\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.5835 - acc: 0.6354 - f1_m: 0.6354 - precision_m: 0.6354 - recall_m: 0.6354 - val_loss: 0.5727 - val_acc: 0.6850 - val_f1_m: 0.6850 - val_precision_m: 0.6850 - val_recall_m: 0.6850\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.5232 - acc: 0.7340 - f1_m: 0.7340 - precision_m: 0.7340 - recall_m: 0.7340 - val_loss: 0.5257 - val_acc: 0.7453 - val_f1_m: 0.7453 - val_precision_m: 0.7453 - val_recall_m: 0.7453\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.4604 - acc: 0.8022 - f1_m: 0.8022 - precision_m: 0.8022 - recall_m: 0.8022 - val_loss: 0.4799 - val_acc: 0.7909 - val_f1_m: 0.7909 - val_precision_m: 0.7909 - val_recall_m: 0.7909\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3932 - acc: 0.8570 - f1_m: 0.8570 - precision_m: 0.8570 - recall_m: 0.8570 - val_loss: 0.4379 - val_acc: 0.8159 - val_f1_m: 0.8159 - val_precision_m: 0.8159 - val_recall_m: 0.8159\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3301 - acc: 0.8948 - f1_m: 0.8948 - precision_m: 0.8948 - recall_m: 0.8948 - val_loss: 0.4050 - val_acc: 0.8328 - val_f1_m: 0.8328 - val_precision_m: 0.8328 - val_recall_m: 0.8328\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.2756 - acc: 0.9184 - f1_m: 0.9184 - precision_m: 0.9184 - recall_m: 0.9184 - val_loss: 0.3754 - val_acc: 0.8444 - val_f1_m: 0.8444 - val_precision_m: 0.8444 - val_recall_m: 0.8444\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2285 - acc: 0.9404 - f1_m: 0.9404 - precision_m: 0.9404 - recall_m: 0.9404 - val_loss: 0.3531 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1901 - acc: 0.9543 - f1_m: 0.9543 - precision_m: 0.9543 - recall_m: 0.9543 - val_loss: 0.3379 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1592 - acc: 0.9641 - f1_m: 0.9641 - precision_m: 0.9641 - recall_m: 0.9641 - val_loss: 0.3244 - val_acc: 0.8759 - val_f1_m: 0.8759 - val_precision_m: 0.8759 - val_recall_m: 0.8759\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1306 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - val_loss: 0.3207 - val_acc: 0.8778 - val_f1_m: 0.8778 - val_precision_m: 0.8778 - val_recall_m: 0.8778\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1099 - acc: 0.9795 - f1_m: 0.9795 - precision_m: 0.9795 - recall_m: 0.9795 - val_loss: 0.3171 - val_acc: 0.8812 - val_f1_m: 0.8812 - val_precision_m: 0.8812 - val_recall_m: 0.8812\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0932 - acc: 0.9835 - f1_m: 0.9835 - precision_m: 0.9835 - recall_m: 0.9835 - val_loss: 0.3214 - val_acc: 0.8812 - val_f1_m: 0.8812 - val_precision_m: 0.8812 - val_recall_m: 0.8812\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0830 - acc: 0.9855 - f1_m: 0.9855 - precision_m: 0.9855 - recall_m: 0.9855 - val_loss: 0.3238 - val_acc: 0.8822 - val_f1_m: 0.8822 - val_precision_m: 0.8822 - val_recall_m: 0.8822\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0751 - acc: 0.9873 - f1_m: 0.9873 - precision_m: 0.9873 - recall_m: 0.9873 - val_loss: 0.3277 - val_acc: 0.8803 - val_f1_m: 0.8803 - val_precision_m: 0.8803 - val_recall_m: 0.8803\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0661 - acc: 0.9885 - f1_m: 0.9885 - precision_m: 0.9885 - recall_m: 0.9885 - val_loss: 0.3349 - val_acc: 0.8819 - val_f1_m: 0.8819 - val_precision_m: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0598 - acc: 0.9896 - f1_m: 0.9896 - precision_m: 0.9896 - recall_m: 0.9896 - val_loss: 0.3442 - val_acc: 0.8794 - val_f1_m: 0.8794 - val_precision_m: 0.8794 - val_recall_m: 0.8794\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0544 - acc: 0.9907 - f1_m: 0.9907 - precision_m: 0.9907 - recall_m: 0.9907 - val_loss: 0.3469 - val_acc: 0.8841 - val_f1_m: 0.8841 - val_precision_m: 0.8841 - val_recall_m: 0.8841\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0506 - acc: 0.9903 - f1_m: 0.9903 - precision_m: 0.9903 - recall_m: 0.9903 - val_loss: 0.3563 - val_acc: 0.8797 - val_f1_m: 0.8797 - val_precision_m: 0.8797 - val_recall_m: 0.8797\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0431 - acc: 0.9919 - f1_m: 0.9919 - precision_m: 0.9919 - recall_m: 0.9919 - val_loss: 0.3659 - val_acc: 0.8812 - val_f1_m: 0.8812 - val_precision_m: 0.8812 - val_recall_m: 0.8812\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0385 - acc: 0.9924 - f1_m: 0.9924 - precision_m: 0.9924 - recall_m: 0.9924 - val_loss: 0.3792 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0362 - acc: 0.9926 - f1_m: 0.9926 - precision_m: 0.9926 - recall_m: 0.9926 - val_loss: 0.3936 - val_acc: 0.8744 - val_f1_m: 0.8744 - val_precision_m: 0.8744 - val_recall_m: 0.8744\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0325 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3956 - val_acc: 0.8769 - val_f1_m: 0.8769 - val_precision_m: 0.8769 - val_recall_m: 0.8769\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0305 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9932 - recall_m: 0.9932 - val_loss: 0.4055 - val_acc: 0.8744 - val_f1_m: 0.8744 - val_precision_m: 0.8744 - val_recall_m: 0.8744\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0276 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.4175 - val_acc: 0.8759 - val_f1_m: 0.8759 - val_precision_m: 0.8759 - val_recall_m: 0.8759\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0251 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4257 - val_acc: 0.8762 - val_f1_m: 0.8762 - val_precision_m: 0.8762 - val_recall_m: 0.8762\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0229 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4336 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0216 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.4551 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0189 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4506 - val_acc: 0.8769 - val_f1_m: 0.8769 - val_precision_m: 0.8769 - val_recall_m: 0.8769\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0199 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4702 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0185 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4710 - val_acc: 0.8781 - val_f1_m: 0.8781 - val_precision_m: 0.8781 - val_recall_m: 0.8781\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0176 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4835 - val_acc: 0.8759 - val_f1_m: 0.8759 - val_precision_m: 0.8759 - val_recall_m: 0.8759\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0175 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4931 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0176 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5059 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0164 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5077 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0160 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5219 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0155 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5253 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0144 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5360 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0146 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.5396 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0153 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5383 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0139 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5497 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0132 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5605 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0140 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5502 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0139 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5595 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0127 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5767 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0131 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5849 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0129 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5854 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0133 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5883 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "4001/4001 [==============================] - 0s 55us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/b6lir4k5\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 2s 137us/step - loss: 0.6694 - acc: 0.6066 - f1_m: 0.6066 - precision_m: 0.6066 - recall_m: 0.6066 - val_loss: 0.6564 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6408 - acc: 0.6072 - f1_m: 0.6072 - precision_m: 0.6072 - recall_m: 0.6072 - val_loss: 0.6245 - val_acc: 0.6150 - val_f1_m: 0.6150 - val_precision_m: 0.6150 - val_recall_m: 0.6150\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.5802 - acc: 0.6720 - f1_m: 0.6720 - precision_m: 0.6720 - recall_m: 0.6720 - val_loss: 0.5609 - val_acc: 0.7272 - val_f1_m: 0.7272 - val_precision_m: 0.7272 - val_recall_m: 0.7272\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.4796 - acc: 0.8091 - f1_m: 0.8091 - precision_m: 0.8091 - recall_m: 0.8091 - val_loss: 0.4857 - val_acc: 0.7753 - val_f1_m: 0.7753 - val_precision_m: 0.7753 - val_recall_m: 0.7753\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3682 - acc: 0.8723 - f1_m: 0.8723 - precision_m: 0.8723 - recall_m: 0.8723 - val_loss: 0.4244 - val_acc: 0.8003 - val_f1_m: 0.8003 - val_precision_m: 0.8003 - val_recall_m: 0.8003\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2677 - acc: 0.9174 - f1_m: 0.9174 - precision_m: 0.9174 - recall_m: 0.9174 - val_loss: 0.3793 - val_acc: 0.8284 - val_f1_m: 0.8284 - val_precision_m: 0.8284 - val_recall_m: 0.8284\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1872 - acc: 0.9487 - f1_m: 0.9487 - precision_m: 0.9487 - recall_m: 0.9487 - val_loss: 0.3543 - val_acc: 0.8356 - val_f1_m: 0.8356 - val_precision_m: 0.8356 - val_recall_m: 0.8356\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1315 - acc: 0.9672 - f1_m: 0.9672 - precision_m: 0.9672 - recall_m: 0.9672 - val_loss: 0.3396 - val_acc: 0.8466 - val_f1_m: 0.8466 - val_precision_m: 0.8466 - val_recall_m: 0.8466\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0902 - acc: 0.9815 - f1_m: 0.9815 - precision_m: 0.9815 - recall_m: 0.9815 - val_loss: 0.3351 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0658 - acc: 0.9863 - f1_m: 0.9863 - precision_m: 0.9863 - recall_m: 0.9863 - val_loss: 0.3396 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0494 - acc: 0.9903 - f1_m: 0.9903 - precision_m: 0.9903 - recall_m: 0.9903 - val_loss: 0.3407 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0378 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.3415 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0309 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3498 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0266 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3569 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0232 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3778 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0207 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3785 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0178 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3801 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0166 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4142 - val_acc: 0.8525 - val_f1_m: 0.8525 - val_precision_m: 0.8525 - val_recall_m: 0.8525\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0157 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.3886 - val_acc: 0.8759 - val_f1_m: 0.8759 - val_precision_m: 0.8759 - val_recall_m: 0.8759\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0149 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4287 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0148 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4211 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0134 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4162 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0131 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4309 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0125 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4422 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0134 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4455 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0123 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4419 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0113 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4623 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0117 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4531 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0108 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4707 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0108 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4580 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0108 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4933 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0104 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4674 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0102 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4823 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0102 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5008 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0103 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4930 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0102 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5001 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0101 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4993 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0097 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5007 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0096 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5051 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0098 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5095 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0093 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5238 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0096 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5174 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0094 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5183 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0102 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5314 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0100 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5257 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0092 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5391 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0092 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5301 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0094 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5369 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0093 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5429 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0094 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5423 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "4001/4001 [==============================] - 0s 60us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/9b4p1fby\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 2s 146us/step - loss: 0.6711 - acc: 0.5942 - f1_m: 0.5942 - precision_m: 0.5942 - recall_m: 0.5942 - val_loss: 0.6551 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6398 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6278 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5897 - acc: 0.6391 - f1_m: 0.6391 - precision_m: 0.6391 - recall_m: 0.6391 - val_loss: 0.5767 - val_acc: 0.7153 - val_f1_m: 0.7153 - val_precision_m: 0.7153 - val_recall_m: 0.7153\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5041 - acc: 0.7997 - f1_m: 0.7997 - precision_m: 0.7997 - recall_m: 0.7997 - val_loss: 0.5071 - val_acc: 0.7803 - val_f1_m: 0.7803 - val_precision_m: 0.7803 - val_recall_m: 0.7803\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4008 - acc: 0.8659 - f1_m: 0.8659 - precision_m: 0.8659 - recall_m: 0.8659 - val_loss: 0.4457 - val_acc: 0.8009 - val_f1_m: 0.8009 - val_precision_m: 0.8009 - val_recall_m: 0.8009\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3030 - acc: 0.9088 - f1_m: 0.9087 - precision_m: 0.9088 - recall_m: 0.9088 - val_loss: 0.3984 - val_acc: 0.8153 - val_f1_m: 0.8153 - val_precision_m: 0.8153 - val_recall_m: 0.8153\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2208 - acc: 0.9395 - f1_m: 0.9395 - precision_m: 0.9395 - recall_m: 0.9395 - val_loss: 0.3609 - val_acc: 0.8372 - val_f1_m: 0.8372 - val_precision_m: 0.8372 - val_recall_m: 0.8372\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1565 - acc: 0.9627 - f1_m: 0.9627 - precision_m: 0.9627 - recall_m: 0.9627 - val_loss: 0.3377 - val_acc: 0.8491 - val_f1_m: 0.8491 - val_precision_m: 0.8491 - val_recall_m: 0.8491\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1103 - acc: 0.9761 - f1_m: 0.9761 - precision_m: 0.9761 - recall_m: 0.9761 - val_loss: 0.3290 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0780 - acc: 0.9836 - f1_m: 0.9836 - precision_m: 0.9836 - recall_m: 0.9836 - val_loss: 0.3243 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0560 - acc: 0.9901 - f1_m: 0.9901 - precision_m: 0.9901 - recall_m: 0.9901 - val_loss: 0.3354 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0434 - acc: 0.9917 - f1_m: 0.9917 - precision_m: 0.9917 - recall_m: 0.9917 - val_loss: 0.3310 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0343 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3478 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0285 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3446 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0241 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3645 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0203 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.3600 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0182 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3697 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0167 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3863 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0148 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.3913 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0137 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4068 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0137 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3934 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0137 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4392 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0128 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4046 - val_acc: 0.8769 - val_f1_m: 0.8769 - val_precision_m: 0.8769 - val_recall_m: 0.8769\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0123 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4283 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0117 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4237 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0110 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4441 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0111 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4367 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0107 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4411 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0103 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4492 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0104 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4602 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0104 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4599 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0100 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4576 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0103 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4710 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0101 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4686 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0099 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4719 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0096 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4772 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0101 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4784 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0094 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4802 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0101 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4869 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0098 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4876 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0097 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4948 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0094 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4873 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0097 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5025 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0100 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4916 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0091 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4956 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0094 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5017 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0095 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5075 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0092 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5112 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0093 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5187 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0091 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5113 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "4001/4001 [==============================] - 0s 63us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/vx7hrht6\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 2s 150us/step - loss: 0.6781 - acc: 0.5902 - f1_m: 0.5902 - precision_m: 0.5902 - recall_m: 0.5902 - val_loss: 0.6629 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6586 - acc: 0.6074 - f1_m: 0.6074 - precision_m: 0.6074 - recall_m: 0.6074 - val_loss: 0.6488 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.6338 - acc: 0.6238 - f1_m: 0.6237 - precision_m: 0.6238 - recall_m: 0.6238 - val_loss: 0.6249 - val_acc: 0.6356 - val_f1_m: 0.6356 - val_precision_m: 0.6356 - val_recall_m: 0.6356\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5954 - acc: 0.6908 - f1_m: 0.6908 - precision_m: 0.6908 - recall_m: 0.6908 - val_loss: 0.5857 - val_acc: 0.7072 - val_f1_m: 0.7072 - val_precision_m: 0.7072 - val_recall_m: 0.7072\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5377 - acc: 0.7613 - f1_m: 0.7613 - precision_m: 0.7613 - recall_m: 0.7613 - val_loss: 0.5382 - val_acc: 0.7653 - val_f1_m: 0.7653 - val_precision_m: 0.7653 - val_recall_m: 0.7653\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.4727 - acc: 0.8149 - f1_m: 0.8149 - precision_m: 0.8149 - recall_m: 0.8149 - val_loss: 0.4916 - val_acc: 0.7850 - val_f1_m: 0.7850 - val_precision_m: 0.7850 - val_recall_m: 0.7850\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4075 - acc: 0.8407 - f1_m: 0.8407 - precision_m: 0.8407 - recall_m: 0.8407 - val_loss: 0.4502 - val_acc: 0.8037 - val_f1_m: 0.8037 - val_precision_m: 0.8037 - val_recall_m: 0.8037\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3406 - acc: 0.8804 - f1_m: 0.8804 - precision_m: 0.8804 - recall_m: 0.8804 - val_loss: 0.4134 - val_acc: 0.8156 - val_f1_m: 0.8156 - val_precision_m: 0.8156 - val_recall_m: 0.8156\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2807 - acc: 0.9100 - f1_m: 0.9100 - precision_m: 0.9100 - recall_m: 0.9100 - val_loss: 0.3831 - val_acc: 0.8263 - val_f1_m: 0.8262 - val_precision_m: 0.8263 - val_recall_m: 0.8263\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2287 - acc: 0.9352 - f1_m: 0.9352 - precision_m: 0.9352 - recall_m: 0.9352 - val_loss: 0.3594 - val_acc: 0.8372 - val_f1_m: 0.8372 - val_precision_m: 0.8372 - val_recall_m: 0.8372\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1823 - acc: 0.9538 - f1_m: 0.9538 - precision_m: 0.9538 - recall_m: 0.9538 - val_loss: 0.3404 - val_acc: 0.8478 - val_f1_m: 0.8478 - val_precision_m: 0.8478 - val_recall_m: 0.8478\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1418 - acc: 0.9664 - f1_m: 0.9664 - precision_m: 0.9664 - recall_m: 0.9664 - val_loss: 0.3293 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1149 - acc: 0.9738 - f1_m: 0.9738 - precision_m: 0.9738 - recall_m: 0.9738 - val_loss: 0.3302 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0919 - acc: 0.9798 - f1_m: 0.9798 - precision_m: 0.9798 - recall_m: 0.9798 - val_loss: 0.3191 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0760 - acc: 0.9831 - f1_m: 0.9831 - precision_m: 0.9831 - recall_m: 0.9831 - val_loss: 0.3241 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0635 - acc: 0.9872 - f1_m: 0.9872 - precision_m: 0.9872 - recall_m: 0.9872 - val_loss: 0.3291 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0546 - acc: 0.9891 - f1_m: 0.9891 - precision_m: 0.9891 - recall_m: 0.9891 - val_loss: 0.3332 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0461 - acc: 0.9898 - f1_m: 0.9898 - precision_m: 0.9898 - recall_m: 0.9898 - val_loss: 0.3479 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0424 - acc: 0.9905 - f1_m: 0.9905 - precision_m: 0.9905 - recall_m: 0.9905 - val_loss: 0.3471 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0375 - acc: 0.9929 - f1_m: 0.9929 - precision_m: 0.9929 - recall_m: 0.9929 - val_loss: 0.3574 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0329 - acc: 0.9925 - f1_m: 0.9925 - precision_m: 0.9925 - recall_m: 0.9925 - val_loss: 0.3640 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0307 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.3655 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0292 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.3793 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0274 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3917 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0267 - acc: 0.9938 - f1_m: 0.9938 - precision_m: 0.9938 - recall_m: 0.9938 - val_loss: 0.3825 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0256 - acc: 0.9938 - f1_m: 0.9938 - precision_m: 0.9938 - recall_m: 0.9938 - val_loss: 0.4003 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0220 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4075 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0224 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4059 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0208 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4163 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0210 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.4235 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0200 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4310 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0197 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.4345 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0189 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4360 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0186 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4477 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0179 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4479 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0183 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4580 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0167 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4619 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0155 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4711 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0163 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4757 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0157 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4913 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0153 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4917 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0156 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4921 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0148 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4993 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0150 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5029 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0149 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5018 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0150 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5243 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0142 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5175 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0141 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5156 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0134 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5214 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0136 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5293 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "4001/4001 [==============================] - 0s 68us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/jgjtdf23\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 2s 154us/step - loss: 0.6717 - acc: 0.5996 - f1_m: 0.5996 - precision_m: 0.5996 - recall_m: 0.5996 - val_loss: 0.6580 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.6449 - acc: 0.6112 - f1_m: 0.6112 - precision_m: 0.6112 - recall_m: 0.6112 - val_loss: 0.6314 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5998 - acc: 0.6581 - f1_m: 0.6581 - precision_m: 0.6581 - recall_m: 0.6581 - val_loss: 0.5807 - val_acc: 0.6828 - val_f1_m: 0.6828 - val_precision_m: 0.6828 - val_recall_m: 0.6828\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5206 - acc: 0.7798 - f1_m: 0.7798 - precision_m: 0.7798 - recall_m: 0.7798 - val_loss: 0.5165 - val_acc: 0.7634 - val_f1_m: 0.7634 - val_precision_m: 0.7634 - val_recall_m: 0.7634\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4301 - acc: 0.8402 - f1_m: 0.8402 - precision_m: 0.8402 - recall_m: 0.8402 - val_loss: 0.4595 - val_acc: 0.7894 - val_f1_m: 0.7894 - val_precision_m: 0.7894 - val_recall_m: 0.7894\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3386 - acc: 0.8811 - f1_m: 0.8811 - precision_m: 0.8811 - recall_m: 0.8811 - val_loss: 0.4142 - val_acc: 0.8097 - val_f1_m: 0.8097 - val_precision_m: 0.8097 - val_recall_m: 0.8097\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2605 - acc: 0.9219 - f1_m: 0.9219 - precision_m: 0.9219 - recall_m: 0.9219 - val_loss: 0.3771 - val_acc: 0.8350 - val_f1_m: 0.8350 - val_precision_m: 0.8350 - val_recall_m: 0.8350\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1967 - acc: 0.9463 - f1_m: 0.9463 - precision_m: 0.9463 - recall_m: 0.9463 - val_loss: 0.3500 - val_acc: 0.8500 - val_f1_m: 0.8500 - val_precision_m: 0.8500 - val_recall_m: 0.8500\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1439 - acc: 0.9666 - f1_m: 0.9666 - precision_m: 0.9666 - recall_m: 0.9666 - val_loss: 0.3347 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1078 - acc: 0.9760 - f1_m: 0.9760 - precision_m: 0.9760 - recall_m: 0.9760 - val_loss: 0.3254 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0825 - acc: 0.9835 - f1_m: 0.9835 - precision_m: 0.9835 - recall_m: 0.9835 - val_loss: 0.3294 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0651 - acc: 0.9874 - f1_m: 0.9874 - precision_m: 0.9874 - recall_m: 0.9874 - val_loss: 0.3319 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0522 - acc: 0.9905 - f1_m: 0.9905 - precision_m: 0.9905 - recall_m: 0.9905 - val_loss: 0.3338 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0426 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.3468 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0359 - acc: 0.9925 - f1_m: 0.9925 - precision_m: 0.9925 - recall_m: 0.9925 - val_loss: 0.3455 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0313 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.3659 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0278 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.3655 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0246 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3806 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0221 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3852 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0199 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.3975 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0183 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4009 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0171 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4135 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0163 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4251 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0159 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4183 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0149 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4350 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0145 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4409 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0145 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4478 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0138 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4393 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0149 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4730 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0132 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4559 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0130 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4722 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0129 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4759 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0121 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4789 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0131 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4858 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0120 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4921 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0120 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4897 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0121 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5012 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0111 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4977 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0110 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5109 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0107 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5155 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0107 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5194 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0109 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5206 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0113 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5261 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0107 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5362 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0111 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5383 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0108 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5366 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0103 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5418 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0104 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5531 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0098 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5519 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5449 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "4001/4001 [==============================] - 0s 63us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/1muisnf7\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 2s 139us/step - loss: 0.6931 - acc: 0.5079 - f1_m: 0.5079 - precision_m: 0.5079 - recall_m: 0.5079 - val_loss: 0.6828 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.6769 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6715 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.6666 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6626 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.6559 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6528 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.6416 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6398 - val_acc: 0.6119 - val_f1_m: 0.6119 - val_precision_m: 0.6119 - val_recall_m: 0.6119\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.6210 - acc: 0.6177 - f1_m: 0.6177 - precision_m: 0.6177 - recall_m: 0.6177 - val_loss: 0.6213 - val_acc: 0.6319 - val_f1_m: 0.6319 - val_precision_m: 0.6319 - val_recall_m: 0.6319\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.5920 - acc: 0.6863 - f1_m: 0.6862 - precision_m: 0.6863 - recall_m: 0.6863 - val_loss: 0.5975 - val_acc: 0.6969 - val_f1_m: 0.6969 - val_precision_m: 0.6969 - val_recall_m: 0.6969\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.5552 - acc: 0.7534 - f1_m: 0.7534 - precision_m: 0.7534 - recall_m: 0.7534 - val_loss: 0.5697 - val_acc: 0.7250 - val_f1_m: 0.7250 - val_precision_m: 0.7250 - val_recall_m: 0.7250\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.5126 - acc: 0.7971 - f1_m: 0.7971 - precision_m: 0.7971 - recall_m: 0.7971 - val_loss: 0.5403 - val_acc: 0.7503 - val_f1_m: 0.7503 - val_precision_m: 0.7503 - val_recall_m: 0.7503\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.4660 - acc: 0.8227 - f1_m: 0.8227 - precision_m: 0.8227 - recall_m: 0.8227 - val_loss: 0.5125 - val_acc: 0.7625 - val_f1_m: 0.7625 - val_precision_m: 0.7625 - val_recall_m: 0.7625\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.4206 - acc: 0.8486 - f1_m: 0.8486 - precision_m: 0.8486 - recall_m: 0.8486 - val_loss: 0.4880 - val_acc: 0.7703 - val_f1_m: 0.7703 - val_precision_m: 0.7703 - val_recall_m: 0.7703\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.3784 - acc: 0.8680 - f1_m: 0.8680 - precision_m: 0.8680 - recall_m: 0.8680 - val_loss: 0.4676 - val_acc: 0.7788 - val_f1_m: 0.7787 - val_precision_m: 0.7788 - val_recall_m: 0.7788\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.3400 - acc: 0.8818 - f1_m: 0.8818 - precision_m: 0.8818 - recall_m: 0.8818 - val_loss: 0.4498 - val_acc: 0.7903 - val_f1_m: 0.7903 - val_precision_m: 0.7903 - val_recall_m: 0.7903\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.3047 - acc: 0.8970 - f1_m: 0.8970 - precision_m: 0.8970 - recall_m: 0.8970 - val_loss: 0.4357 - val_acc: 0.7937 - val_f1_m: 0.7937 - val_precision_m: 0.7937 - val_recall_m: 0.7937\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.2733 - acc: 0.9116 - f1_m: 0.9116 - precision_m: 0.9116 - recall_m: 0.9116 - val_loss: 0.4231 - val_acc: 0.8016 - val_f1_m: 0.8016 - val_precision_m: 0.8016 - val_recall_m: 0.8016\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.2453 - acc: 0.9232 - f1_m: 0.9232 - precision_m: 0.9232 - recall_m: 0.9232 - val_loss: 0.4135 - val_acc: 0.8078 - val_f1_m: 0.8078 - val_precision_m: 0.8078 - val_recall_m: 0.8078\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.2204 - acc: 0.9332 - f1_m: 0.9332 - precision_m: 0.9332 - recall_m: 0.9332 - val_loss: 0.4048 - val_acc: 0.8103 - val_f1_m: 0.8103 - val_precision_m: 0.8103 - val_recall_m: 0.8103\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.1983 - acc: 0.9402 - f1_m: 0.9402 - precision_m: 0.9402 - recall_m: 0.9402 - val_loss: 0.3988 - val_acc: 0.8141 - val_f1_m: 0.8141 - val_precision_m: 0.8141 - val_recall_m: 0.8141\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.1782 - acc: 0.9473 - f1_m: 0.9473 - precision_m: 0.9473 - recall_m: 0.9473 - val_loss: 0.3933 - val_acc: 0.8175 - val_f1_m: 0.8175 - val_precision_m: 0.8175 - val_recall_m: 0.8175\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.1616 - acc: 0.9530 - f1_m: 0.9530 - precision_m: 0.9530 - recall_m: 0.9530 - val_loss: 0.3903 - val_acc: 0.8181 - val_f1_m: 0.8181 - val_precision_m: 0.8181 - val_recall_m: 0.8181\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.1460 - acc: 0.9605 - f1_m: 0.9605 - precision_m: 0.9605 - recall_m: 0.9605 - val_loss: 0.3888 - val_acc: 0.8200 - val_f1_m: 0.8200 - val_precision_m: 0.8200 - val_recall_m: 0.8200\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.1337 - acc: 0.9628 - f1_m: 0.9628 - precision_m: 0.9628 - recall_m: 0.9628 - val_loss: 0.3859 - val_acc: 0.8213 - val_f1_m: 0.8212 - val_precision_m: 0.8213 - val_recall_m: 0.8213\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.1222 - acc: 0.9691 - f1_m: 0.9691 - precision_m: 0.9691 - recall_m: 0.9691 - val_loss: 0.3873 - val_acc: 0.8225 - val_f1_m: 0.8225 - val_precision_m: 0.8225 - val_recall_m: 0.8225\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.1116 - acc: 0.9703 - f1_m: 0.9703 - precision_m: 0.9703 - recall_m: 0.9703 - val_loss: 0.3865 - val_acc: 0.8247 - val_f1_m: 0.8247 - val_precision_m: 0.8247 - val_recall_m: 0.8247\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.1030 - acc: 0.9720 - f1_m: 0.9720 - precision_m: 0.9720 - recall_m: 0.9720 - val_loss: 0.3890 - val_acc: 0.8250 - val_f1_m: 0.8250 - val_precision_m: 0.8250 - val_recall_m: 0.8250\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0952 - acc: 0.9752 - f1_m: 0.9752 - precision_m: 0.9752 - recall_m: 0.9752 - val_loss: 0.3889 - val_acc: 0.8294 - val_f1_m: 0.8294 - val_precision_m: 0.8294 - val_recall_m: 0.8294\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0885 - acc: 0.9773 - f1_m: 0.9773 - precision_m: 0.9773 - recall_m: 0.9773 - val_loss: 0.3908 - val_acc: 0.8300 - val_f1_m: 0.8300 - val_precision_m: 0.8300 - val_recall_m: 0.8300\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0820 - acc: 0.9798 - f1_m: 0.9798 - precision_m: 0.9798 - recall_m: 0.9798 - val_loss: 0.3934 - val_acc: 0.8334 - val_f1_m: 0.8334 - val_precision_m: 0.8334 - val_recall_m: 0.8334\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0764 - acc: 0.9805 - f1_m: 0.9805 - precision_m: 0.9805 - recall_m: 0.9805 - val_loss: 0.3968 - val_acc: 0.8350 - val_f1_m: 0.8350 - val_precision_m: 0.8350 - val_recall_m: 0.8350\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0717 - acc: 0.9820 - f1_m: 0.9820 - precision_m: 0.9820 - recall_m: 0.9820 - val_loss: 0.3989 - val_acc: 0.8359 - val_f1_m: 0.8359 - val_precision_m: 0.8359 - val_recall_m: 0.8359\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0669 - acc: 0.9830 - f1_m: 0.9830 - precision_m: 0.9830 - recall_m: 0.9830 - val_loss: 0.4023 - val_acc: 0.8363 - val_f1_m: 0.8362 - val_precision_m: 0.8363 - val_recall_m: 0.8363\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0630 - acc: 0.9851 - f1_m: 0.9851 - precision_m: 0.9851 - recall_m: 0.9851 - val_loss: 0.4067 - val_acc: 0.8372 - val_f1_m: 0.8372 - val_precision_m: 0.8372 - val_recall_m: 0.8372\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0592 - acc: 0.9859 - f1_m: 0.9859 - precision_m: 0.9859 - recall_m: 0.9859 - val_loss: 0.4099 - val_acc: 0.8387 - val_f1_m: 0.8387 - val_precision_m: 0.8387 - val_recall_m: 0.8387\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0566 - acc: 0.9864 - f1_m: 0.9864 - precision_m: 0.9864 - recall_m: 0.9864 - val_loss: 0.4149 - val_acc: 0.8381 - val_f1_m: 0.8381 - val_precision_m: 0.8381 - val_recall_m: 0.8381\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0531 - acc: 0.9871 - f1_m: 0.9871 - precision_m: 0.9871 - recall_m: 0.9871 - val_loss: 0.4192 - val_acc: 0.8375 - val_f1_m: 0.8375 - val_precision_m: 0.8375 - val_recall_m: 0.8375\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0507 - acc: 0.9876 - f1_m: 0.9876 - precision_m: 0.9876 - recall_m: 0.9876 - val_loss: 0.4222 - val_acc: 0.8400 - val_f1_m: 0.8400 - val_precision_m: 0.8400 - val_recall_m: 0.8400\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0481 - acc: 0.9887 - f1_m: 0.9887 - precision_m: 0.9887 - recall_m: 0.9887 - val_loss: 0.4276 - val_acc: 0.8387 - val_f1_m: 0.8387 - val_precision_m: 0.8387 - val_recall_m: 0.8387\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0460 - acc: 0.9891 - f1_m: 0.9891 - precision_m: 0.9891 - recall_m: 0.9891 - val_loss: 0.4300 - val_acc: 0.8397 - val_f1_m: 0.8397 - val_precision_m: 0.8397 - val_recall_m: 0.8397\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0437 - acc: 0.9895 - f1_m: 0.9895 - precision_m: 0.9895 - recall_m: 0.9895 - val_loss: 0.4359 - val_acc: 0.8387 - val_f1_m: 0.8387 - val_precision_m: 0.8387 - val_recall_m: 0.8387\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0418 - acc: 0.9904 - f1_m: 0.9904 - precision_m: 0.9904 - recall_m: 0.9904 - val_loss: 0.4398 - val_acc: 0.8391 - val_f1_m: 0.8391 - val_precision_m: 0.8391 - val_recall_m: 0.8391\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0398 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.4439 - val_acc: 0.8397 - val_f1_m: 0.8397 - val_precision_m: 0.8397 - val_recall_m: 0.8397\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0385 - acc: 0.9913 - f1_m: 0.9912 - precision_m: 0.9913 - recall_m: 0.9913 - val_loss: 0.4476 - val_acc: 0.8394 - val_f1_m: 0.8394 - val_precision_m: 0.8394 - val_recall_m: 0.8394\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0373 - acc: 0.9913 - f1_m: 0.9912 - precision_m: 0.9913 - recall_m: 0.9913 - val_loss: 0.4541 - val_acc: 0.8378 - val_f1_m: 0.8378 - val_precision_m: 0.8378 - val_recall_m: 0.8378\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0355 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.4563 - val_acc: 0.8384 - val_f1_m: 0.8384 - val_precision_m: 0.8384 - val_recall_m: 0.8384\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0342 - acc: 0.9919 - f1_m: 0.9919 - precision_m: 0.9919 - recall_m: 0.9919 - val_loss: 0.4642 - val_acc: 0.8375 - val_f1_m: 0.8375 - val_precision_m: 0.8375 - val_recall_m: 0.8375\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0332 - acc: 0.9925 - f1_m: 0.9925 - precision_m: 0.9925 - recall_m: 0.9925 - val_loss: 0.4648 - val_acc: 0.8391 - val_f1_m: 0.8391 - val_precision_m: 0.8391 - val_recall_m: 0.8391\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0320 - acc: 0.9925 - f1_m: 0.9925 - precision_m: 0.9925 - recall_m: 0.9925 - val_loss: 0.4704 - val_acc: 0.8397 - val_f1_m: 0.8397 - val_precision_m: 0.8397 - val_recall_m: 0.8397\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0309 - acc: 0.9927 - f1_m: 0.9927 - precision_m: 0.9927 - recall_m: 0.9927 - val_loss: 0.4738 - val_acc: 0.8400 - val_f1_m: 0.8400 - val_precision_m: 0.8400 - val_recall_m: 0.8400\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0299 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.4787 - val_acc: 0.8391 - val_f1_m: 0.8391 - val_precision_m: 0.8391 - val_recall_m: 0.8391\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0292 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.4829 - val_acc: 0.8394 - val_f1_m: 0.8394 - val_precision_m: 0.8394 - val_recall_m: 0.8394\n",
            "4001/4001 [==============================] - 0s 64us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/jxv3scar\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 2s 180us/step - loss: 0.6793 - acc: 0.5811 - f1_m: 0.5811 - precision_m: 0.5811 - recall_m: 0.5811 - val_loss: 0.6634 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.6568 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6478 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.6307 - acc: 0.6117 - f1_m: 0.6117 - precision_m: 0.6117 - recall_m: 0.6117 - val_loss: 0.6194 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.5817 - acc: 0.6673 - f1_m: 0.6673 - precision_m: 0.6673 - recall_m: 0.6673 - val_loss: 0.5721 - val_acc: 0.7044 - val_f1_m: 0.7044 - val_precision_m: 0.7044 - val_recall_m: 0.7044\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.5166 - acc: 0.7535 - f1_m: 0.7535 - precision_m: 0.7535 - recall_m: 0.7535 - val_loss: 0.5191 - val_acc: 0.7550 - val_f1_m: 0.7550 - val_precision_m: 0.7550 - val_recall_m: 0.7550\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.4416 - acc: 0.8089 - f1_m: 0.8089 - precision_m: 0.8089 - recall_m: 0.8089 - val_loss: 0.4685 - val_acc: 0.7925 - val_f1_m: 0.7925 - val_precision_m: 0.7925 - val_recall_m: 0.7925\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.3673 - acc: 0.8662 - f1_m: 0.8662 - precision_m: 0.8662 - recall_m: 0.8662 - val_loss: 0.4215 - val_acc: 0.8200 - val_f1_m: 0.8200 - val_precision_m: 0.8200 - val_recall_m: 0.8200\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2928 - acc: 0.9091 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 0.3817 - val_acc: 0.8325 - val_f1_m: 0.8325 - val_precision_m: 0.8325 - val_recall_m: 0.8325\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2327 - acc: 0.9330 - f1_m: 0.9330 - precision_m: 0.9330 - recall_m: 0.9330 - val_loss: 0.3544 - val_acc: 0.8447 - val_f1_m: 0.8447 - val_precision_m: 0.8447 - val_recall_m: 0.8447\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1720 - acc: 0.9563 - f1_m: 0.9563 - precision_m: 0.9563 - recall_m: 0.9563 - val_loss: 0.3356 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1331 - acc: 0.9690 - f1_m: 0.9690 - precision_m: 0.9690 - recall_m: 0.9690 - val_loss: 0.3284 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1045 - acc: 0.9780 - f1_m: 0.9780 - precision_m: 0.9780 - recall_m: 0.9780 - val_loss: 0.3301 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0797 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - val_loss: 0.3303 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0664 - acc: 0.9872 - f1_m: 0.9872 - precision_m: 0.9872 - recall_m: 0.9872 - val_loss: 0.3316 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0573 - acc: 0.9888 - f1_m: 0.9888 - precision_m: 0.9888 - recall_m: 0.9888 - val_loss: 0.3434 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0477 - acc: 0.9919 - f1_m: 0.9919 - precision_m: 0.9919 - recall_m: 0.9919 - val_loss: 0.3598 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0414 - acc: 0.9921 - f1_m: 0.9921 - precision_m: 0.9921 - recall_m: 0.9921 - val_loss: 0.3547 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0371 - acc: 0.9928 - f1_m: 0.9928 - precision_m: 0.9928 - recall_m: 0.9928 - val_loss: 0.3735 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0342 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9932 - recall_m: 0.9932 - val_loss: 0.3770 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0290 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.3903 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0279 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3976 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0276 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.4033 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0258 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4219 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0235 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4199 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0215 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4391 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0219 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4400 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0196 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4534 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0192 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4535 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0174 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4775 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0169 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.4780 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0170 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4864 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0163 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4910 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0147 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5132 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0153 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5171 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0156 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.5261 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0148 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5339 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0143 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5319 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0140 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5494 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0137 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5474 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0139 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5669 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0129 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5640 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0125 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5760 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0125 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5765 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0128 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5791 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0126 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5770 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0128 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.6107 - val_acc: 0.8525 - val_f1_m: 0.8525 - val_precision_m: 0.8525 - val_recall_m: 0.8525\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0125 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6151 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0121 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.6035 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0121 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6197 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0120 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.6155 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "4001/4001 [==============================] - 0s 65us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/m8rmeext\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 2s 176us/step - loss: 0.6763 - acc: 0.5923 - f1_m: 0.5923 - precision_m: 0.5923 - recall_m: 0.5923 - val_loss: 0.6634 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6546 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6430 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6183 - acc: 0.6173 - f1_m: 0.6173 - precision_m: 0.6173 - recall_m: 0.6173 - val_loss: 0.6001 - val_acc: 0.6403 - val_f1_m: 0.6403 - val_precision_m: 0.6403 - val_recall_m: 0.6403\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5444 - acc: 0.7196 - f1_m: 0.7196 - precision_m: 0.7196 - recall_m: 0.7196 - val_loss: 0.5329 - val_acc: 0.7538 - val_f1_m: 0.7537 - val_precision_m: 0.7538 - val_recall_m: 0.7538\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4463 - acc: 0.8314 - f1_m: 0.8314 - precision_m: 0.8314 - recall_m: 0.8314 - val_loss: 0.4666 - val_acc: 0.7841 - val_f1_m: 0.7841 - val_precision_m: 0.7841 - val_recall_m: 0.7841\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3448 - acc: 0.8840 - f1_m: 0.8840 - precision_m: 0.8840 - recall_m: 0.8840 - val_loss: 0.4124 - val_acc: 0.8091 - val_f1_m: 0.8091 - val_precision_m: 0.8091 - val_recall_m: 0.8091\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2517 - acc: 0.9231 - f1_m: 0.9231 - precision_m: 0.9231 - recall_m: 0.9231 - val_loss: 0.3736 - val_acc: 0.8319 - val_f1_m: 0.8319 - val_precision_m: 0.8319 - val_recall_m: 0.8319\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1788 - acc: 0.9517 - f1_m: 0.9517 - precision_m: 0.9517 - recall_m: 0.9517 - val_loss: 0.3483 - val_acc: 0.8494 - val_f1_m: 0.8494 - val_precision_m: 0.8494 - val_recall_m: 0.8494\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1245 - acc: 0.9719 - f1_m: 0.9719 - precision_m: 0.9719 - recall_m: 0.9719 - val_loss: 0.3316 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0868 - acc: 0.9805 - f1_m: 0.9805 - precision_m: 0.9805 - recall_m: 0.9805 - val_loss: 0.3335 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0636 - acc: 0.9873 - f1_m: 0.9873 - precision_m: 0.9873 - recall_m: 0.9873 - val_loss: 0.3379 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0495 - acc: 0.9897 - f1_m: 0.9897 - precision_m: 0.9897 - recall_m: 0.9897 - val_loss: 0.3404 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0392 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.3486 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0321 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.3559 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0272 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.3602 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0235 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3688 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0208 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3895 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0181 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3870 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0177 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4130 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0159 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3990 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0160 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4180 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0146 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4373 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0138 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4264 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0135 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4422 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0130 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4385 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0126 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4498 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0121 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4585 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0111 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4578 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0109 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4734 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0111 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4657 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0112 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4832 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0103 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4843 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0108 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4869 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0107 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4902 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0109 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4998 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0109 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4961 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0099 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5014 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0101 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5078 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0104 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5137 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0104 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5188 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0100 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5082 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0097 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5289 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0096 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5163 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0101 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5348 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0104 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5299 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0096 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5423 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0095 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5399 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0094 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5367 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0099 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5605 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0101 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5482 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "4001/4001 [==============================] - 0s 71us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/ed7m70kr\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 2s 169us/step - loss: 0.6830 - acc: 0.5681 - f1_m: 0.5681 - precision_m: 0.5681 - recall_m: 0.5681 - val_loss: 0.6677 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.6715 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6611 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6575 - acc: 0.6081 - f1_m: 0.6081 - precision_m: 0.6081 - recall_m: 0.6081 - val_loss: 0.6489 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6377 - acc: 0.6137 - f1_m: 0.6137 - precision_m: 0.6137 - recall_m: 0.6137 - val_loss: 0.6255 - val_acc: 0.6138 - val_f1_m: 0.6137 - val_precision_m: 0.6138 - val_recall_m: 0.6138\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.6032 - acc: 0.6544 - f1_m: 0.6544 - precision_m: 0.6544 - recall_m: 0.6544 - val_loss: 0.5908 - val_acc: 0.6816 - val_f1_m: 0.6816 - val_precision_m: 0.6816 - val_recall_m: 0.6816\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.5561 - acc: 0.7234 - f1_m: 0.7234 - precision_m: 0.7234 - recall_m: 0.7234 - val_loss: 0.5462 - val_acc: 0.7331 - val_f1_m: 0.7331 - val_precision_m: 0.7331 - val_recall_m: 0.7331\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.4981 - acc: 0.7800 - f1_m: 0.7800 - precision_m: 0.7800 - recall_m: 0.7800 - val_loss: 0.5038 - val_acc: 0.7681 - val_f1_m: 0.7681 - val_precision_m: 0.7681 - val_recall_m: 0.7681\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.4356 - acc: 0.8235 - f1_m: 0.8235 - precision_m: 0.8235 - recall_m: 0.8235 - val_loss: 0.4627 - val_acc: 0.7887 - val_f1_m: 0.7887 - val_precision_m: 0.7887 - val_recall_m: 0.7887\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.3783 - acc: 0.8602 - f1_m: 0.8602 - precision_m: 0.8602 - recall_m: 0.8602 - val_loss: 0.4277 - val_acc: 0.8094 - val_f1_m: 0.8094 - val_precision_m: 0.8094 - val_recall_m: 0.8094\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.3163 - acc: 0.8930 - f1_m: 0.8930 - precision_m: 0.8930 - recall_m: 0.8930 - val_loss: 0.3962 - val_acc: 0.8247 - val_f1_m: 0.8247 - val_precision_m: 0.8247 - val_recall_m: 0.8247\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.2619 - acc: 0.9208 - f1_m: 0.9208 - precision_m: 0.9208 - recall_m: 0.9208 - val_loss: 0.3725 - val_acc: 0.8341 - val_f1_m: 0.8341 - val_precision_m: 0.8341 - val_recall_m: 0.8341\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.2121 - acc: 0.9388 - f1_m: 0.9388 - precision_m: 0.9388 - recall_m: 0.9388 - val_loss: 0.3521 - val_acc: 0.8444 - val_f1_m: 0.8444 - val_precision_m: 0.8444 - val_recall_m: 0.8444\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1739 - acc: 0.9543 - f1_m: 0.9543 - precision_m: 0.9543 - recall_m: 0.9543 - val_loss: 0.3408 - val_acc: 0.8484 - val_f1_m: 0.8484 - val_precision_m: 0.8484 - val_recall_m: 0.8484\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.1460 - acc: 0.9630 - f1_m: 0.9630 - precision_m: 0.9630 - recall_m: 0.9630 - val_loss: 0.3377 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.1187 - acc: 0.9740 - f1_m: 0.9740 - precision_m: 0.9740 - recall_m: 0.9740 - val_loss: 0.3342 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.1015 - acc: 0.9779 - f1_m: 0.9779 - precision_m: 0.9779 - recall_m: 0.9779 - val_loss: 0.3340 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0842 - acc: 0.9831 - f1_m: 0.9831 - precision_m: 0.9831 - recall_m: 0.9831 - val_loss: 0.3454 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0718 - acc: 0.9853 - f1_m: 0.9853 - precision_m: 0.9853 - recall_m: 0.9853 - val_loss: 0.3478 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0625 - acc: 0.9881 - f1_m: 0.9881 - precision_m: 0.9881 - recall_m: 0.9881 - val_loss: 0.3545 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0552 - acc: 0.9888 - f1_m: 0.9887 - precision_m: 0.9888 - recall_m: 0.9888 - val_loss: 0.3633 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0507 - acc: 0.9888 - f1_m: 0.9888 - precision_m: 0.9888 - recall_m: 0.9888 - val_loss: 0.3720 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0435 - acc: 0.9915 - f1_m: 0.9915 - precision_m: 0.9915 - recall_m: 0.9915 - val_loss: 0.3766 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0404 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.3922 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0376 - acc: 0.9917 - f1_m: 0.9917 - precision_m: 0.9917 - recall_m: 0.9917 - val_loss: 0.3924 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0356 - acc: 0.9918 - f1_m: 0.9918 - precision_m: 0.9918 - recall_m: 0.9918 - val_loss: 0.4057 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0316 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.4074 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0311 - acc: 0.9926 - f1_m: 0.9926 - precision_m: 0.9926 - recall_m: 0.9926 - val_loss: 0.4244 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0292 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.4318 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0267 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.4375 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0248 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4394 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0250 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.4551 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0229 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4613 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0221 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4721 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0225 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.4748 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0212 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4783 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0200 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.4887 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0200 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4990 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0198 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.5085 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0186 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.5212 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0192 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.5112 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0185 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5315 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0174 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5399 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0171 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5356 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0167 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5498 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0159 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5540 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0165 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.5610 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0158 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5642 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0153 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5839 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0160 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.5760 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0154 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5862 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "4001/4001 [==============================] - 0s 67us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/j4u1yc3i\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 2s 194us/step - loss: 0.6740 - acc: 0.5916 - f1_m: 0.5916 - precision_m: 0.5916 - recall_m: 0.5916 - val_loss: 0.6591 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.6456 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6322 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5976 - acc: 0.6213 - f1_m: 0.6213 - precision_m: 0.6213 - recall_m: 0.6213 - val_loss: 0.5802 - val_acc: 0.6878 - val_f1_m: 0.6878 - val_precision_m: 0.6878 - val_recall_m: 0.6878\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.5168 - acc: 0.7622 - f1_m: 0.7622 - precision_m: 0.7622 - recall_m: 0.7622 - val_loss: 0.5168 - val_acc: 0.7738 - val_f1_m: 0.7737 - val_precision_m: 0.7738 - val_recall_m: 0.7738\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.4236 - acc: 0.8542 - f1_m: 0.8542 - precision_m: 0.8542 - recall_m: 0.8542 - val_loss: 0.4546 - val_acc: 0.8022 - val_f1_m: 0.8022 - val_precision_m: 0.8022 - val_recall_m: 0.8022\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.3244 - acc: 0.9035 - f1_m: 0.9035 - precision_m: 0.9035 - recall_m: 0.9035 - val_loss: 0.4003 - val_acc: 0.8184 - val_f1_m: 0.8184 - val_precision_m: 0.8184 - val_recall_m: 0.8184\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2349 - acc: 0.9351 - f1_m: 0.9351 - precision_m: 0.9351 - recall_m: 0.9351 - val_loss: 0.3677 - val_acc: 0.8322 - val_f1_m: 0.8322 - val_precision_m: 0.8322 - val_recall_m: 0.8322\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1679 - acc: 0.9562 - f1_m: 0.9562 - precision_m: 0.9562 - recall_m: 0.9562 - val_loss: 0.3409 - val_acc: 0.8484 - val_f1_m: 0.8484 - val_precision_m: 0.8484 - val_recall_m: 0.8484\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1172 - acc: 0.9741 - f1_m: 0.9741 - precision_m: 0.9741 - recall_m: 0.9741 - val_loss: 0.3292 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0866 - acc: 0.9816 - f1_m: 0.9816 - precision_m: 0.9816 - recall_m: 0.9816 - val_loss: 0.3220 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0638 - acc: 0.9879 - f1_m: 0.9879 - precision_m: 0.9879 - recall_m: 0.9879 - val_loss: 0.3236 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0498 - acc: 0.9903 - f1_m: 0.9903 - precision_m: 0.9903 - recall_m: 0.9903 - val_loss: 0.3348 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0395 - acc: 0.9924 - f1_m: 0.9924 - precision_m: 0.9924 - recall_m: 0.9924 - val_loss: 0.3423 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0326 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3493 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0277 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.3515 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0243 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3766 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0219 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3700 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0190 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.3935 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0174 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3901 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0168 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.3992 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0151 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4198 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0145 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4167 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0133 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4308 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0133 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4369 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0127 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4533 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0116 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4337 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0116 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4705 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0110 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4583 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0112 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4664 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0113 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4737 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0101 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4832 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0110 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4809 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0104 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4787 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5144 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0102 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4969 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0099 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5027 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0099 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4974 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0103 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5265 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0101 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5115 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0101 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5086 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0101 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5229 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0095 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5291 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0101 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5347 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0097 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5265 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0098 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5299 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0101 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5546 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0098 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5234 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0091 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5380 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0093 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5499 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0090 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5508 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "4001/4001 [==============================] - 0s 71us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/osylebjs\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 2s 180us/step - loss: 0.6843 - acc: 0.5649 - f1_m: 0.5644 - precision_m: 0.5651 - recall_m: 0.5638 - val_loss: 0.6701 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6730 - acc: 0.6070 - f1_m: 0.6070 - precision_m: 0.6070 - recall_m: 0.6070 - val_loss: 0.6643 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6634 - acc: 0.6071 - f1_m: 0.6071 - precision_m: 0.6071 - recall_m: 0.6071 - val_loss: 0.6572 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6538 - acc: 0.6080 - f1_m: 0.6080 - precision_m: 0.6080 - recall_m: 0.6080 - val_loss: 0.6452 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6355 - acc: 0.6167 - f1_m: 0.6167 - precision_m: 0.6167 - recall_m: 0.6167 - val_loss: 0.6272 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6115 - acc: 0.6338 - f1_m: 0.6338 - precision_m: 0.6338 - recall_m: 0.6338 - val_loss: 0.6013 - val_acc: 0.6309 - val_f1_m: 0.6309 - val_precision_m: 0.6309 - val_recall_m: 0.6309\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.5773 - acc: 0.6749 - f1_m: 0.6749 - precision_m: 0.6749 - recall_m: 0.6749 - val_loss: 0.5681 - val_acc: 0.6925 - val_f1_m: 0.6925 - val_precision_m: 0.6925 - val_recall_m: 0.6925\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.5402 - acc: 0.7000 - f1_m: 0.7000 - precision_m: 0.7000 - recall_m: 0.7000 - val_loss: 0.5343 - val_acc: 0.7506 - val_f1_m: 0.7506 - val_precision_m: 0.7506 - val_recall_m: 0.7506\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.4938 - acc: 0.7342 - f1_m: 0.7342 - precision_m: 0.7342 - recall_m: 0.7342 - val_loss: 0.4997 - val_acc: 0.7781 - val_f1_m: 0.7781 - val_precision_m: 0.7781 - val_recall_m: 0.7781\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.4531 - acc: 0.7655 - f1_m: 0.7655 - precision_m: 0.7655 - recall_m: 0.7655 - val_loss: 0.4687 - val_acc: 0.7978 - val_f1_m: 0.7978 - val_precision_m: 0.7978 - val_recall_m: 0.7978\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.4093 - acc: 0.7905 - f1_m: 0.7905 - precision_m: 0.7905 - recall_m: 0.7905 - val_loss: 0.4406 - val_acc: 0.8141 - val_f1_m: 0.8141 - val_precision_m: 0.8141 - val_recall_m: 0.8141\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.3675 - acc: 0.8474 - f1_m: 0.8474 - precision_m: 0.8474 - recall_m: 0.8474 - val_loss: 0.4149 - val_acc: 0.8309 - val_f1_m: 0.8309 - val_precision_m: 0.8309 - val_recall_m: 0.8309\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.3241 - acc: 0.8845 - f1_m: 0.8845 - precision_m: 0.8845 - recall_m: 0.8845 - val_loss: 0.3926 - val_acc: 0.8444 - val_f1_m: 0.8444 - val_precision_m: 0.8444 - val_recall_m: 0.8444\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.2923 - acc: 0.9041 - f1_m: 0.9041 - precision_m: 0.9041 - recall_m: 0.9041 - val_loss: 0.3754 - val_acc: 0.8497 - val_f1_m: 0.8497 - val_precision_m: 0.8497 - val_recall_m: 0.8497\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.2563 - acc: 0.9274 - f1_m: 0.9274 - precision_m: 0.9274 - recall_m: 0.9274 - val_loss: 0.3589 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.2335 - acc: 0.9323 - f1_m: 0.9323 - precision_m: 0.9323 - recall_m: 0.9323 - val_loss: 0.3484 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.2072 - acc: 0.9458 - f1_m: 0.9458 - precision_m: 0.9458 - recall_m: 0.9458 - val_loss: 0.3406 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1896 - acc: 0.9489 - f1_m: 0.9489 - precision_m: 0.9489 - recall_m: 0.9489 - val_loss: 0.3364 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1719 - acc: 0.9586 - f1_m: 0.9586 - precision_m: 0.9586 - recall_m: 0.9586 - val_loss: 0.3321 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.1573 - acc: 0.9608 - f1_m: 0.9608 - precision_m: 0.9608 - recall_m: 0.9608 - val_loss: 0.3329 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.1438 - acc: 0.9657 - f1_m: 0.9657 - precision_m: 0.9657 - recall_m: 0.9657 - val_loss: 0.3343 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.1276 - acc: 0.9718 - f1_m: 0.9718 - precision_m: 0.9718 - recall_m: 0.9718 - val_loss: 0.3317 - val_acc: 0.8794 - val_f1_m: 0.8794 - val_precision_m: 0.8794 - val_recall_m: 0.8794\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1213 - acc: 0.9716 - f1_m: 0.9716 - precision_m: 0.9716 - recall_m: 0.9716 - val_loss: 0.3399 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.1120 - acc: 0.9751 - f1_m: 0.9751 - precision_m: 0.9751 - recall_m: 0.9751 - val_loss: 0.3436 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1053 - acc: 0.9760 - f1_m: 0.9760 - precision_m: 0.9760 - recall_m: 0.9760 - val_loss: 0.3486 - val_acc: 0.8794 - val_f1_m: 0.8794 - val_precision_m: 0.8794 - val_recall_m: 0.8794\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.1025 - acc: 0.9769 - f1_m: 0.9769 - precision_m: 0.9769 - recall_m: 0.9769 - val_loss: 0.3565 - val_acc: 0.8791 - val_f1_m: 0.8791 - val_precision_m: 0.8791 - val_recall_m: 0.8791\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0955 - acc: 0.9775 - f1_m: 0.9775 - precision_m: 0.9775 - recall_m: 0.9775 - val_loss: 0.3623 - val_acc: 0.8794 - val_f1_m: 0.8794 - val_precision_m: 0.8794 - val_recall_m: 0.8794\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0903 - acc: 0.9788 - f1_m: 0.9788 - precision_m: 0.9788 - recall_m: 0.9788 - val_loss: 0.3709 - val_acc: 0.8809 - val_f1_m: 0.8809 - val_precision_m: 0.8809 - val_recall_m: 0.8809\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0907 - acc: 0.9769 - f1_m: 0.9769 - precision_m: 0.9769 - recall_m: 0.9769 - val_loss: 0.3774 - val_acc: 0.8794 - val_f1_m: 0.8794 - val_precision_m: 0.8794 - val_recall_m: 0.8794\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0830 - acc: 0.9791 - f1_m: 0.9791 - precision_m: 0.9791 - recall_m: 0.9791 - val_loss: 0.3794 - val_acc: 0.8797 - val_f1_m: 0.8797 - val_precision_m: 0.8797 - val_recall_m: 0.8797\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0828 - acc: 0.9816 - f1_m: 0.9816 - precision_m: 0.9816 - recall_m: 0.9816 - val_loss: 0.3909 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0785 - acc: 0.9809 - f1_m: 0.9809 - precision_m: 0.9809 - recall_m: 0.9809 - val_loss: 0.3994 - val_acc: 0.8784 - val_f1_m: 0.8784 - val_precision_m: 0.8784 - val_recall_m: 0.8784\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0782 - acc: 0.9820 - f1_m: 0.9820 - precision_m: 0.9820 - recall_m: 0.9820 - val_loss: 0.4067 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0746 - acc: 0.9817 - f1_m: 0.9817 - precision_m: 0.9817 - recall_m: 0.9817 - val_loss: 0.4156 - val_acc: 0.8791 - val_f1_m: 0.8791 - val_precision_m: 0.8791 - val_recall_m: 0.8791\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0728 - acc: 0.9825 - f1_m: 0.9825 - precision_m: 0.9825 - recall_m: 0.9825 - val_loss: 0.4243 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0679 - acc: 0.9852 - f1_m: 0.9852 - precision_m: 0.9852 - recall_m: 0.9852 - val_loss: 0.4289 - val_acc: 0.8800 - val_f1_m: 0.8800 - val_precision_m: 0.8800 - val_recall_m: 0.8800\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0646 - acc: 0.9828 - f1_m: 0.9828 - precision_m: 0.9828 - recall_m: 0.9828 - val_loss: 0.4346 - val_acc: 0.8825 - val_f1_m: 0.8825 - val_precision_m: 0.8825 - val_recall_m: 0.8825\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0658 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - val_loss: 0.4437 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0623 - acc: 0.9838 - f1_m: 0.9838 - precision_m: 0.9838 - recall_m: 0.9838 - val_loss: 0.4544 - val_acc: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0597 - acc: 0.9835 - f1_m: 0.9835 - precision_m: 0.9835 - recall_m: 0.9835 - val_loss: 0.4575 - val_acc: 0.8794 - val_f1_m: 0.8794 - val_precision_m: 0.8794 - val_recall_m: 0.8794\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0589 - acc: 0.9833 - f1_m: 0.9833 - precision_m: 0.9833 - recall_m: 0.9833 - val_loss: 0.4718 - val_acc: 0.8794 - val_f1_m: 0.8794 - val_precision_m: 0.8794 - val_recall_m: 0.8794\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0549 - acc: 0.9866 - f1_m: 0.9866 - precision_m: 0.9866 - recall_m: 0.9866 - val_loss: 0.4780 - val_acc: 0.8788 - val_f1_m: 0.8787 - val_precision_m: 0.8788 - val_recall_m: 0.8788\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0546 - acc: 0.9856 - f1_m: 0.9856 - precision_m: 0.9856 - recall_m: 0.9856 - val_loss: 0.4904 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0554 - acc: 0.9834 - f1_m: 0.9834 - precision_m: 0.9834 - recall_m: 0.9834 - val_loss: 0.4947 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0525 - acc: 0.9848 - f1_m: 0.9848 - precision_m: 0.9848 - recall_m: 0.9848 - val_loss: 0.5065 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0503 - acc: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865 - val_loss: 0.5073 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0493 - acc: 0.9851 - f1_m: 0.9851 - precision_m: 0.9851 - recall_m: 0.9851 - val_loss: 0.5212 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0494 - acc: 0.9822 - f1_m: 0.9822 - precision_m: 0.9822 - recall_m: 0.9822 - val_loss: 0.5311 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0465 - acc: 0.9847 - f1_m: 0.9847 - precision_m: 0.9847 - recall_m: 0.9847 - val_loss: 0.5403 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0453 - acc: 0.9860 - f1_m: 0.9860 - precision_m: 0.9860 - recall_m: 0.9860 - val_loss: 0.5494 - val_acc: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
            "4001/4001 [==============================] - 0s 68us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/ww5xl0eh\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 3s 199us/step - loss: 0.6852 - acc: 0.5772 - f1_m: 0.5772 - precision_m: 0.5772 - recall_m: 0.5772 - val_loss: 0.6683 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6700 - acc: 0.6069 - f1_m: 0.6069 - precision_m: 0.6069 - recall_m: 0.6069 - val_loss: 0.6612 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6569 - acc: 0.6072 - f1_m: 0.6072 - precision_m: 0.6072 - recall_m: 0.6072 - val_loss: 0.6459 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.6341 - acc: 0.6104 - f1_m: 0.6104 - precision_m: 0.6104 - recall_m: 0.6104 - val_loss: 0.6208 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5990 - acc: 0.6313 - f1_m: 0.6313 - precision_m: 0.6313 - recall_m: 0.6313 - val_loss: 0.5854 - val_acc: 0.6356 - val_f1_m: 0.6356 - val_precision_m: 0.6356 - val_recall_m: 0.6356\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5527 - acc: 0.6717 - f1_m: 0.6717 - precision_m: 0.6717 - recall_m: 0.6717 - val_loss: 0.5435 - val_acc: 0.7266 - val_f1_m: 0.7266 - val_precision_m: 0.7266 - val_recall_m: 0.7266\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.5007 - acc: 0.7077 - f1_m: 0.7077 - precision_m: 0.7077 - recall_m: 0.7077 - val_loss: 0.5039 - val_acc: 0.7656 - val_f1_m: 0.7656 - val_precision_m: 0.7656 - val_recall_m: 0.7656\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.4476 - acc: 0.7660 - f1_m: 0.7660 - precision_m: 0.7660 - recall_m: 0.7660 - val_loss: 0.4667 - val_acc: 0.7956 - val_f1_m: 0.7956 - val_precision_m: 0.7956 - val_recall_m: 0.7956\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3900 - acc: 0.8502 - f1_m: 0.8502 - precision_m: 0.8502 - recall_m: 0.8502 - val_loss: 0.4316 - val_acc: 0.8228 - val_f1_m: 0.8228 - val_precision_m: 0.8228 - val_recall_m: 0.8228\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3334 - acc: 0.8932 - f1_m: 0.8932 - precision_m: 0.8932 - recall_m: 0.8932 - val_loss: 0.3982 - val_acc: 0.8375 - val_f1_m: 0.8375 - val_precision_m: 0.8375 - val_recall_m: 0.8375\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2892 - acc: 0.9171 - f1_m: 0.9171 - precision_m: 0.9171 - recall_m: 0.9171 - val_loss: 0.3718 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2345 - acc: 0.9413 - f1_m: 0.9412 - precision_m: 0.9413 - recall_m: 0.9413 - val_loss: 0.3471 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2008 - acc: 0.9486 - f1_m: 0.9486 - precision_m: 0.9486 - recall_m: 0.9486 - val_loss: 0.3335 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1669 - acc: 0.9634 - f1_m: 0.9634 - precision_m: 0.9634 - recall_m: 0.9634 - val_loss: 0.3264 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1413 - acc: 0.9699 - f1_m: 0.9699 - precision_m: 0.9699 - recall_m: 0.9699 - val_loss: 0.3247 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1189 - acc: 0.9742 - f1_m: 0.9742 - precision_m: 0.9742 - recall_m: 0.9742 - val_loss: 0.3235 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1033 - acc: 0.9803 - f1_m: 0.9803 - precision_m: 0.9803 - recall_m: 0.9803 - val_loss: 0.3268 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0865 - acc: 0.9840 - f1_m: 0.9840 - precision_m: 0.9840 - recall_m: 0.9840 - val_loss: 0.3359 - val_acc: 0.8784 - val_f1_m: 0.8784 - val_precision_m: 0.8784 - val_recall_m: 0.8784\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0756 - acc: 0.9855 - f1_m: 0.9855 - precision_m: 0.9855 - recall_m: 0.9855 - val_loss: 0.3461 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0681 - acc: 0.9860 - f1_m: 0.9860 - precision_m: 0.9860 - recall_m: 0.9860 - val_loss: 0.3587 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0590 - acc: 0.9888 - f1_m: 0.9887 - precision_m: 0.9888 - recall_m: 0.9888 - val_loss: 0.3686 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0496 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.3884 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0460 - acc: 0.9915 - f1_m: 0.9915 - precision_m: 0.9915 - recall_m: 0.9915 - val_loss: 0.3976 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0410 - acc: 0.9915 - f1_m: 0.9915 - precision_m: 0.9915 - recall_m: 0.9915 - val_loss: 0.4083 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0406 - acc: 0.9915 - f1_m: 0.9915 - precision_m: 0.9915 - recall_m: 0.9915 - val_loss: 0.4182 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0363 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.4321 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0343 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.4422 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0314 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.4688 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0309 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.4701 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0279 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.4849 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0279 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.4879 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0278 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.4978 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0252 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.5145 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0255 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.5067 - val_acc: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0253 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.5319 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0231 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.5286 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0240 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.5458 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0219 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.5548 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0214 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.5729 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0199 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.5715 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0213 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.5765 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0192 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.5946 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0189 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.5958 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0199 - acc: 0.9938 - f1_m: 0.9938 - precision_m: 0.9938 - recall_m: 0.9938 - val_loss: 0.6029 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0194 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.6198 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0179 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.6110 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0173 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.6319 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0175 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.6386 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0169 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.6481 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0158 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.6709 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "4001/4001 [==============================] - 0s 68us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/78astqt5\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 3s 206us/step - loss: 0.6797 - acc: 0.5802 - f1_m: 0.5802 - precision_m: 0.5802 - recall_m: 0.5802 - val_loss: 0.6664 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6619 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6529 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6387 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6294 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5982 - acc: 0.6194 - f1_m: 0.6194 - precision_m: 0.6194 - recall_m: 0.6194 - val_loss: 0.5871 - val_acc: 0.6606 - val_f1_m: 0.6606 - val_precision_m: 0.6606 - val_recall_m: 0.6606\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5351 - acc: 0.7268 - f1_m: 0.7268 - precision_m: 0.7268 - recall_m: 0.7268 - val_loss: 0.5345 - val_acc: 0.7450 - val_f1_m: 0.7450 - val_precision_m: 0.7450 - val_recall_m: 0.7450\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.4609 - acc: 0.7946 - f1_m: 0.7946 - precision_m: 0.7946 - recall_m: 0.7946 - val_loss: 0.4826 - val_acc: 0.7837 - val_f1_m: 0.7837 - val_precision_m: 0.7837 - val_recall_m: 0.7837\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3780 - acc: 0.8738 - f1_m: 0.8737 - precision_m: 0.8738 - recall_m: 0.8738 - val_loss: 0.4276 - val_acc: 0.8134 - val_f1_m: 0.8134 - val_precision_m: 0.8134 - val_recall_m: 0.8134\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2932 - acc: 0.9073 - f1_m: 0.9073 - precision_m: 0.9073 - recall_m: 0.9073 - val_loss: 0.3821 - val_acc: 0.8287 - val_f1_m: 0.8287 - val_precision_m: 0.8287 - val_recall_m: 0.8287\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2194 - acc: 0.9370 - f1_m: 0.9370 - precision_m: 0.9370 - recall_m: 0.9370 - val_loss: 0.3578 - val_acc: 0.8375 - val_f1_m: 0.8375 - val_precision_m: 0.8375 - val_recall_m: 0.8375\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1642 - acc: 0.9578 - f1_m: 0.9578 - precision_m: 0.9578 - recall_m: 0.9578 - val_loss: 0.3405 - val_acc: 0.8491 - val_f1_m: 0.8491 - val_precision_m: 0.8491 - val_recall_m: 0.8491\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1208 - acc: 0.9712 - f1_m: 0.9712 - precision_m: 0.9712 - recall_m: 0.9712 - val_loss: 0.3316 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0919 - acc: 0.9787 - f1_m: 0.9787 - precision_m: 0.9787 - recall_m: 0.9787 - val_loss: 0.3231 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0716 - acc: 0.9848 - f1_m: 0.9848 - precision_m: 0.9848 - recall_m: 0.9848 - val_loss: 0.3295 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0573 - acc: 0.9883 - f1_m: 0.9883 - precision_m: 0.9883 - recall_m: 0.9883 - val_loss: 0.3311 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0465 - acc: 0.9917 - f1_m: 0.9917 - precision_m: 0.9917 - recall_m: 0.9917 - val_loss: 0.3428 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0404 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.3513 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0346 - acc: 0.9929 - f1_m: 0.9929 - precision_m: 0.9929 - recall_m: 0.9929 - val_loss: 0.3595 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0298 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3703 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0270 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.3801 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0242 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3774 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0223 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4032 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0201 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3955 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0188 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4100 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0186 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4218 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0171 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4188 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0161 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4318 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0149 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4354 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0150 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4461 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0140 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4413 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0144 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4558 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0129 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4638 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0138 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4732 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0132 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4718 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0128 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4885 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0128 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4952 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0117 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4917 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0113 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4985 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0120 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5115 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0112 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5094 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0110 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5112 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0110 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5306 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0111 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5186 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0108 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5307 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0108 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5302 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0110 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5305 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0108 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5512 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0108 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5534 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0103 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5464 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0105 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5562 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0097 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5655 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "4001/4001 [==============================] - 0s 70us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/4v4wszkq\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 3s 217us/step - loss: 0.6797 - acc: 0.5760 - f1_m: 0.5760 - precision_m: 0.5760 - recall_m: 0.5760 - val_loss: 0.6639 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.6550 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6435 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6220 - acc: 0.6080 - f1_m: 0.6080 - precision_m: 0.6080 - recall_m: 0.6080 - val_loss: 0.6092 - val_acc: 0.6159 - val_f1_m: 0.6159 - val_precision_m: 0.6159 - val_recall_m: 0.6159\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.5684 - acc: 0.6523 - f1_m: 0.6523 - precision_m: 0.6523 - recall_m: 0.6523 - val_loss: 0.5577 - val_acc: 0.7169 - val_f1_m: 0.7169 - val_precision_m: 0.7169 - val_recall_m: 0.7169\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.4904 - acc: 0.7978 - f1_m: 0.7978 - precision_m: 0.7978 - recall_m: 0.7978 - val_loss: 0.4956 - val_acc: 0.7753 - val_f1_m: 0.7753 - val_precision_m: 0.7753 - val_recall_m: 0.7753\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4017 - acc: 0.8577 - f1_m: 0.8577 - precision_m: 0.8577 - recall_m: 0.8577 - val_loss: 0.4414 - val_acc: 0.8059 - val_f1_m: 0.8059 - val_precision_m: 0.8059 - val_recall_m: 0.8059\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3199 - acc: 0.8945 - f1_m: 0.8945 - precision_m: 0.8945 - recall_m: 0.8945 - val_loss: 0.3981 - val_acc: 0.8216 - val_f1_m: 0.8216 - val_precision_m: 0.8216 - val_recall_m: 0.8216\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.2430 - acc: 0.9309 - f1_m: 0.9309 - precision_m: 0.9309 - recall_m: 0.9309 - val_loss: 0.3646 - val_acc: 0.8337 - val_f1_m: 0.8337 - val_precision_m: 0.8337 - val_recall_m: 0.8337\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1779 - acc: 0.9548 - f1_m: 0.9548 - precision_m: 0.9548 - recall_m: 0.9548 - val_loss: 0.3434 - val_acc: 0.8450 - val_f1_m: 0.8450 - val_precision_m: 0.8450 - val_recall_m: 0.8450\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1335 - acc: 0.9678 - f1_m: 0.9678 - precision_m: 0.9678 - recall_m: 0.9678 - val_loss: 0.3279 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1000 - acc: 0.9773 - f1_m: 0.9773 - precision_m: 0.9773 - recall_m: 0.9773 - val_loss: 0.3285 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0761 - acc: 0.9843 - f1_m: 0.9843 - precision_m: 0.9843 - recall_m: 0.9843 - val_loss: 0.3282 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0609 - acc: 0.9884 - f1_m: 0.9884 - precision_m: 0.9884 - recall_m: 0.9884 - val_loss: 0.3263 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0498 - acc: 0.9897 - f1_m: 0.9897 - precision_m: 0.9897 - recall_m: 0.9897 - val_loss: 0.3384 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0406 - acc: 0.9911 - f1_m: 0.9911 - precision_m: 0.9911 - recall_m: 0.9911 - val_loss: 0.3601 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0333 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3559 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0278 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.3653 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0247 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3788 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0227 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3760 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0209 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.3997 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0191 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4032 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0172 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4143 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0169 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4138 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0154 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4236 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0141 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4390 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0142 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4480 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0141 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4539 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0126 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4535 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0125 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4628 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0123 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4731 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0117 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4807 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0120 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4800 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0114 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4916 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0120 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4969 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0112 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4859 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0114 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5250 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0115 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5068 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0102 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5208 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0107 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5240 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0105 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5305 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0103 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5256 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0094 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5372 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0104 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5362 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0101 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5426 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0103 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5545 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0102 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5522 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0105 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5537 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0096 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5537 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0100 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5784 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0093 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5618 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "4001/4001 [==============================] - 0s 72us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/yxyren1d\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 3s 213us/step - loss: 0.6776 - acc: 0.5811 - f1_m: 0.5811 - precision_m: 0.5811 - recall_m: 0.5811 - val_loss: 0.6638 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.6547 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6468 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6266 - acc: 0.6182 - f1_m: 0.6182 - precision_m: 0.6182 - recall_m: 0.6182 - val_loss: 0.6161 - val_acc: 0.6372 - val_f1_m: 0.6372 - val_precision_m: 0.6372 - val_recall_m: 0.6372\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.5736 - acc: 0.6997 - f1_m: 0.6997 - precision_m: 0.6997 - recall_m: 0.6997 - val_loss: 0.5669 - val_acc: 0.7284 - val_f1_m: 0.7284 - val_precision_m: 0.7284 - val_recall_m: 0.7284\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.4992 - acc: 0.8134 - f1_m: 0.8134 - precision_m: 0.8134 - recall_m: 0.8134 - val_loss: 0.5079 - val_acc: 0.7691 - val_f1_m: 0.7691 - val_precision_m: 0.7691 - val_recall_m: 0.7691\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.4102 - acc: 0.8612 - f1_m: 0.8612 - precision_m: 0.8612 - recall_m: 0.8612 - val_loss: 0.4578 - val_acc: 0.7906 - val_f1_m: 0.7906 - val_precision_m: 0.7906 - val_recall_m: 0.7906\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3283 - acc: 0.8935 - f1_m: 0.8935 - precision_m: 0.8935 - recall_m: 0.8935 - val_loss: 0.4164 - val_acc: 0.8053 - val_f1_m: 0.8053 - val_precision_m: 0.8053 - val_recall_m: 0.8053\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2539 - acc: 0.9259 - f1_m: 0.9259 - precision_m: 0.9259 - recall_m: 0.9259 - val_loss: 0.3841 - val_acc: 0.8247 - val_f1_m: 0.8247 - val_precision_m: 0.8247 - val_recall_m: 0.8247\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1885 - acc: 0.9496 - f1_m: 0.9496 - precision_m: 0.9496 - recall_m: 0.9496 - val_loss: 0.3619 - val_acc: 0.8328 - val_f1_m: 0.8328 - val_precision_m: 0.8328 - val_recall_m: 0.8328\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1410 - acc: 0.9650 - f1_m: 0.9650 - precision_m: 0.9650 - recall_m: 0.9650 - val_loss: 0.3408 - val_acc: 0.8481 - val_f1_m: 0.8481 - val_precision_m: 0.8481 - val_recall_m: 0.8481\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1043 - acc: 0.9767 - f1_m: 0.9767 - precision_m: 0.9767 - recall_m: 0.9767 - val_loss: 0.3303 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0793 - acc: 0.9834 - f1_m: 0.9834 - precision_m: 0.9834 - recall_m: 0.9834 - val_loss: 0.3335 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0620 - acc: 0.9876 - f1_m: 0.9876 - precision_m: 0.9876 - recall_m: 0.9876 - val_loss: 0.3311 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0495 - acc: 0.9897 - f1_m: 0.9897 - precision_m: 0.9897 - recall_m: 0.9897 - val_loss: 0.3348 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0406 - acc: 0.9917 - f1_m: 0.9917 - precision_m: 0.9917 - recall_m: 0.9917 - val_loss: 0.3370 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0336 - acc: 0.9928 - f1_m: 0.9928 - precision_m: 0.9928 - recall_m: 0.9928 - val_loss: 0.3438 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0287 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3468 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0253 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3606 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0227 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3579 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0211 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3735 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0191 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3742 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0179 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3785 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0169 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3869 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0153 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3951 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0153 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.3934 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0143 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4025 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0141 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4049 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0142 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4128 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0126 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4114 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0136 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4256 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0127 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4179 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0123 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4294 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0117 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4322 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0114 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4367 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0119 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4362 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0108 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.4410 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0112 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4457 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0106 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4489 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0109 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4514 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0108 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4565 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0111 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4597 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0109 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4656 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0109 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4577 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0104 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4660 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0113 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4741 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4741 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0104 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4737 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0110 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4755 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0105 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4810 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0104 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4834 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "4001/4001 [==============================] - 0s 70us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/7z0k2f3r\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 3s 204us/step - loss: 0.6829 - acc: 0.6030 - f1_m: 0.6030 - precision_m: 0.6030 - recall_m: 0.6030 - val_loss: 0.6732 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.6694 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6644 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.6611 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6570 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.6490 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6439 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.6274 - acc: 0.6075 - f1_m: 0.6075 - precision_m: 0.6075 - recall_m: 0.6075 - val_loss: 0.6228 - val_acc: 0.6150 - val_f1_m: 0.6150 - val_precision_m: 0.6150 - val_recall_m: 0.6150\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.5932 - acc: 0.6345 - f1_m: 0.6345 - precision_m: 0.6345 - recall_m: 0.6345 - val_loss: 0.5928 - val_acc: 0.6678 - val_f1_m: 0.6678 - val_precision_m: 0.6678 - val_recall_m: 0.6678\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.5473 - acc: 0.7304 - f1_m: 0.7304 - precision_m: 0.7304 - recall_m: 0.7304 - val_loss: 0.5577 - val_acc: 0.7309 - val_f1_m: 0.7309 - val_precision_m: 0.7309 - val_recall_m: 0.7309\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.4943 - acc: 0.7965 - f1_m: 0.7965 - precision_m: 0.7965 - recall_m: 0.7965 - val_loss: 0.5217 - val_acc: 0.7594 - val_f1_m: 0.7594 - val_precision_m: 0.7594 - val_recall_m: 0.7594\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.4393 - acc: 0.8366 - f1_m: 0.8366 - precision_m: 0.8366 - recall_m: 0.8366 - val_loss: 0.4902 - val_acc: 0.7694 - val_f1_m: 0.7694 - val_precision_m: 0.7694 - val_recall_m: 0.7694\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.3869 - acc: 0.8609 - f1_m: 0.8609 - precision_m: 0.8609 - recall_m: 0.8609 - val_loss: 0.4642 - val_acc: 0.7794 - val_f1_m: 0.7794 - val_precision_m: 0.7794 - val_recall_m: 0.7794\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.3395 - acc: 0.8789 - f1_m: 0.8789 - precision_m: 0.8789 - recall_m: 0.8789 - val_loss: 0.4429 - val_acc: 0.7891 - val_f1_m: 0.7891 - val_precision_m: 0.7891 - val_recall_m: 0.7891\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.2982 - acc: 0.8993 - f1_m: 0.8993 - precision_m: 0.8993 - recall_m: 0.8993 - val_loss: 0.4248 - val_acc: 0.8013 - val_f1_m: 0.8012 - val_precision_m: 0.8013 - val_recall_m: 0.8013\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.2611 - acc: 0.9149 - f1_m: 0.9149 - precision_m: 0.9149 - recall_m: 0.9149 - val_loss: 0.4107 - val_acc: 0.8066 - val_f1_m: 0.8066 - val_precision_m: 0.8066 - val_recall_m: 0.8066\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.2288 - acc: 0.9278 - f1_m: 0.9278 - precision_m: 0.9278 - recall_m: 0.9278 - val_loss: 0.3982 - val_acc: 0.8153 - val_f1_m: 0.8153 - val_precision_m: 0.8153 - val_recall_m: 0.8153\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.1996 - acc: 0.9384 - f1_m: 0.9384 - precision_m: 0.9384 - recall_m: 0.9384 - val_loss: 0.3881 - val_acc: 0.8184 - val_f1_m: 0.8184 - val_precision_m: 0.8184 - val_recall_m: 0.8184\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.1768 - acc: 0.9473 - f1_m: 0.9473 - precision_m: 0.9473 - recall_m: 0.9473 - val_loss: 0.3797 - val_acc: 0.8275 - val_f1_m: 0.8275 - val_precision_m: 0.8275 - val_recall_m: 0.8275\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.1552 - acc: 0.9535 - f1_m: 0.9535 - precision_m: 0.9535 - recall_m: 0.9535 - val_loss: 0.3739 - val_acc: 0.8337 - val_f1_m: 0.8337 - val_precision_m: 0.8337 - val_recall_m: 0.8337\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.1372 - acc: 0.9612 - f1_m: 0.9612 - precision_m: 0.9612 - recall_m: 0.9612 - val_loss: 0.3695 - val_acc: 0.8394 - val_f1_m: 0.8394 - val_precision_m: 0.8394 - val_recall_m: 0.8394\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.1235 - acc: 0.9659 - f1_m: 0.9659 - precision_m: 0.9659 - recall_m: 0.9659 - val_loss: 0.3662 - val_acc: 0.8419 - val_f1_m: 0.8419 - val_precision_m: 0.8419 - val_recall_m: 0.8419\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.1101 - acc: 0.9701 - f1_m: 0.9701 - precision_m: 0.9701 - recall_m: 0.9701 - val_loss: 0.3650 - val_acc: 0.8453 - val_f1_m: 0.8453 - val_precision_m: 0.8453 - val_recall_m: 0.8453\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0985 - acc: 0.9754 - f1_m: 0.9754 - precision_m: 0.9754 - recall_m: 0.9754 - val_loss: 0.3648 - val_acc: 0.8462 - val_f1_m: 0.8462 - val_precision_m: 0.8462 - val_recall_m: 0.8462\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0888 - acc: 0.9777 - f1_m: 0.9777 - precision_m: 0.9777 - recall_m: 0.9777 - val_loss: 0.3620 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0794 - acc: 0.9820 - f1_m: 0.9820 - precision_m: 0.9820 - recall_m: 0.9820 - val_loss: 0.3644 - val_acc: 0.8497 - val_f1_m: 0.8497 - val_precision_m: 0.8497 - val_recall_m: 0.8497\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0742 - acc: 0.9817 - f1_m: 0.9817 - precision_m: 0.9817 - recall_m: 0.9817 - val_loss: 0.3651 - val_acc: 0.8503 - val_f1_m: 0.8503 - val_precision_m: 0.8503 - val_recall_m: 0.8503\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0667 - acc: 0.9835 - f1_m: 0.9835 - precision_m: 0.9835 - recall_m: 0.9835 - val_loss: 0.3709 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0619 - acc: 0.9847 - f1_m: 0.9847 - precision_m: 0.9847 - recall_m: 0.9847 - val_loss: 0.3690 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0561 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 0.3784 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0524 - acc: 0.9879 - f1_m: 0.9879 - precision_m: 0.9879 - recall_m: 0.9879 - val_loss: 0.3771 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0475 - acc: 0.9895 - f1_m: 0.9895 - precision_m: 0.9895 - recall_m: 0.9895 - val_loss: 0.3821 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0462 - acc: 0.9888 - f1_m: 0.9888 - precision_m: 0.9888 - recall_m: 0.9888 - val_loss: 0.3875 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0421 - acc: 0.9908 - f1_m: 0.9908 - precision_m: 0.9908 - recall_m: 0.9908 - val_loss: 0.3878 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0387 - acc: 0.9917 - f1_m: 0.9917 - precision_m: 0.9917 - recall_m: 0.9917 - val_loss: 0.3945 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0382 - acc: 0.9913 - f1_m: 0.9913 - precision_m: 0.9913 - recall_m: 0.9913 - val_loss: 0.3982 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0356 - acc: 0.9919 - f1_m: 0.9919 - precision_m: 0.9919 - recall_m: 0.9919 - val_loss: 0.4029 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0332 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.4066 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0314 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.4092 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0292 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9932 - recall_m: 0.9932 - val_loss: 0.4146 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0284 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.4195 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0268 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.4229 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0261 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.4279 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0254 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.4323 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0244 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.4316 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 6us/step - loss: 0.0233 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4398 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0220 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4414 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0216 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4503 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0203 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4539 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0197 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4560 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0195 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4574 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0191 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4702 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0183 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4664 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "4001/4001 [==============================] - 0s 75us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/xfpqtcwf\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 3s 244us/step - loss: 0.6699 - acc: 0.5982 - f1_m: 0.5982 - precision_m: 0.5982 - recall_m: 0.5982 - val_loss: 0.6511 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.6284 - acc: 0.6147 - f1_m: 0.6147 - precision_m: 0.6147 - recall_m: 0.6147 - val_loss: 0.6057 - val_acc: 0.6309 - val_f1_m: 0.6309 - val_precision_m: 0.6309 - val_recall_m: 0.6309\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.5449 - acc: 0.7316 - f1_m: 0.7316 - precision_m: 0.7316 - recall_m: 0.7316 - val_loss: 0.5245 - val_acc: 0.7603 - val_f1_m: 0.7603 - val_precision_m: 0.7603 - val_recall_m: 0.7603\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.4203 - acc: 0.8470 - f1_m: 0.8470 - precision_m: 0.8470 - recall_m: 0.8470 - val_loss: 0.4481 - val_acc: 0.7944 - val_f1_m: 0.7944 - val_precision_m: 0.7944 - val_recall_m: 0.7944\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.3020 - acc: 0.8990 - f1_m: 0.8990 - precision_m: 0.8990 - recall_m: 0.8990 - val_loss: 0.3930 - val_acc: 0.8209 - val_f1_m: 0.8209 - val_precision_m: 0.8209 - val_recall_m: 0.8209\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2051 - acc: 0.9405 - f1_m: 0.9405 - precision_m: 0.9405 - recall_m: 0.9405 - val_loss: 0.3541 - val_acc: 0.8366 - val_f1_m: 0.8366 - val_precision_m: 0.8366 - val_recall_m: 0.8366\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1342 - acc: 0.9675 - f1_m: 0.9675 - precision_m: 0.9675 - recall_m: 0.9675 - val_loss: 0.3354 - val_acc: 0.8525 - val_f1_m: 0.8525 - val_precision_m: 0.8525 - val_recall_m: 0.8525\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0867 - acc: 0.9820 - f1_m: 0.9820 - precision_m: 0.9820 - recall_m: 0.9820 - val_loss: 0.3300 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0597 - acc: 0.9882 - f1_m: 0.9882 - precision_m: 0.9882 - recall_m: 0.9882 - val_loss: 0.3345 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0420 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.3429 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0329 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3462 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0261 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3506 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0223 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3543 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0189 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3619 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0163 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3775 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0153 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3935 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0145 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3876 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0129 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.4086 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0127 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4053 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0121 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4090 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0118 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4419 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0113 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4180 - val_acc: 0.8794 - val_f1_m: 0.8794 - val_precision_m: 0.8794 - val_recall_m: 0.8794\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0111 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4514 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0110 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4284 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0106 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4504 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0113 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4582 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0107 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4495 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0104 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4541 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0102 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4678 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0100 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4620 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0095 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.4646 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0097 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4735 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0093 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4755 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0095 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4826 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0099 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4837 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0097 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.4926 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0098 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4871 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0094 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5056 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0097 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4917 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0102 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5069 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0088 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.4971 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0094 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5019 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0098 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5060 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0100 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5103 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0091 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5238 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0092 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5019 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0090 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5302 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0092 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5148 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0089 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5225 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0088 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5138 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "4001/4001 [==============================] - 0s 72us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/tguddzdr\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 3s 240us/step - loss: 0.6763 - acc: 0.5965 - f1_m: 0.5962 - precision_m: 0.5963 - recall_m: 0.5960 - val_loss: 0.6605 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.6512 - acc: 0.6084 - f1_m: 0.6084 - precision_m: 0.6084 - recall_m: 0.6084 - val_loss: 0.6403 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.6283 - acc: 0.6220 - f1_m: 0.6220 - precision_m: 0.6220 - recall_m: 0.6220 - val_loss: 0.6159 - val_acc: 0.6122 - val_f1_m: 0.6122 - val_precision_m: 0.6122 - val_recall_m: 0.6122\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5916 - acc: 0.6426 - f1_m: 0.6426 - precision_m: 0.6426 - recall_m: 0.6426 - val_loss: 0.5818 - val_acc: 0.6728 - val_f1_m: 0.6728 - val_precision_m: 0.6728 - val_recall_m: 0.6728\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.5486 - acc: 0.7081 - f1_m: 0.7081 - precision_m: 0.7081 - recall_m: 0.7081 - val_loss: 0.5428 - val_acc: 0.7522 - val_f1_m: 0.7522 - val_precision_m: 0.7522 - val_recall_m: 0.7522\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.4989 - acc: 0.7613 - f1_m: 0.7613 - precision_m: 0.7613 - recall_m: 0.7613 - val_loss: 0.5026 - val_acc: 0.7834 - val_f1_m: 0.7834 - val_precision_m: 0.7834 - val_recall_m: 0.7834\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4493 - acc: 0.7821 - f1_m: 0.7821 - precision_m: 0.7821 - recall_m: 0.7821 - val_loss: 0.4669 - val_acc: 0.8006 - val_f1_m: 0.8006 - val_precision_m: 0.8006 - val_recall_m: 0.8006\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3925 - acc: 0.8113 - f1_m: 0.8113 - precision_m: 0.8113 - recall_m: 0.8113 - val_loss: 0.4321 - val_acc: 0.8091 - val_f1_m: 0.8091 - val_precision_m: 0.8091 - val_recall_m: 0.8091\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3488 - acc: 0.8630 - f1_m: 0.8630 - precision_m: 0.8630 - recall_m: 0.8630 - val_loss: 0.4063 - val_acc: 0.8287 - val_f1_m: 0.8287 - val_precision_m: 0.8287 - val_recall_m: 0.8287\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3031 - acc: 0.9039 - f1_m: 0.9039 - precision_m: 0.9039 - recall_m: 0.9039 - val_loss: 0.3813 - val_acc: 0.8431 - val_f1_m: 0.8431 - val_precision_m: 0.8431 - val_recall_m: 0.8431\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.2684 - acc: 0.9237 - f1_m: 0.9237 - precision_m: 0.9237 - recall_m: 0.9237 - val_loss: 0.3604 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2407 - acc: 0.9370 - f1_m: 0.9370 - precision_m: 0.9370 - recall_m: 0.9370 - val_loss: 0.3422 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2067 - acc: 0.9521 - f1_m: 0.9521 - precision_m: 0.9521 - recall_m: 0.9521 - val_loss: 0.3261 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1826 - acc: 0.9564 - f1_m: 0.9564 - precision_m: 0.9564 - recall_m: 0.9564 - val_loss: 0.3158 - val_acc: 0.8797 - val_f1_m: 0.8797 - val_precision_m: 0.8797 - val_recall_m: 0.8797\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1600 - acc: 0.9656 - f1_m: 0.9656 - precision_m: 0.9656 - recall_m: 0.9656 - val_loss: 0.3128 - val_acc: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1406 - acc: 0.9713 - f1_m: 0.9713 - precision_m: 0.9713 - recall_m: 0.9713 - val_loss: 0.3115 - val_acc: 0.8778 - val_f1_m: 0.8778 - val_precision_m: 0.8778 - val_recall_m: 0.8778\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1242 - acc: 0.9763 - f1_m: 0.9762 - precision_m: 0.9763 - recall_m: 0.9763 - val_loss: 0.3110 - val_acc: 0.8825 - val_f1_m: 0.8825 - val_precision_m: 0.8825 - val_recall_m: 0.8825\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1182 - acc: 0.9779 - f1_m: 0.9779 - precision_m: 0.9779 - recall_m: 0.9779 - val_loss: 0.3125 - val_acc: 0.8853 - val_f1_m: 0.8853 - val_precision_m: 0.8853 - val_recall_m: 0.8853\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1075 - acc: 0.9805 - f1_m: 0.9805 - precision_m: 0.9805 - recall_m: 0.9805 - val_loss: 0.3168 - val_acc: 0.8853 - val_f1_m: 0.8853 - val_precision_m: 0.8853 - val_recall_m: 0.8853\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1002 - acc: 0.9810 - f1_m: 0.9810 - precision_m: 0.9810 - recall_m: 0.9810 - val_loss: 0.3234 - val_acc: 0.8825 - val_f1_m: 0.8825 - val_precision_m: 0.8825 - val_recall_m: 0.8825\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0919 - acc: 0.9843 - f1_m: 0.9843 - precision_m: 0.9843 - recall_m: 0.9843 - val_loss: 0.3277 - val_acc: 0.8816 - val_f1_m: 0.8816 - val_precision_m: 0.8816 - val_recall_m: 0.8816\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0881 - acc: 0.9844 - f1_m: 0.9844 - precision_m: 0.9844 - recall_m: 0.9844 - val_loss: 0.3307 - val_acc: 0.8850 - val_f1_m: 0.8850 - val_precision_m: 0.8850 - val_recall_m: 0.8850\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0863 - acc: 0.9830 - f1_m: 0.9830 - precision_m: 0.9830 - recall_m: 0.9830 - val_loss: 0.3368 - val_acc: 0.8822 - val_f1_m: 0.8822 - val_precision_m: 0.8822 - val_recall_m: 0.8822\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0814 - acc: 0.9853 - f1_m: 0.9853 - precision_m: 0.9853 - recall_m: 0.9853 - val_loss: 0.3441 - val_acc: 0.8816 - val_f1_m: 0.8816 - val_precision_m: 0.8816 - val_recall_m: 0.8816\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0794 - acc: 0.9847 - f1_m: 0.9847 - precision_m: 0.9847 - recall_m: 0.9847 - val_loss: 0.3495 - val_acc: 0.8859 - val_f1_m: 0.8859 - val_precision_m: 0.8859 - val_recall_m: 0.8859\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0759 - acc: 0.9855 - f1_m: 0.9855 - precision_m: 0.9855 - recall_m: 0.9855 - val_loss: 0.3548 - val_acc: 0.8844 - val_f1_m: 0.8844 - val_precision_m: 0.8844 - val_recall_m: 0.8844\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0727 - acc: 0.9849 - f1_m: 0.9849 - precision_m: 0.9849 - recall_m: 0.9849 - val_loss: 0.3669 - val_acc: 0.8806 - val_f1_m: 0.8806 - val_precision_m: 0.8806 - val_recall_m: 0.8806\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0709 - acc: 0.9858 - f1_m: 0.9858 - precision_m: 0.9858 - recall_m: 0.9858 - val_loss: 0.3705 - val_acc: 0.8834 - val_f1_m: 0.8834 - val_precision_m: 0.8834 - val_recall_m: 0.8834\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0677 - acc: 0.9888 - f1_m: 0.9888 - precision_m: 0.9888 - recall_m: 0.9888 - val_loss: 0.3767 - val_acc: 0.8847 - val_f1_m: 0.8847 - val_precision_m: 0.8847 - val_recall_m: 0.8847\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0644 - acc: 0.9891 - f1_m: 0.9891 - precision_m: 0.9891 - recall_m: 0.9891 - val_loss: 0.3821 - val_acc: 0.8831 - val_f1_m: 0.8831 - val_precision_m: 0.8831 - val_recall_m: 0.8831\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0634 - acc: 0.9884 - f1_m: 0.9884 - precision_m: 0.9884 - recall_m: 0.9884 - val_loss: 0.3896 - val_acc: 0.8819 - val_f1_m: 0.8819 - val_precision_m: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0608 - acc: 0.9876 - f1_m: 0.9876 - precision_m: 0.9876 - recall_m: 0.9876 - val_loss: 0.3928 - val_acc: 0.8862 - val_f1_m: 0.8862 - val_precision_m: 0.8862 - val_recall_m: 0.8862\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0580 - acc: 0.9873 - f1_m: 0.9873 - precision_m: 0.9873 - recall_m: 0.9873 - val_loss: 0.4008 - val_acc: 0.8859 - val_f1_m: 0.8859 - val_precision_m: 0.8859 - val_recall_m: 0.8859\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0568 - acc: 0.9867 - f1_m: 0.9867 - precision_m: 0.9867 - recall_m: 0.9867 - val_loss: 0.4106 - val_acc: 0.8859 - val_f1_m: 0.8859 - val_precision_m: 0.8859 - val_recall_m: 0.8859\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0539 - acc: 0.9872 - f1_m: 0.9872 - precision_m: 0.9872 - recall_m: 0.9872 - val_loss: 0.4206 - val_acc: 0.8828 - val_f1_m: 0.8828 - val_precision_m: 0.8828 - val_recall_m: 0.8828\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0510 - acc: 0.9878 - f1_m: 0.9878 - precision_m: 0.9878 - recall_m: 0.9878 - val_loss: 0.4264 - val_acc: 0.8859 - val_f1_m: 0.8859 - val_precision_m: 0.8859 - val_recall_m: 0.8859\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0518 - acc: 0.9877 - f1_m: 0.9877 - precision_m: 0.9877 - recall_m: 0.9877 - val_loss: 0.4336 - val_acc: 0.8850 - val_f1_m: 0.8850 - val_precision_m: 0.8850 - val_recall_m: 0.8850\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0467 - acc: 0.9891 - f1_m: 0.9891 - precision_m: 0.9891 - recall_m: 0.9891 - val_loss: 0.4410 - val_acc: 0.8872 - val_f1_m: 0.8872 - val_precision_m: 0.8872 - val_recall_m: 0.8872\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0471 - acc: 0.9874 - f1_m: 0.9874 - precision_m: 0.9874 - recall_m: 0.9874 - val_loss: 0.4482 - val_acc: 0.8888 - val_f1_m: 0.8887 - val_precision_m: 0.8888 - val_recall_m: 0.8888\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0461 - acc: 0.9893 - f1_m: 0.9893 - precision_m: 0.9893 - recall_m: 0.9893 - val_loss: 0.4514 - val_acc: 0.8872 - val_f1_m: 0.8872 - val_precision_m: 0.8872 - val_recall_m: 0.8872\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0465 - acc: 0.9872 - f1_m: 0.9872 - precision_m: 0.9872 - recall_m: 0.9872 - val_loss: 0.4608 - val_acc: 0.8856 - val_f1_m: 0.8856 - val_precision_m: 0.8856 - val_recall_m: 0.8856\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0442 - acc: 0.9883 - f1_m: 0.9883 - precision_m: 0.9883 - recall_m: 0.9883 - val_loss: 0.4656 - val_acc: 0.8869 - val_f1_m: 0.8869 - val_precision_m: 0.8869 - val_recall_m: 0.8869\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0449 - acc: 0.9883 - f1_m: 0.9883 - precision_m: 0.9883 - recall_m: 0.9883 - val_loss: 0.4715 - val_acc: 0.8828 - val_f1_m: 0.8828 - val_precision_m: 0.8828 - val_recall_m: 0.8828\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0409 - acc: 0.9907 - f1_m: 0.9907 - precision_m: 0.9907 - recall_m: 0.9907 - val_loss: 0.4790 - val_acc: 0.8838 - val_f1_m: 0.8837 - val_precision_m: 0.8838 - val_recall_m: 0.8838\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0427 - acc: 0.9892 - f1_m: 0.9892 - precision_m: 0.9892 - recall_m: 0.9892 - val_loss: 0.4849 - val_acc: 0.8847 - val_f1_m: 0.8847 - val_precision_m: 0.8847 - val_recall_m: 0.8847\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0418 - acc: 0.9880 - f1_m: 0.9880 - precision_m: 0.9880 - recall_m: 0.9880 - val_loss: 0.4948 - val_acc: 0.8825 - val_f1_m: 0.8825 - val_precision_m: 0.8825 - val_recall_m: 0.8825\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0414 - acc: 0.9903 - f1_m: 0.9903 - precision_m: 0.9903 - recall_m: 0.9903 - val_loss: 0.4959 - val_acc: 0.8859 - val_f1_m: 0.8859 - val_precision_m: 0.8859 - val_recall_m: 0.8859\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0435 - acc: 0.9882 - f1_m: 0.9882 - precision_m: 0.9882 - recall_m: 0.9882 - val_loss: 0.5021 - val_acc: 0.8853 - val_f1_m: 0.8853 - val_precision_m: 0.8853 - val_recall_m: 0.8853\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0415 - acc: 0.9890 - f1_m: 0.9890 - precision_m: 0.9890 - recall_m: 0.9890 - val_loss: 0.5083 - val_acc: 0.8838 - val_f1_m: 0.8837 - val_precision_m: 0.8838 - val_recall_m: 0.8838\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0397 - acc: 0.9891 - f1_m: 0.9891 - precision_m: 0.9891 - recall_m: 0.9891 - val_loss: 0.5127 - val_acc: 0.8850 - val_f1_m: 0.8850 - val_precision_m: 0.8850 - val_recall_m: 0.8850\n",
            "4001/4001 [==============================] - 0s 73us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/becb74j8\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 3s 249us/step - loss: 0.6817 - acc: 0.5729 - f1_m: 0.5728 - precision_m: 0.5729 - recall_m: 0.5727 - val_loss: 0.6650 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.6624 - acc: 0.6085 - f1_m: 0.6085 - precision_m: 0.6085 - recall_m: 0.6085 - val_loss: 0.6529 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.6425 - acc: 0.6195 - f1_m: 0.6195 - precision_m: 0.6195 - recall_m: 0.6195 - val_loss: 0.6332 - val_acc: 0.6231 - val_f1_m: 0.6231 - val_precision_m: 0.6231 - val_recall_m: 0.6231\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6134 - acc: 0.6595 - f1_m: 0.6595 - precision_m: 0.6595 - recall_m: 0.6595 - val_loss: 0.6006 - val_acc: 0.6831 - val_f1_m: 0.6831 - val_precision_m: 0.6831 - val_recall_m: 0.6831\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5682 - acc: 0.7291 - f1_m: 0.7291 - precision_m: 0.7291 - recall_m: 0.7291 - val_loss: 0.5574 - val_acc: 0.7469 - val_f1_m: 0.7469 - val_precision_m: 0.7469 - val_recall_m: 0.7469\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5142 - acc: 0.7793 - f1_m: 0.7793 - precision_m: 0.7793 - recall_m: 0.7793 - val_loss: 0.5139 - val_acc: 0.7803 - val_f1_m: 0.7803 - val_precision_m: 0.7803 - val_recall_m: 0.7803\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4581 - acc: 0.8185 - f1_m: 0.8185 - precision_m: 0.8185 - recall_m: 0.8185 - val_loss: 0.4752 - val_acc: 0.7928 - val_f1_m: 0.7928 - val_precision_m: 0.7928 - val_recall_m: 0.7928\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3968 - acc: 0.8528 - f1_m: 0.8528 - precision_m: 0.8528 - recall_m: 0.8528 - val_loss: 0.4358 - val_acc: 0.8131 - val_f1_m: 0.8131 - val_precision_m: 0.8131 - val_recall_m: 0.8131\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3396 - acc: 0.8853 - f1_m: 0.8853 - precision_m: 0.8853 - recall_m: 0.8853 - val_loss: 0.4049 - val_acc: 0.8206 - val_f1_m: 0.8206 - val_precision_m: 0.8206 - val_recall_m: 0.8206\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2803 - acc: 0.9149 - f1_m: 0.9149 - precision_m: 0.9149 - recall_m: 0.9149 - val_loss: 0.3775 - val_acc: 0.8272 - val_f1_m: 0.8272 - val_precision_m: 0.8272 - val_recall_m: 0.8272\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2353 - acc: 0.9308 - f1_m: 0.9308 - precision_m: 0.9308 - recall_m: 0.9308 - val_loss: 0.3568 - val_acc: 0.8378 - val_f1_m: 0.8378 - val_precision_m: 0.8378 - val_recall_m: 0.8378\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1962 - acc: 0.9495 - f1_m: 0.9495 - precision_m: 0.9495 - recall_m: 0.9495 - val_loss: 0.3417 - val_acc: 0.8459 - val_f1_m: 0.8459 - val_precision_m: 0.8459 - val_recall_m: 0.8459\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1664 - acc: 0.9559 - f1_m: 0.9559 - precision_m: 0.9559 - recall_m: 0.9559 - val_loss: 0.3308 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1372 - acc: 0.9659 - f1_m: 0.9659 - precision_m: 0.9659 - recall_m: 0.9659 - val_loss: 0.3292 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1128 - acc: 0.9745 - f1_m: 0.9745 - precision_m: 0.9745 - recall_m: 0.9745 - val_loss: 0.3270 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0993 - acc: 0.9769 - f1_m: 0.9769 - precision_m: 0.9769 - recall_m: 0.9769 - val_loss: 0.3375 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0820 - acc: 0.9822 - f1_m: 0.9822 - precision_m: 0.9822 - recall_m: 0.9822 - val_loss: 0.3322 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0757 - acc: 0.9825 - f1_m: 0.9825 - precision_m: 0.9825 - recall_m: 0.9825 - val_loss: 0.3517 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0649 - acc: 0.9852 - f1_m: 0.9852 - precision_m: 0.9852 - recall_m: 0.9852 - val_loss: 0.3541 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0601 - acc: 0.9872 - f1_m: 0.9872 - precision_m: 0.9872 - recall_m: 0.9872 - val_loss: 0.3687 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0554 - acc: 0.9866 - f1_m: 0.9866 - precision_m: 0.9866 - recall_m: 0.9866 - val_loss: 0.3707 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0497 - acc: 0.9862 - f1_m: 0.9862 - precision_m: 0.9862 - recall_m: 0.9862 - val_loss: 0.3876 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0472 - acc: 0.9883 - f1_m: 0.9883 - precision_m: 0.9883 - recall_m: 0.9883 - val_loss: 0.3912 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0430 - acc: 0.9895 - f1_m: 0.9895 - precision_m: 0.9895 - recall_m: 0.9895 - val_loss: 0.4069 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0409 - acc: 0.9899 - f1_m: 0.9899 - precision_m: 0.9899 - recall_m: 0.9899 - val_loss: 0.4168 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0396 - acc: 0.9901 - f1_m: 0.9901 - precision_m: 0.9901 - recall_m: 0.9901 - val_loss: 0.4153 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0382 - acc: 0.9909 - f1_m: 0.9909 - precision_m: 0.9909 - recall_m: 0.9909 - val_loss: 0.4241 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0363 - acc: 0.9894 - f1_m: 0.9894 - precision_m: 0.9894 - recall_m: 0.9894 - val_loss: 0.4359 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0354 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.4450 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0349 - acc: 0.9895 - f1_m: 0.9895 - precision_m: 0.9895 - recall_m: 0.9895 - val_loss: 0.4453 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0338 - acc: 0.9900 - f1_m: 0.9900 - precision_m: 0.9900 - recall_m: 0.9900 - val_loss: 0.4598 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0328 - acc: 0.9905 - f1_m: 0.9905 - precision_m: 0.9905 - recall_m: 0.9905 - val_loss: 0.4685 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0322 - acc: 0.9905 - f1_m: 0.9905 - precision_m: 0.9905 - recall_m: 0.9905 - val_loss: 0.4750 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0298 - acc: 0.9917 - f1_m: 0.9917 - precision_m: 0.9917 - recall_m: 0.9917 - val_loss: 0.4816 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0289 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.4933 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0294 - acc: 0.9913 - f1_m: 0.9913 - precision_m: 0.9913 - recall_m: 0.9913 - val_loss: 0.5026 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0295 - acc: 0.9907 - f1_m: 0.9907 - precision_m: 0.9907 - recall_m: 0.9907 - val_loss: 0.5064 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0278 - acc: 0.9903 - f1_m: 0.9903 - precision_m: 0.9903 - recall_m: 0.9903 - val_loss: 0.5146 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0276 - acc: 0.9914 - f1_m: 0.9914 - precision_m: 0.9914 - recall_m: 0.9914 - val_loss: 0.5285 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0257 - acc: 0.9914 - f1_m: 0.9914 - precision_m: 0.9914 - recall_m: 0.9914 - val_loss: 0.5295 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0282 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.5306 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0259 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9932 - recall_m: 0.9932 - val_loss: 0.5535 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0242 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.5550 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0239 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.5747 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0224 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.5787 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0217 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.5788 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0221 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.6074 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0228 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9932 - recall_m: 0.9932 - val_loss: 0.5939 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0216 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.6060 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0211 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.6267 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "4001/4001 [==============================] - 0s 78us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/zm1wvh73\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 3s 255us/step - loss: 0.6702 - acc: 0.6052 - f1_m: 0.6052 - precision_m: 0.6052 - recall_m: 0.6052 - val_loss: 0.6568 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.6391 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6203 - val_acc: 0.6166 - val_f1_m: 0.6166 - val_precision_m: 0.6166 - val_recall_m: 0.6166\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5708 - acc: 0.6759 - f1_m: 0.6759 - precision_m: 0.6759 - recall_m: 0.6759 - val_loss: 0.5497 - val_acc: 0.7406 - val_f1_m: 0.7406 - val_precision_m: 0.7406 - val_recall_m: 0.7406\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.4625 - acc: 0.8230 - f1_m: 0.8230 - precision_m: 0.8230 - recall_m: 0.8230 - val_loss: 0.4715 - val_acc: 0.7894 - val_f1_m: 0.7894 - val_precision_m: 0.7894 - val_recall_m: 0.7894\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.3440 - acc: 0.8834 - f1_m: 0.8834 - precision_m: 0.8834 - recall_m: 0.8834 - val_loss: 0.4123 - val_acc: 0.8091 - val_f1_m: 0.8091 - val_precision_m: 0.8091 - val_recall_m: 0.8091\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2398 - acc: 0.9283 - f1_m: 0.9283 - precision_m: 0.9283 - recall_m: 0.9283 - val_loss: 0.3694 - val_acc: 0.8294 - val_f1_m: 0.8294 - val_precision_m: 0.8294 - val_recall_m: 0.8294\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1614 - acc: 0.9584 - f1_m: 0.9584 - precision_m: 0.9584 - recall_m: 0.9584 - val_loss: 0.3442 - val_acc: 0.8478 - val_f1_m: 0.8478 - val_precision_m: 0.8478 - val_recall_m: 0.8478\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1053 - acc: 0.9757 - f1_m: 0.9757 - precision_m: 0.9757 - recall_m: 0.9757 - val_loss: 0.3410 - val_acc: 0.8494 - val_f1_m: 0.8494 - val_precision_m: 0.8494 - val_recall_m: 0.8494\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0701 - acc: 0.9848 - f1_m: 0.9848 - precision_m: 0.9848 - recall_m: 0.9848 - val_loss: 0.3386 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0499 - acc: 0.9896 - f1_m: 0.9896 - precision_m: 0.9896 - recall_m: 0.9896 - val_loss: 0.3421 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0360 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.3472 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0288 - acc: 0.9938 - f1_m: 0.9938 - precision_m: 0.9938 - recall_m: 0.9938 - val_loss: 0.3582 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0241 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3631 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0206 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3659 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0188 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3905 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0170 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4073 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0151 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3982 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0144 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3979 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0136 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4346 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0128 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4128 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0127 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4398 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0116 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4259 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0111 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4569 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0116 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4354 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0111 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4680 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0107 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4472 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0105 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4713 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0105 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4527 - val_acc: 0.8744 - val_f1_m: 0.8744 - val_precision_m: 0.8744 - val_recall_m: 0.8744\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0109 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4825 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0104 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4724 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0101 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.4692 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0111 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4967 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0098 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4843 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0105 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5010 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0104 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4829 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0102 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5053 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0098 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4844 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0100 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5009 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0092 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5062 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0098 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4972 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0095 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5152 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0098 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5073 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0094 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5198 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0095 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5198 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0093 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5196 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0092 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5207 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0090 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5332 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0093 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5261 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0104 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5251 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0090 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5350 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "4001/4001 [==============================] - 0s 74us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/d18933qx\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 3s 244us/step - loss: 0.6784 - acc: 0.5925 - f1_m: 0.5925 - precision_m: 0.5925 - recall_m: 0.5925 - val_loss: 0.6670 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.6654 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6589 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.6496 - acc: 0.6069 - f1_m: 0.6069 - precision_m: 0.6069 - recall_m: 0.6069 - val_loss: 0.6438 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.6214 - acc: 0.6184 - f1_m: 0.6184 - precision_m: 0.6184 - recall_m: 0.6184 - val_loss: 0.6131 - val_acc: 0.6388 - val_f1_m: 0.6387 - val_precision_m: 0.6388 - val_recall_m: 0.6388\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.5703 - acc: 0.7141 - f1_m: 0.7141 - precision_m: 0.7141 - recall_m: 0.7141 - val_loss: 0.5688 - val_acc: 0.7200 - val_f1_m: 0.7200 - val_precision_m: 0.7200 - val_recall_m: 0.7200\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.4998 - acc: 0.8002 - f1_m: 0.8002 - precision_m: 0.8002 - recall_m: 0.8002 - val_loss: 0.5190 - val_acc: 0.7669 - val_f1_m: 0.7669 - val_precision_m: 0.7669 - val_recall_m: 0.7669\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.4233 - acc: 0.8503 - f1_m: 0.8503 - precision_m: 0.8503 - recall_m: 0.8503 - val_loss: 0.4736 - val_acc: 0.7822 - val_f1_m: 0.7822 - val_precision_m: 0.7822 - val_recall_m: 0.7822\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.3496 - acc: 0.8823 - f1_m: 0.8823 - precision_m: 0.8823 - recall_m: 0.8823 - val_loss: 0.4345 - val_acc: 0.8034 - val_f1_m: 0.8034 - val_precision_m: 0.8034 - val_recall_m: 0.8034\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.2803 - acc: 0.9097 - f1_m: 0.9097 - precision_m: 0.9097 - recall_m: 0.9097 - val_loss: 0.4031 - val_acc: 0.8116 - val_f1_m: 0.8116 - val_precision_m: 0.8116 - val_recall_m: 0.8116\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.2229 - acc: 0.9352 - f1_m: 0.9352 - precision_m: 0.9352 - recall_m: 0.9352 - val_loss: 0.3777 - val_acc: 0.8281 - val_f1_m: 0.8281 - val_precision_m: 0.8281 - val_recall_m: 0.8281\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.1762 - acc: 0.9509 - f1_m: 0.9509 - precision_m: 0.9509 - recall_m: 0.9509 - val_loss: 0.3606 - val_acc: 0.8397 - val_f1_m: 0.8397 - val_precision_m: 0.8397 - val_recall_m: 0.8397\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.1394 - acc: 0.9645 - f1_m: 0.9645 - precision_m: 0.9645 - recall_m: 0.9645 - val_loss: 0.3500 - val_acc: 0.8459 - val_f1_m: 0.8459 - val_precision_m: 0.8459 - val_recall_m: 0.8459\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.1122 - acc: 0.9716 - f1_m: 0.9716 - precision_m: 0.9716 - recall_m: 0.9716 - val_loss: 0.3442 - val_acc: 0.8494 - val_f1_m: 0.8494 - val_precision_m: 0.8494 - val_recall_m: 0.8494\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0901 - acc: 0.9782 - f1_m: 0.9782 - precision_m: 0.9782 - recall_m: 0.9782 - val_loss: 0.3398 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0735 - acc: 0.9830 - f1_m: 0.9830 - precision_m: 0.9830 - recall_m: 0.9830 - val_loss: 0.3406 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0621 - acc: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865 - val_loss: 0.3388 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0515 - acc: 0.9878 - f1_m: 0.9878 - precision_m: 0.9878 - recall_m: 0.9878 - val_loss: 0.3486 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0452 - acc: 0.9898 - f1_m: 0.9898 - precision_m: 0.9898 - recall_m: 0.9898 - val_loss: 0.3484 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0381 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.3551 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0340 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.3648 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0305 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3647 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0273 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.3765 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0252 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.3774 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0227 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3879 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0209 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3909 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0199 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3984 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0182 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4069 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0174 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4153 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0163 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4144 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0162 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4213 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0148 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4323 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0147 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4324 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0143 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4305 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0137 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4438 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0132 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4475 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0132 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4619 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0131 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4571 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0125 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4545 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0125 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4723 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0122 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4673 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4717 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0117 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4830 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0117 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4822 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0121 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4817 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0114 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4899 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0112 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4971 - val_acc: 0.8516 - val_f1_m: 0.8516 - val_precision_m: 0.8516 - val_recall_m: 0.8516\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0117 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4877 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4942 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0110 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5044 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0110 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5016 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "4001/4001 [==============================] - 0s 74us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/odr26fxu\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 3s 252us/step - loss: 0.6736 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6661 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.6626 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6560 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.6443 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6350 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.6060 - acc: 0.6239 - f1_m: 0.6239 - precision_m: 0.6239 - recall_m: 0.6239 - val_loss: 0.5957 - val_acc: 0.6578 - val_f1_m: 0.6578 - val_precision_m: 0.6578 - val_recall_m: 0.6578\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.5428 - acc: 0.7409 - f1_m: 0.7409 - precision_m: 0.7409 - recall_m: 0.7409 - val_loss: 0.5418 - val_acc: 0.7409 - val_f1_m: 0.7409 - val_precision_m: 0.7409 - val_recall_m: 0.7409\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.4593 - acc: 0.8196 - f1_m: 0.8196 - precision_m: 0.8196 - recall_m: 0.8196 - val_loss: 0.4868 - val_acc: 0.7722 - val_f1_m: 0.7722 - val_precision_m: 0.7722 - val_recall_m: 0.7722\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.3724 - acc: 0.8709 - f1_m: 0.8709 - precision_m: 0.8709 - recall_m: 0.8709 - val_loss: 0.4410 - val_acc: 0.7959 - val_f1_m: 0.7959 - val_precision_m: 0.7959 - val_recall_m: 0.7959\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.2917 - acc: 0.9076 - f1_m: 0.9076 - precision_m: 0.9076 - recall_m: 0.9076 - val_loss: 0.4060 - val_acc: 0.8153 - val_f1_m: 0.8153 - val_precision_m: 0.8153 - val_recall_m: 0.8153\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.2241 - acc: 0.9352 - f1_m: 0.9352 - precision_m: 0.9352 - recall_m: 0.9352 - val_loss: 0.3784 - val_acc: 0.8284 - val_f1_m: 0.8284 - val_precision_m: 0.8284 - val_recall_m: 0.8284\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1712 - acc: 0.9527 - f1_m: 0.9527 - precision_m: 0.9527 - recall_m: 0.9527 - val_loss: 0.3633 - val_acc: 0.8375 - val_f1_m: 0.8375 - val_precision_m: 0.8375 - val_recall_m: 0.8375\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.1304 - acc: 0.9664 - f1_m: 0.9664 - precision_m: 0.9664 - recall_m: 0.9664 - val_loss: 0.3546 - val_acc: 0.8456 - val_f1_m: 0.8456 - val_precision_m: 0.8456 - val_recall_m: 0.8456\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1011 - acc: 0.9760 - f1_m: 0.9760 - precision_m: 0.9760 - recall_m: 0.9760 - val_loss: 0.3502 - val_acc: 0.8525 - val_f1_m: 0.8525 - val_precision_m: 0.8525 - val_recall_m: 0.8525\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0796 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 0.3412 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0641 - acc: 0.9856 - f1_m: 0.9856 - precision_m: 0.9856 - recall_m: 0.9856 - val_loss: 0.3519 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0519 - acc: 0.9894 - f1_m: 0.9894 - precision_m: 0.9894 - recall_m: 0.9894 - val_loss: 0.3571 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0435 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 0.3563 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0366 - acc: 0.9918 - f1_m: 0.9918 - precision_m: 0.9918 - recall_m: 0.9918 - val_loss: 0.3604 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0320 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.3686 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0281 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3764 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0255 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3825 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0225 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3916 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0207 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3951 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0191 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4038 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0184 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4117 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0168 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4193 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0157 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4203 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0151 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4321 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0149 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4382 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0142 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4376 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0135 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4411 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0131 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4474 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0129 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4523 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0124 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4554 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0120 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4675 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0118 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4611 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0117 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4678 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0113 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4718 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0114 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4782 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4795 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0113 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4854 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0110 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4805 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0102 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4899 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4951 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0104 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4928 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4979 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5060 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0102 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4998 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5089 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5135 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 8us/step - loss: 0.0104 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5092 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "4001/4001 [==============================] - 0s 80us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/1ygym3n3\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 4s 285us/step - loss: 0.6725 - acc: 0.6039 - f1_m: 0.6039 - precision_m: 0.6039 - recall_m: 0.6039 - val_loss: 0.6576 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.6453 - acc: 0.6070 - f1_m: 0.6070 - precision_m: 0.6070 - recall_m: 0.6070 - val_loss: 0.6294 - val_acc: 0.6122 - val_f1_m: 0.6122 - val_precision_m: 0.6122 - val_recall_m: 0.6122\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.5962 - acc: 0.6455 - f1_m: 0.6455 - precision_m: 0.6455 - recall_m: 0.6455 - val_loss: 0.5782 - val_acc: 0.6713 - val_f1_m: 0.6712 - val_precision_m: 0.6713 - val_recall_m: 0.6713\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5191 - acc: 0.7716 - f1_m: 0.7716 - precision_m: 0.7716 - recall_m: 0.7716 - val_loss: 0.5147 - val_acc: 0.7659 - val_f1_m: 0.7659 - val_precision_m: 0.7659 - val_recall_m: 0.7659\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.4316 - acc: 0.8388 - f1_m: 0.8388 - precision_m: 0.8388 - recall_m: 0.8388 - val_loss: 0.4567 - val_acc: 0.7944 - val_f1_m: 0.7944 - val_precision_m: 0.7944 - val_recall_m: 0.7944\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.3438 - acc: 0.8841 - f1_m: 0.8841 - precision_m: 0.8841 - recall_m: 0.8841 - val_loss: 0.4097 - val_acc: 0.8134 - val_f1_m: 0.8134 - val_precision_m: 0.8134 - val_recall_m: 0.8134\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.2657 - acc: 0.9188 - f1_m: 0.9188 - precision_m: 0.9188 - recall_m: 0.9188 - val_loss: 0.3727 - val_acc: 0.8281 - val_f1_m: 0.8281 - val_precision_m: 0.8281 - val_recall_m: 0.8281\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.2028 - acc: 0.9470 - f1_m: 0.9470 - precision_m: 0.9470 - recall_m: 0.9470 - val_loss: 0.3458 - val_acc: 0.8484 - val_f1_m: 0.8484 - val_precision_m: 0.8484 - val_recall_m: 0.8484\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1527 - acc: 0.9647 - f1_m: 0.9647 - precision_m: 0.9647 - recall_m: 0.9647 - val_loss: 0.3290 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1170 - acc: 0.9734 - f1_m: 0.9734 - precision_m: 0.9734 - recall_m: 0.9734 - val_loss: 0.3198 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0890 - acc: 0.9808 - f1_m: 0.9808 - precision_m: 0.9808 - recall_m: 0.9808 - val_loss: 0.3183 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0707 - acc: 0.9862 - f1_m: 0.9862 - precision_m: 0.9862 - recall_m: 0.9862 - val_loss: 0.3212 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0548 - acc: 0.9898 - f1_m: 0.9898 - precision_m: 0.9898 - recall_m: 0.9898 - val_loss: 0.3354 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0450 - acc: 0.9914 - f1_m: 0.9914 - precision_m: 0.9914 - recall_m: 0.9914 - val_loss: 0.3443 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0362 - acc: 0.9928 - f1_m: 0.9928 - precision_m: 0.9928 - recall_m: 0.9928 - val_loss: 0.3570 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0333 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3647 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0302 - acc: 0.9928 - f1_m: 0.9928 - precision_m: 0.9928 - recall_m: 0.9928 - val_loss: 0.3698 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0257 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.3762 - val_acc: 0.8759 - val_f1_m: 0.8759 - val_precision_m: 0.8759 - val_recall_m: 0.8759\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0235 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3893 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0219 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4046 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0189 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4075 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0191 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4157 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0169 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4455 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0169 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4300 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0151 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4462 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0142 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4509 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0137 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4561 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0136 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4667 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0136 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4799 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0137 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4753 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0128 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4917 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0122 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4947 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0129 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4976 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0115 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5037 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0120 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5023 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0118 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5260 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0117 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5222 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0119 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5221 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0118 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5327 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0109 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5352 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0109 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5407 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0102 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5424 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0103 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5545 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0102 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5578 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5577 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0097 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5731 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0098 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5694 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0098 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5839 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0103 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5894 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0101 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5770 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "4001/4001 [==============================] - 0s 79us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/n8tna41q\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 4s 282us/step - loss: 0.6721 - acc: 0.6004 - f1_m: 0.6004 - precision_m: 0.6004 - recall_m: 0.6004 - val_loss: 0.6574 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.6478 - acc: 0.6113 - f1_m: 0.6113 - precision_m: 0.6113 - recall_m: 0.6113 - val_loss: 0.6362 - val_acc: 0.6125 - val_f1_m: 0.6125 - val_precision_m: 0.6125 - val_recall_m: 0.6125\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.6130 - acc: 0.6346 - f1_m: 0.6346 - precision_m: 0.6346 - recall_m: 0.6346 - val_loss: 0.6001 - val_acc: 0.6637 - val_f1_m: 0.6637 - val_precision_m: 0.6637 - val_recall_m: 0.6637\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5574 - acc: 0.7303 - f1_m: 0.7303 - precision_m: 0.7303 - recall_m: 0.7303 - val_loss: 0.5494 - val_acc: 0.7469 - val_f1_m: 0.7469 - val_precision_m: 0.7469 - val_recall_m: 0.7469\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.4846 - acc: 0.8074 - f1_m: 0.8074 - precision_m: 0.8074 - recall_m: 0.8074 - val_loss: 0.4943 - val_acc: 0.7797 - val_f1_m: 0.7797 - val_precision_m: 0.7797 - val_recall_m: 0.7797\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4051 - acc: 0.8484 - f1_m: 0.8484 - precision_m: 0.8484 - recall_m: 0.8484 - val_loss: 0.4470 - val_acc: 0.7975 - val_f1_m: 0.7975 - val_precision_m: 0.7975 - val_recall_m: 0.7975\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.3298 - acc: 0.8867 - f1_m: 0.8867 - precision_m: 0.8867 - recall_m: 0.8867 - val_loss: 0.4068 - val_acc: 0.8094 - val_f1_m: 0.8094 - val_precision_m: 0.8094 - val_recall_m: 0.8094\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2608 - acc: 0.9249 - f1_m: 0.9249 - precision_m: 0.9249 - recall_m: 0.9249 - val_loss: 0.3753 - val_acc: 0.8256 - val_f1_m: 0.8256 - val_precision_m: 0.8256 - val_recall_m: 0.8256\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1988 - acc: 0.9487 - f1_m: 0.9487 - precision_m: 0.9487 - recall_m: 0.9487 - val_loss: 0.3502 - val_acc: 0.8347 - val_f1_m: 0.8347 - val_precision_m: 0.8347 - val_recall_m: 0.8347\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1563 - acc: 0.9611 - f1_m: 0.9611 - precision_m: 0.9611 - recall_m: 0.9611 - val_loss: 0.3364 - val_acc: 0.8444 - val_f1_m: 0.8444 - val_precision_m: 0.8444 - val_recall_m: 0.8444\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1206 - acc: 0.9752 - f1_m: 0.9752 - precision_m: 0.9752 - recall_m: 0.9752 - val_loss: 0.3280 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0944 - acc: 0.9797 - f1_m: 0.9797 - precision_m: 0.9797 - recall_m: 0.9797 - val_loss: 0.3177 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0739 - acc: 0.9853 - f1_m: 0.9853 - precision_m: 0.9853 - recall_m: 0.9853 - val_loss: 0.3285 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0599 - acc: 0.9889 - f1_m: 0.9889 - precision_m: 0.9889 - recall_m: 0.9889 - val_loss: 0.3271 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0489 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.3369 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0412 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.3463 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0355 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.3544 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0327 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.3606 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0296 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.3694 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0254 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3768 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0231 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3879 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0209 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3982 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0206 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4046 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0195 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4082 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0186 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4197 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0176 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4286 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0167 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4316 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0163 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4390 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0160 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4461 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0154 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4590 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0154 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4573 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0151 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4671 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0141 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4654 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0143 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4824 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0134 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4821 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0134 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4848 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0127 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4940 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0131 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4946 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0124 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4995 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0123 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5043 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0122 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5085 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0124 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5181 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0118 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5202 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0120 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5152 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0123 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5331 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0118 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5442 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0118 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5346 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0113 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5473 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0108 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5465 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0107 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5555 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "4001/4001 [==============================] - 0s 83us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/9pyng9fy\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 4s 300us/step - loss: 0.6722 - acc: 0.6058 - f1_m: 0.6058 - precision_m: 0.6058 - recall_m: 0.6058 - val_loss: 0.6588 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.6452 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6320 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5973 - acc: 0.6285 - f1_m: 0.6285 - precision_m: 0.6285 - recall_m: 0.6285 - val_loss: 0.5812 - val_acc: 0.6766 - val_f1_m: 0.6766 - val_precision_m: 0.6766 - val_recall_m: 0.6766\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.5193 - acc: 0.7658 - f1_m: 0.7658 - precision_m: 0.7658 - recall_m: 0.7658 - val_loss: 0.5165 - val_acc: 0.7631 - val_f1_m: 0.7631 - val_precision_m: 0.7631 - val_recall_m: 0.7631\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.4208 - acc: 0.8505 - f1_m: 0.8505 - precision_m: 0.8505 - recall_m: 0.8505 - val_loss: 0.4551 - val_acc: 0.7947 - val_f1_m: 0.7947 - val_precision_m: 0.7947 - val_recall_m: 0.7947\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3238 - acc: 0.8959 - f1_m: 0.8959 - precision_m: 0.8959 - recall_m: 0.8959 - val_loss: 0.4059 - val_acc: 0.8216 - val_f1_m: 0.8216 - val_precision_m: 0.8216 - val_recall_m: 0.8216\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2423 - acc: 0.9265 - f1_m: 0.9265 - precision_m: 0.9265 - recall_m: 0.9265 - val_loss: 0.3717 - val_acc: 0.8328 - val_f1_m: 0.8328 - val_precision_m: 0.8328 - val_recall_m: 0.8328\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1736 - acc: 0.9552 - f1_m: 0.9552 - precision_m: 0.9552 - recall_m: 0.9552 - val_loss: 0.3479 - val_acc: 0.8469 - val_f1_m: 0.8469 - val_precision_m: 0.8469 - val_recall_m: 0.8469\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1248 - acc: 0.9694 - f1_m: 0.9694 - precision_m: 0.9694 - recall_m: 0.9694 - val_loss: 0.3389 - val_acc: 0.8512 - val_f1_m: 0.8512 - val_precision_m: 0.8512 - val_recall_m: 0.8512\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0900 - acc: 0.9799 - f1_m: 0.9799 - precision_m: 0.9799 - recall_m: 0.9799 - val_loss: 0.3339 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0684 - acc: 0.9855 - f1_m: 0.9855 - precision_m: 0.9855 - recall_m: 0.9855 - val_loss: 0.3378 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0531 - acc: 0.9888 - f1_m: 0.9887 - precision_m: 0.9888 - recall_m: 0.9888 - val_loss: 0.3402 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0420 - acc: 0.9913 - f1_m: 0.9912 - precision_m: 0.9913 - recall_m: 0.9913 - val_loss: 0.3431 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0344 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.3575 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0290 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.3639 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0251 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.3765 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0218 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3915 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0198 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.3967 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0176 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.3973 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0169 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4248 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0161 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4171 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0144 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4290 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0139 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4359 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0132 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4324 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0131 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4570 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0129 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4535 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0123 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4603 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0122 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4615 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0114 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4881 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0132 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4691 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0116 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4741 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0115 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4991 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0117 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4837 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0107 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5032 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0108 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4911 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0103 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5075 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0107 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5132 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0103 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5134 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0104 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5194 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0098 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5191 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0100 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5231 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0100 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5239 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0102 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5358 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0097 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5323 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0101 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5334 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0107 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5352 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0101 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5540 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0103 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5495 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0094 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5415 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0102 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5580 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "4001/4001 [==============================] - 0s 77us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/1epwifov\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 4s 291us/step - loss: 0.6777 - acc: 0.5863 - f1_m: 0.5863 - precision_m: 0.5863 - recall_m: 0.5863 - val_loss: 0.6653 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6571 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6492 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6290 - acc: 0.6090 - f1_m: 0.6090 - precision_m: 0.6090 - recall_m: 0.6090 - val_loss: 0.6172 - val_acc: 0.6200 - val_f1_m: 0.6200 - val_precision_m: 0.6200 - val_recall_m: 0.6200\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.5690 - acc: 0.6968 - f1_m: 0.6968 - precision_m: 0.6968 - recall_m: 0.6968 - val_loss: 0.5579 - val_acc: 0.7309 - val_f1_m: 0.7309 - val_precision_m: 0.7309 - val_recall_m: 0.7309\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4748 - acc: 0.8193 - f1_m: 0.8193 - precision_m: 0.8193 - recall_m: 0.8193 - val_loss: 0.4918 - val_acc: 0.7706 - val_f1_m: 0.7706 - val_precision_m: 0.7706 - val_recall_m: 0.7706\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3715 - acc: 0.8736 - f1_m: 0.8736 - precision_m: 0.8736 - recall_m: 0.8736 - val_loss: 0.4358 - val_acc: 0.7969 - val_f1_m: 0.7969 - val_precision_m: 0.7969 - val_recall_m: 0.7969\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2774 - acc: 0.9127 - f1_m: 0.9127 - precision_m: 0.9127 - recall_m: 0.9127 - val_loss: 0.3935 - val_acc: 0.8137 - val_f1_m: 0.8137 - val_precision_m: 0.8137 - val_recall_m: 0.8137\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2004 - acc: 0.9421 - f1_m: 0.9421 - precision_m: 0.9421 - recall_m: 0.9421 - val_loss: 0.3605 - val_acc: 0.8359 - val_f1_m: 0.8359 - val_precision_m: 0.8359 - val_recall_m: 0.8359\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1433 - acc: 0.9620 - f1_m: 0.9620 - precision_m: 0.9620 - recall_m: 0.9620 - val_loss: 0.3436 - val_acc: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1017 - acc: 0.9753 - f1_m: 0.9753 - precision_m: 0.9753 - recall_m: 0.9753 - val_loss: 0.3344 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0748 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - val_loss: 0.3349 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0555 - acc: 0.9882 - f1_m: 0.9882 - precision_m: 0.9882 - recall_m: 0.9882 - val_loss: 0.3438 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0429 - acc: 0.9914 - f1_m: 0.9914 - precision_m: 0.9914 - recall_m: 0.9914 - val_loss: 0.3481 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0350 - acc: 0.9926 - f1_m: 0.9926 - precision_m: 0.9926 - recall_m: 0.9926 - val_loss: 0.3522 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0289 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3567 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0258 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3699 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0216 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3722 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0194 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3826 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0181 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.3877 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0173 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3925 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0157 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.3985 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0147 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4183 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0148 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4141 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0139 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4189 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0131 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4191 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0123 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4421 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0117 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4355 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0118 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4439 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0111 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4451 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0112 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4593 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0110 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4494 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0108 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4613 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0108 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4672 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0110 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4722 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0102 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4735 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0112 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4685 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0103 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4862 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0103 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4839 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0104 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4889 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0118 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4843 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0100 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4910 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0105 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4892 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0106 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5070 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0099 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.4950 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0099 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5033 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0094 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5050 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0098 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5089 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0102 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5106 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0094 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5058 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0093 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5230 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "4001/4001 [==============================] - 0s 80us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/gakv2bgs\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 4s 318us/step - loss: 0.6834 - acc: 0.5912 - f1_m: 0.5824 - precision_m: 0.5881 - recall_m: 0.5782 - val_loss: 0.6703 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.6693 - acc: 0.6075 - f1_m: 0.6075 - precision_m: 0.6075 - recall_m: 0.6075 - val_loss: 0.6568 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.6571 - acc: 0.6092 - f1_m: 0.6092 - precision_m: 0.6092 - recall_m: 0.6092 - val_loss: 0.6434 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.6399 - acc: 0.6200 - f1_m: 0.6200 - precision_m: 0.6200 - recall_m: 0.6200 - val_loss: 0.6246 - val_acc: 0.6172 - val_f1_m: 0.6172 - val_precision_m: 0.6172 - val_recall_m: 0.6172\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.6185 - acc: 0.6323 - f1_m: 0.6323 - precision_m: 0.6323 - recall_m: 0.6323 - val_loss: 0.6005 - val_acc: 0.6391 - val_f1_m: 0.6391 - val_precision_m: 0.6391 - val_recall_m: 0.6391\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.5906 - acc: 0.6491 - f1_m: 0.6491 - precision_m: 0.6491 - recall_m: 0.6491 - val_loss: 0.5720 - val_acc: 0.7197 - val_f1_m: 0.7197 - val_precision_m: 0.7197 - val_recall_m: 0.7197\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.5630 - acc: 0.6742 - f1_m: 0.6742 - precision_m: 0.6742 - recall_m: 0.6742 - val_loss: 0.5408 - val_acc: 0.7531 - val_f1_m: 0.7531 - val_precision_m: 0.7531 - val_recall_m: 0.7531\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.5286 - acc: 0.7040 - f1_m: 0.7040 - precision_m: 0.7040 - recall_m: 0.7040 - val_loss: 0.5105 - val_acc: 0.7756 - val_f1_m: 0.7756 - val_precision_m: 0.7756 - val_recall_m: 0.7756\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.4965 - acc: 0.7200 - f1_m: 0.7200 - precision_m: 0.7200 - recall_m: 0.7200 - val_loss: 0.4802 - val_acc: 0.8100 - val_f1_m: 0.8100 - val_precision_m: 0.8100 - val_recall_m: 0.8100\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.4685 - acc: 0.7299 - f1_m: 0.7299 - precision_m: 0.7299 - recall_m: 0.7299 - val_loss: 0.4519 - val_acc: 0.8278 - val_f1_m: 0.8278 - val_precision_m: 0.8278 - val_recall_m: 0.8278\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.4350 - acc: 0.7454 - f1_m: 0.7454 - precision_m: 0.7454 - recall_m: 0.7454 - val_loss: 0.4280 - val_acc: 0.8400 - val_f1_m: 0.8400 - val_precision_m: 0.8400 - val_recall_m: 0.8400\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.4109 - acc: 0.7559 - f1_m: 0.7559 - precision_m: 0.7559 - recall_m: 0.7559 - val_loss: 0.4054 - val_acc: 0.8466 - val_f1_m: 0.8466 - val_precision_m: 0.8466 - val_recall_m: 0.8466\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.3846 - acc: 0.7560 - f1_m: 0.7560 - precision_m: 0.7560 - recall_m: 0.7560 - val_loss: 0.3873 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.3667 - acc: 0.7628 - f1_m: 0.7628 - precision_m: 0.7628 - recall_m: 0.7628 - val_loss: 0.3669 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.3523 - acc: 0.7668 - f1_m: 0.7668 - precision_m: 0.7668 - recall_m: 0.7668 - val_loss: 0.3518 - val_acc: 0.8744 - val_f1_m: 0.8744 - val_precision_m: 0.8744 - val_recall_m: 0.8744\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.3312 - acc: 0.7726 - f1_m: 0.7726 - precision_m: 0.7726 - recall_m: 0.7726 - val_loss: 0.3412 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.3173 - acc: 0.7775 - f1_m: 0.7775 - precision_m: 0.7775 - recall_m: 0.7775 - val_loss: 0.3289 - val_acc: 0.8844 - val_f1_m: 0.8844 - val_precision_m: 0.8844 - val_recall_m: 0.8844\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.3078 - acc: 0.7732 - f1_m: 0.7732 - precision_m: 0.7732 - recall_m: 0.7732 - val_loss: 0.3207 - val_acc: 0.8884 - val_f1_m: 0.8884 - val_precision_m: 0.8884 - val_recall_m: 0.8884\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.3037 - acc: 0.7750 - f1_m: 0.7750 - precision_m: 0.7750 - recall_m: 0.7750 - val_loss: 0.3130 - val_acc: 0.8869 - val_f1_m: 0.8869 - val_precision_m: 0.8869 - val_recall_m: 0.8869\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2912 - acc: 0.8184 - f1_m: 0.8184 - precision_m: 0.8184 - recall_m: 0.8184 - val_loss: 0.3098 - val_acc: 0.8888 - val_f1_m: 0.8887 - val_precision_m: 0.8888 - val_recall_m: 0.8888\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2818 - acc: 0.8286 - f1_m: 0.8286 - precision_m: 0.8286 - recall_m: 0.8286 - val_loss: 0.3030 - val_acc: 0.8869 - val_f1_m: 0.8869 - val_precision_m: 0.8869 - val_recall_m: 0.8869\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2664 - acc: 0.8355 - f1_m: 0.8355 - precision_m: 0.8355 - recall_m: 0.8355 - val_loss: 0.3062 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2559 - acc: 0.8395 - f1_m: 0.8395 - precision_m: 0.8395 - recall_m: 0.8395 - val_loss: 0.3002 - val_acc: 0.8900 - val_f1_m: 0.8900 - val_precision_m: 0.8900 - val_recall_m: 0.8900\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2464 - acc: 0.8420 - f1_m: 0.8420 - precision_m: 0.8420 - recall_m: 0.8420 - val_loss: 0.3028 - val_acc: 0.8809 - val_f1_m: 0.8809 - val_precision_m: 0.8809 - val_recall_m: 0.8809\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2433 - acc: 0.8434 - f1_m: 0.8434 - precision_m: 0.8434 - recall_m: 0.8434 - val_loss: 0.3030 - val_acc: 0.8809 - val_f1_m: 0.8809 - val_precision_m: 0.8809 - val_recall_m: 0.8809\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2404 - acc: 0.8445 - f1_m: 0.8445 - precision_m: 0.8445 - recall_m: 0.8445 - val_loss: 0.3044 - val_acc: 0.8822 - val_f1_m: 0.8822 - val_precision_m: 0.8822 - val_recall_m: 0.8822\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.2363 - acc: 0.8353 - f1_m: 0.8353 - precision_m: 0.8353 - recall_m: 0.8353 - val_loss: 0.3106 - val_acc: 0.8778 - val_f1_m: 0.8778 - val_precision_m: 0.8778 - val_recall_m: 0.8778\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2244 - acc: 0.8459 - f1_m: 0.8459 - precision_m: 0.8459 - recall_m: 0.8459 - val_loss: 0.3079 - val_acc: 0.8822 - val_f1_m: 0.8822 - val_precision_m: 0.8822 - val_recall_m: 0.8822\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.2136 - acc: 0.8473 - f1_m: 0.8473 - precision_m: 0.8473 - recall_m: 0.8473 - val_loss: 0.3182 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.2067 - acc: 0.8513 - f1_m: 0.8513 - precision_m: 0.8513 - recall_m: 0.8513 - val_loss: 0.3240 - val_acc: 0.8781 - val_f1_m: 0.8781 - val_precision_m: 0.8781 - val_recall_m: 0.8781\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1990 - acc: 0.8489 - f1_m: 0.8489 - precision_m: 0.8489 - recall_m: 0.8489 - val_loss: 0.3297 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2066 - acc: 0.8509 - f1_m: 0.8509 - precision_m: 0.8509 - recall_m: 0.8509 - val_loss: 0.3337 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2103 - acc: 0.8731 - f1_m: 0.8731 - precision_m: 0.8731 - recall_m: 0.8731 - val_loss: 0.3428 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1950 - acc: 0.8906 - f1_m: 0.8906 - precision_m: 0.8906 - recall_m: 0.8906 - val_loss: 0.3494 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1883 - acc: 0.8956 - f1_m: 0.8956 - precision_m: 0.8956 - recall_m: 0.8956 - val_loss: 0.3577 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1868 - acc: 0.8981 - f1_m: 0.8981 - precision_m: 0.8981 - recall_m: 0.8981 - val_loss: 0.3638 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1829 - acc: 0.8985 - f1_m: 0.8985 - precision_m: 0.8985 - recall_m: 0.8985 - val_loss: 0.3644 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1813 - acc: 0.9020 - f1_m: 0.9020 - precision_m: 0.9020 - recall_m: 0.9020 - val_loss: 0.3799 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1695 - acc: 0.9118 - f1_m: 0.9118 - precision_m: 0.9118 - recall_m: 0.9118 - val_loss: 0.3849 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1747 - acc: 0.9105 - f1_m: 0.9105 - precision_m: 0.9105 - recall_m: 0.9105 - val_loss: 0.3866 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1678 - acc: 0.9147 - f1_m: 0.9147 - precision_m: 0.9147 - recall_m: 0.9147 - val_loss: 0.4009 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1628 - acc: 0.9205 - f1_m: 0.9205 - precision_m: 0.9205 - recall_m: 0.9205 - val_loss: 0.4071 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1604 - acc: 0.9234 - f1_m: 0.9234 - precision_m: 0.9234 - recall_m: 0.9234 - val_loss: 0.4181 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1600 - acc: 0.9217 - f1_m: 0.9217 - precision_m: 0.9217 - recall_m: 0.9217 - val_loss: 0.4379 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1567 - acc: 0.9211 - f1_m: 0.9211 - precision_m: 0.9211 - recall_m: 0.9211 - val_loss: 0.4373 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1526 - acc: 0.9262 - f1_m: 0.9262 - precision_m: 0.9262 - recall_m: 0.9262 - val_loss: 0.4393 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1565 - acc: 0.9235 - f1_m: 0.9235 - precision_m: 0.9235 - recall_m: 0.9235 - val_loss: 0.4579 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1538 - acc: 0.9234 - f1_m: 0.9234 - precision_m: 0.9234 - recall_m: 0.9234 - val_loss: 0.4536 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1538 - acc: 0.9240 - f1_m: 0.9240 - precision_m: 0.9240 - recall_m: 0.9240 - val_loss: 0.4574 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1496 - acc: 0.9260 - f1_m: 0.9260 - precision_m: 0.9260 - recall_m: 0.9260 - val_loss: 0.4714 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "4001/4001 [==============================] - 0s 79us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/a5had4f6\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 4s 333us/step - loss: 0.6760 - acc: 0.5841 - f1_m: 0.5841 - precision_m: 0.5841 - recall_m: 0.5841 - val_loss: 0.6606 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.6453 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6324 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5973 - acc: 0.6255 - f1_m: 0.6255 - precision_m: 0.6255 - recall_m: 0.6255 - val_loss: 0.5807 - val_acc: 0.6856 - val_f1_m: 0.6856 - val_precision_m: 0.6856 - val_recall_m: 0.6856\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5156 - acc: 0.7701 - f1_m: 0.7701 - precision_m: 0.7701 - recall_m: 0.7701 - val_loss: 0.5150 - val_acc: 0.7647 - val_f1_m: 0.7647 - val_precision_m: 0.7647 - val_recall_m: 0.7647\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4194 - acc: 0.8527 - f1_m: 0.8527 - precision_m: 0.8527 - recall_m: 0.8527 - val_loss: 0.4560 - val_acc: 0.7956 - val_f1_m: 0.7956 - val_precision_m: 0.7956 - val_recall_m: 0.7956\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3230 - acc: 0.9002 - f1_m: 0.9002 - precision_m: 0.9002 - recall_m: 0.9002 - val_loss: 0.4076 - val_acc: 0.8181 - val_f1_m: 0.8181 - val_precision_m: 0.8181 - val_recall_m: 0.8181\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2385 - acc: 0.9362 - f1_m: 0.9362 - precision_m: 0.9362 - recall_m: 0.9362 - val_loss: 0.3670 - val_acc: 0.8331 - val_f1_m: 0.8331 - val_precision_m: 0.8331 - val_recall_m: 0.8331\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1700 - acc: 0.9585 - f1_m: 0.9585 - precision_m: 0.9585 - recall_m: 0.9585 - val_loss: 0.3401 - val_acc: 0.8484 - val_f1_m: 0.8484 - val_precision_m: 0.8484 - val_recall_m: 0.8484\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1195 - acc: 0.9739 - f1_m: 0.9739 - precision_m: 0.9739 - recall_m: 0.9739 - val_loss: 0.3277 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0863 - acc: 0.9826 - f1_m: 0.9826 - precision_m: 0.9826 - recall_m: 0.9826 - val_loss: 0.3188 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0644 - acc: 0.9874 - f1_m: 0.9874 - precision_m: 0.9874 - recall_m: 0.9874 - val_loss: 0.3289 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0498 - acc: 0.9899 - f1_m: 0.9899 - precision_m: 0.9899 - recall_m: 0.9899 - val_loss: 0.3328 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0394 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3261 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0319 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3448 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0272 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.3451 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0232 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3511 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0203 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3558 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0186 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.3714 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0169 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.3651 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0161 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.3873 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0147 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3777 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0141 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3901 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0137 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.3926 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0133 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4004 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0127 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4122 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0130 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4034 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0130 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4226 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0122 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4178 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0125 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4333 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0117 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4160 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0113 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4404 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0110 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4274 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0116 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4410 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0106 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4449 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0109 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4391 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0100 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4500 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0106 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4443 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0107 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4629 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0108 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4535 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0107 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4761 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0103 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4547 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0099 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4715 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0096 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4681 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0094 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4748 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0101 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4831 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0095 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4695 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0095 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4925 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0096 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4778 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0101 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4879 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0094 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4865 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "4001/4001 [==============================] - 0s 81us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/8uospnwv\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 4s 313us/step - loss: 0.6753 - acc: 0.5927 - f1_m: 0.5927 - precision_m: 0.5927 - recall_m: 0.5927 - val_loss: 0.6618 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6491 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6369 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6075 - acc: 0.6320 - f1_m: 0.6320 - precision_m: 0.6320 - recall_m: 0.6320 - val_loss: 0.5938 - val_acc: 0.6669 - val_f1_m: 0.6669 - val_precision_m: 0.6669 - val_recall_m: 0.6669\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.5364 - acc: 0.7537 - f1_m: 0.7537 - precision_m: 0.7537 - recall_m: 0.7537 - val_loss: 0.5330 - val_acc: 0.7491 - val_f1_m: 0.7491 - val_precision_m: 0.7491 - val_recall_m: 0.7491\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4430 - acc: 0.8438 - f1_m: 0.8438 - precision_m: 0.8438 - recall_m: 0.8438 - val_loss: 0.4720 - val_acc: 0.7778 - val_f1_m: 0.7778 - val_precision_m: 0.7778 - val_recall_m: 0.7778\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3479 - acc: 0.8823 - f1_m: 0.8823 - precision_m: 0.8823 - recall_m: 0.8823 - val_loss: 0.4244 - val_acc: 0.7991 - val_f1_m: 0.7991 - val_precision_m: 0.7991 - val_recall_m: 0.7991\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2616 - acc: 0.9208 - f1_m: 0.9208 - precision_m: 0.9208 - recall_m: 0.9208 - val_loss: 0.3892 - val_acc: 0.8128 - val_f1_m: 0.8128 - val_precision_m: 0.8128 - val_recall_m: 0.8128\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1907 - acc: 0.9486 - f1_m: 0.9486 - precision_m: 0.9486 - recall_m: 0.9486 - val_loss: 0.3615 - val_acc: 0.8281 - val_f1_m: 0.8281 - val_precision_m: 0.8281 - val_recall_m: 0.8281\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1356 - acc: 0.9684 - f1_m: 0.9684 - precision_m: 0.9684 - recall_m: 0.9684 - val_loss: 0.3441 - val_acc: 0.8406 - val_f1_m: 0.8406 - val_precision_m: 0.8406 - val_recall_m: 0.8406\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0980 - acc: 0.9777 - f1_m: 0.9777 - precision_m: 0.9777 - recall_m: 0.9777 - val_loss: 0.3418 - val_acc: 0.8422 - val_f1_m: 0.8422 - val_precision_m: 0.8422 - val_recall_m: 0.8422\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0711 - acc: 0.9854 - f1_m: 0.9854 - precision_m: 0.9854 - recall_m: 0.9854 - val_loss: 0.3328 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0537 - acc: 0.9893 - f1_m: 0.9893 - precision_m: 0.9893 - recall_m: 0.9893 - val_loss: 0.3411 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0419 - acc: 0.9917 - f1_m: 0.9917 - precision_m: 0.9917 - recall_m: 0.9917 - val_loss: 0.3359 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0333 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3482 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0278 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.3577 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0240 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3681 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0212 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3615 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0189 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3832 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0174 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3704 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0164 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3987 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0154 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3836 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0140 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4080 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0135 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.3989 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0128 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4129 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0124 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4145 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0124 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4219 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0117 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4217 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0117 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4226 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0112 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4410 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0113 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4353 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0111 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4400 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0107 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4422 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0105 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4463 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0105 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4493 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0102 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4540 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0104 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4666 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0104 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4577 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0098 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4634 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0095 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4624 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0097 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4641 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0095 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4732 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0094 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4751 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0099 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4700 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0096 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4802 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0097 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4815 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0097 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4817 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0093 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4915 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0092 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.4883 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0090 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4864 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0092 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4998 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "4001/4001 [==============================] - 0s 82us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/k6bat32d\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 4s 316us/step - loss: 0.6799 - acc: 0.5761 - f1_m: 0.5761 - precision_m: 0.5761 - recall_m: 0.5761 - val_loss: 0.6688 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.6671 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6593 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.6519 - acc: 0.6074 - f1_m: 0.6074 - precision_m: 0.6074 - recall_m: 0.6074 - val_loss: 0.6420 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6214 - acc: 0.6147 - f1_m: 0.6147 - precision_m: 0.6147 - recall_m: 0.6147 - val_loss: 0.6097 - val_acc: 0.6206 - val_f1_m: 0.6206 - val_precision_m: 0.6206 - val_recall_m: 0.6206\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.5719 - acc: 0.6775 - f1_m: 0.6775 - precision_m: 0.6775 - recall_m: 0.6775 - val_loss: 0.5622 - val_acc: 0.7087 - val_f1_m: 0.7087 - val_precision_m: 0.7087 - val_recall_m: 0.7087\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.5028 - acc: 0.7763 - f1_m: 0.7763 - precision_m: 0.7763 - recall_m: 0.7763 - val_loss: 0.5097 - val_acc: 0.7609 - val_f1_m: 0.7609 - val_precision_m: 0.7609 - val_recall_m: 0.7609\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.4244 - acc: 0.8324 - f1_m: 0.8324 - precision_m: 0.8324 - recall_m: 0.8324 - val_loss: 0.4598 - val_acc: 0.7928 - val_f1_m: 0.7928 - val_precision_m: 0.7928 - val_recall_m: 0.7928\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.3474 - acc: 0.8752 - f1_m: 0.8752 - precision_m: 0.8752 - recall_m: 0.8752 - val_loss: 0.4194 - val_acc: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.2802 - acc: 0.9087 - f1_m: 0.9087 - precision_m: 0.9087 - recall_m: 0.9087 - val_loss: 0.3866 - val_acc: 0.8269 - val_f1_m: 0.8269 - val_precision_m: 0.8269 - val_recall_m: 0.8269\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.2183 - acc: 0.9363 - f1_m: 0.9362 - precision_m: 0.9363 - recall_m: 0.9363 - val_loss: 0.3635 - val_acc: 0.8381 - val_f1_m: 0.8381 - val_precision_m: 0.8381 - val_recall_m: 0.8381\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.1732 - acc: 0.9545 - f1_m: 0.9545 - precision_m: 0.9545 - recall_m: 0.9545 - val_loss: 0.3498 - val_acc: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1364 - acc: 0.9650 - f1_m: 0.9650 - precision_m: 0.9650 - recall_m: 0.9650 - val_loss: 0.3433 - val_acc: 0.8478 - val_f1_m: 0.8478 - val_precision_m: 0.8478 - val_recall_m: 0.8478\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1075 - acc: 0.9755 - f1_m: 0.9755 - precision_m: 0.9755 - recall_m: 0.9755 - val_loss: 0.3390 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0833 - acc: 0.9827 - f1_m: 0.9827 - precision_m: 0.9827 - recall_m: 0.9827 - val_loss: 0.3389 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0667 - acc: 0.9862 - f1_m: 0.9862 - precision_m: 0.9862 - recall_m: 0.9862 - val_loss: 0.3512 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0561 - acc: 0.9890 - f1_m: 0.9890 - precision_m: 0.9890 - recall_m: 0.9890 - val_loss: 0.3600 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0474 - acc: 0.9907 - f1_m: 0.9907 - precision_m: 0.9907 - recall_m: 0.9907 - val_loss: 0.3642 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0397 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.3790 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0353 - acc: 0.9922 - f1_m: 0.9922 - precision_m: 0.9922 - recall_m: 0.9922 - val_loss: 0.3852 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0302 - acc: 0.9938 - f1_m: 0.9938 - precision_m: 0.9938 - recall_m: 0.9938 - val_loss: 0.3997 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0279 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.4062 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0250 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4232 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0224 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4276 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0221 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.4316 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0202 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4500 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0193 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4487 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0185 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4693 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0173 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4823 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0169 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4740 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0161 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4894 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0154 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4981 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0161 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5002 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0140 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5148 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0139 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5253 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0135 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5225 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0137 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5297 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0129 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5425 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0136 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5364 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0125 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5534 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0125 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5587 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0127 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5665 - val_acc: 0.8516 - val_f1_m: 0.8516 - val_precision_m: 0.8516 - val_recall_m: 0.8516\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0121 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5663 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0120 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5771 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0122 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5837 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0111 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5779 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5878 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0114 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6012 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0118 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5950 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0115 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.6169 - val_acc: 0.8512 - val_f1_m: 0.8512 - val_precision_m: 0.8512 - val_recall_m: 0.8512\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.6106 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "4001/4001 [==============================] - 0s 84us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/silybcgm\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 4s 332us/step - loss: 0.6755 - acc: 0.5960 - f1_m: 0.5960 - precision_m: 0.5960 - recall_m: 0.5960 - val_loss: 0.6615 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.6517 - acc: 0.6074 - f1_m: 0.6074 - precision_m: 0.6074 - recall_m: 0.6074 - val_loss: 0.6385 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.6068 - acc: 0.6602 - f1_m: 0.6602 - precision_m: 0.6602 - recall_m: 0.6602 - val_loss: 0.5876 - val_acc: 0.6666 - val_f1_m: 0.6666 - val_precision_m: 0.6666 - val_recall_m: 0.6666\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5208 - acc: 0.7679 - f1_m: 0.7679 - precision_m: 0.7679 - recall_m: 0.7679 - val_loss: 0.5147 - val_acc: 0.7641 - val_f1_m: 0.7641 - val_precision_m: 0.7641 - val_recall_m: 0.7641\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4125 - acc: 0.8423 - f1_m: 0.8423 - precision_m: 0.8423 - recall_m: 0.8423 - val_loss: 0.4520 - val_acc: 0.7869 - val_f1_m: 0.7869 - val_precision_m: 0.7869 - val_recall_m: 0.7869\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.3102 - acc: 0.8876 - f1_m: 0.8876 - precision_m: 0.8876 - recall_m: 0.8876 - val_loss: 0.4049 - val_acc: 0.8087 - val_f1_m: 0.8087 - val_precision_m: 0.8087 - val_recall_m: 0.8087\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2252 - acc: 0.9309 - f1_m: 0.9309 - precision_m: 0.9309 - recall_m: 0.9309 - val_loss: 0.3662 - val_acc: 0.8313 - val_f1_m: 0.8312 - val_precision_m: 0.8313 - val_recall_m: 0.8313\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1558 - acc: 0.9595 - f1_m: 0.9595 - precision_m: 0.9595 - recall_m: 0.9595 - val_loss: 0.3467 - val_acc: 0.8453 - val_f1_m: 0.8453 - val_precision_m: 0.8453 - val_recall_m: 0.8453\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1104 - acc: 0.9743 - f1_m: 0.9743 - precision_m: 0.9743 - recall_m: 0.9743 - val_loss: 0.3355 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0773 - acc: 0.9836 - f1_m: 0.9836 - precision_m: 0.9836 - recall_m: 0.9836 - val_loss: 0.3347 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0572 - acc: 0.9888 - f1_m: 0.9887 - precision_m: 0.9888 - recall_m: 0.9888 - val_loss: 0.3343 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0445 - acc: 0.9905 - f1_m: 0.9905 - precision_m: 0.9905 - recall_m: 0.9905 - val_loss: 0.3388 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0351 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3483 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0293 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.3492 - val_acc: 0.8762 - val_f1_m: 0.8762 - val_precision_m: 0.8762 - val_recall_m: 0.8762\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0255 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3880 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0228 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3679 - val_acc: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0202 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.3820 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0181 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3982 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0165 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3960 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0158 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4150 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0151 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4140 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0139 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4255 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0131 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4265 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0125 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4312 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0120 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4454 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0122 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4450 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0121 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4524 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0117 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4556 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0113 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4784 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0114 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4623 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0115 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4871 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0115 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4681 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0112 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4803 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0105 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4948 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0104 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4873 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0106 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5051 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0111 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4921 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0113 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4997 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0101 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5211 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0105 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4966 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0104 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5244 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0103 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5208 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0097 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5105 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0099 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5323 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0105 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5137 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0097 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5354 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0094 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5403 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0102 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5269 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0100 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5344 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0092 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5402 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "4001/4001 [==============================] - 0s 89us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/k8zeeiix\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 4s 341us/step - loss: 0.6745 - acc: 0.6052 - f1_m: 0.6052 - precision_m: 0.6052 - recall_m: 0.6052 - val_loss: 0.6632 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6539 - acc: 0.6070 - f1_m: 0.6070 - precision_m: 0.6070 - recall_m: 0.6070 - val_loss: 0.6448 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6223 - acc: 0.6181 - f1_m: 0.6181 - precision_m: 0.6181 - recall_m: 0.6181 - val_loss: 0.6110 - val_acc: 0.6284 - val_f1_m: 0.6284 - val_precision_m: 0.6284 - val_recall_m: 0.6284\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.5671 - acc: 0.7009 - f1_m: 0.7009 - precision_m: 0.7009 - recall_m: 0.7009 - val_loss: 0.5606 - val_acc: 0.7316 - val_f1_m: 0.7316 - val_precision_m: 0.7316 - val_recall_m: 0.7316\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.4919 - acc: 0.8041 - f1_m: 0.8041 - precision_m: 0.8041 - recall_m: 0.8041 - val_loss: 0.5056 - val_acc: 0.7741 - val_f1_m: 0.7741 - val_precision_m: 0.7741 - val_recall_m: 0.7741\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.4104 - acc: 0.8548 - f1_m: 0.8548 - precision_m: 0.8548 - recall_m: 0.8548 - val_loss: 0.4567 - val_acc: 0.7916 - val_f1_m: 0.7916 - val_precision_m: 0.7916 - val_recall_m: 0.7916\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3335 - acc: 0.8920 - f1_m: 0.8920 - precision_m: 0.8920 - recall_m: 0.8920 - val_loss: 0.4161 - val_acc: 0.8094 - val_f1_m: 0.8094 - val_precision_m: 0.8094 - val_recall_m: 0.8094\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2645 - acc: 0.9183 - f1_m: 0.9183 - precision_m: 0.9183 - recall_m: 0.9183 - val_loss: 0.3845 - val_acc: 0.8263 - val_f1_m: 0.8262 - val_precision_m: 0.8263 - val_recall_m: 0.8263\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2072 - acc: 0.9437 - f1_m: 0.9437 - precision_m: 0.9437 - recall_m: 0.9437 - val_loss: 0.3592 - val_acc: 0.8394 - val_f1_m: 0.8394 - val_precision_m: 0.8394 - val_recall_m: 0.8394\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1573 - acc: 0.9609 - f1_m: 0.9609 - precision_m: 0.9609 - recall_m: 0.9609 - val_loss: 0.3424 - val_acc: 0.8488 - val_f1_m: 0.8487 - val_precision_m: 0.8488 - val_recall_m: 0.8488\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1219 - acc: 0.9705 - f1_m: 0.9705 - precision_m: 0.9705 - recall_m: 0.9705 - val_loss: 0.3283 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0933 - acc: 0.9799 - f1_m: 0.9799 - precision_m: 0.9799 - recall_m: 0.9799 - val_loss: 0.3339 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0736 - acc: 0.9854 - f1_m: 0.9854 - precision_m: 0.9854 - recall_m: 0.9854 - val_loss: 0.3252 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0605 - acc: 0.9859 - f1_m: 0.9859 - precision_m: 0.9859 - recall_m: 0.9859 - val_loss: 0.3312 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0482 - acc: 0.9896 - f1_m: 0.9896 - precision_m: 0.9896 - recall_m: 0.9896 - val_loss: 0.3464 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0406 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.3405 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0340 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3527 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0294 - acc: 0.9927 - f1_m: 0.9927 - precision_m: 0.9927 - recall_m: 0.9927 - val_loss: 0.3522 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0267 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3617 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0235 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.3660 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0214 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3784 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0194 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3785 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0187 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3862 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0182 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3991 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0171 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.3902 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0161 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4104 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0153 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4055 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0149 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4194 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0138 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4198 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0136 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4226 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0128 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4332 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0125 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4376 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0119 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4425 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0124 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4399 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0117 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4518 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0120 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4488 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0116 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4571 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0110 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4655 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0109 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4698 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0111 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4679 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0108 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4734 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0107 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4822 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0112 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4793 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0111 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4831 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0109 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4991 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0108 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4826 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0103 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4981 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0105 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4912 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0104 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5019 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0102 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4980 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "4001/4001 [==============================] - 0s 83us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/moq8oupa\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 5s 356us/step - loss: 0.6713 - acc: 0.6016 - f1_m: 0.6016 - precision_m: 0.6016 - recall_m: 0.6016 - val_loss: 0.6569 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.6409 - acc: 0.6069 - f1_m: 0.6069 - precision_m: 0.6069 - recall_m: 0.6069 - val_loss: 0.6263 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5907 - acc: 0.6354 - f1_m: 0.6354 - precision_m: 0.6354 - recall_m: 0.6354 - val_loss: 0.5751 - val_acc: 0.6747 - val_f1_m: 0.6747 - val_precision_m: 0.6747 - val_recall_m: 0.6747\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5165 - acc: 0.7555 - f1_m: 0.7555 - precision_m: 0.7555 - recall_m: 0.7555 - val_loss: 0.5154 - val_acc: 0.7622 - val_f1_m: 0.7622 - val_precision_m: 0.7622 - val_recall_m: 0.7622\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.4296 - acc: 0.8412 - f1_m: 0.8412 - precision_m: 0.8412 - recall_m: 0.8412 - val_loss: 0.4579 - val_acc: 0.7994 - val_f1_m: 0.7994 - val_precision_m: 0.7994 - val_recall_m: 0.7994\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.3421 - acc: 0.8855 - f1_m: 0.8855 - precision_m: 0.8855 - recall_m: 0.8855 - val_loss: 0.4093 - val_acc: 0.8137 - val_f1_m: 0.8137 - val_precision_m: 0.8137 - val_recall_m: 0.8137\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2633 - acc: 0.9212 - f1_m: 0.9212 - precision_m: 0.9212 - recall_m: 0.9212 - val_loss: 0.3713 - val_acc: 0.8337 - val_f1_m: 0.8337 - val_precision_m: 0.8337 - val_recall_m: 0.8337\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1962 - acc: 0.9451 - f1_m: 0.9451 - precision_m: 0.9451 - recall_m: 0.9451 - val_loss: 0.3436 - val_acc: 0.8450 - val_f1_m: 0.8450 - val_precision_m: 0.8450 - val_recall_m: 0.8450\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1425 - acc: 0.9662 - f1_m: 0.9662 - precision_m: 0.9662 - recall_m: 0.9662 - val_loss: 0.3280 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1037 - acc: 0.9756 - f1_m: 0.9756 - precision_m: 0.9756 - recall_m: 0.9756 - val_loss: 0.3210 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0792 - acc: 0.9836 - f1_m: 0.9836 - precision_m: 0.9836 - recall_m: 0.9836 - val_loss: 0.3260 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0601 - acc: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865 - val_loss: 0.3373 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0488 - acc: 0.9909 - f1_m: 0.9909 - precision_m: 0.9909 - recall_m: 0.9909 - val_loss: 0.3459 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0414 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.3456 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0339 - acc: 0.9927 - f1_m: 0.9927 - precision_m: 0.9927 - recall_m: 0.9927 - val_loss: 0.3541 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0293 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.3714 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0259 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.3711 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0236 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3885 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0207 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3900 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0189 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4024 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0182 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4152 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0174 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4249 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0172 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4188 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0151 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4570 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0147 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4382 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0142 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4417 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0141 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4555 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0128 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4660 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0126 - acc: 0.9963 - f1_m: 0.9963 - precision_m: 0.9963 - recall_m: 0.9963 - val_loss: 0.4698 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0132 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4919 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0134 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4784 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0125 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4948 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0120 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4828 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0114 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5056 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0123 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5104 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0114 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5041 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0110 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5230 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0103 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5252 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0109 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5258 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0108 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5363 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0099 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5348 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0105 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5350 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0104 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5466 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0109 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5618 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0099 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5491 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0105 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5607 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0098 - acc: 0.9964 - f1_m: 0.9964 - precision_m: 0.9964 - recall_m: 0.9964 - val_loss: 0.5679 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0101 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5602 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0100 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5736 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0095 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5775 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "4001/4001 [==============================] - 0s 84us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/veheoqw7\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 4s 351us/step - loss: 0.6774 - acc: 0.5901 - f1_m: 0.5901 - precision_m: 0.5901 - recall_m: 0.5901 - val_loss: 0.6649 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6593 - acc: 0.6070 - f1_m: 0.6070 - precision_m: 0.6070 - recall_m: 0.6070 - val_loss: 0.6491 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6324 - acc: 0.6142 - f1_m: 0.6142 - precision_m: 0.6142 - recall_m: 0.6142 - val_loss: 0.6185 - val_acc: 0.6244 - val_f1_m: 0.6244 - val_precision_m: 0.6244 - val_recall_m: 0.6244\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.5816 - acc: 0.6776 - f1_m: 0.6776 - precision_m: 0.6776 - recall_m: 0.6776 - val_loss: 0.5664 - val_acc: 0.7269 - val_f1_m: 0.7269 - val_precision_m: 0.7269 - val_recall_m: 0.7269\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.5044 - acc: 0.7866 - f1_m: 0.7866 - precision_m: 0.7866 - recall_m: 0.7866 - val_loss: 0.5046 - val_acc: 0.7753 - val_f1_m: 0.7753 - val_precision_m: 0.7753 - val_recall_m: 0.7753\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.4147 - acc: 0.8448 - f1_m: 0.8448 - precision_m: 0.8448 - recall_m: 0.8448 - val_loss: 0.4480 - val_acc: 0.8003 - val_f1_m: 0.8003 - val_precision_m: 0.8003 - val_recall_m: 0.8003\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3256 - acc: 0.8895 - f1_m: 0.8895 - precision_m: 0.8895 - recall_m: 0.8895 - val_loss: 0.4044 - val_acc: 0.8141 - val_f1_m: 0.8141 - val_precision_m: 0.8141 - val_recall_m: 0.8141\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2483 - acc: 0.9222 - f1_m: 0.9222 - precision_m: 0.9222 - recall_m: 0.9222 - val_loss: 0.3702 - val_acc: 0.8384 - val_f1_m: 0.8384 - val_precision_m: 0.8384 - val_recall_m: 0.8384\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1844 - acc: 0.9502 - f1_m: 0.9502 - precision_m: 0.9502 - recall_m: 0.9502 - val_loss: 0.3482 - val_acc: 0.8469 - val_f1_m: 0.8469 - val_precision_m: 0.8469 - val_recall_m: 0.8469\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1382 - acc: 0.9646 - f1_m: 0.9646 - precision_m: 0.9646 - recall_m: 0.9646 - val_loss: 0.3353 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1018 - acc: 0.9771 - f1_m: 0.9771 - precision_m: 0.9771 - recall_m: 0.9771 - val_loss: 0.3300 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0765 - acc: 0.9842 - f1_m: 0.9842 - precision_m: 0.9842 - recall_m: 0.9842 - val_loss: 0.3276 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0612 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 0.3397 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0488 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.3443 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0400 - acc: 0.9914 - f1_m: 0.9914 - precision_m: 0.9914 - recall_m: 0.9914 - val_loss: 0.3547 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0336 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9932 - recall_m: 0.9932 - val_loss: 0.3691 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0289 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3717 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0256 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.3777 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0228 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4091 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0205 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3936 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0197 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4175 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0178 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4154 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0176 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.4263 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0166 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4466 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0164 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4345 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0140 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4526 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0144 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4582 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0143 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4565 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0138 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4746 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0136 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4787 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0128 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4737 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0123 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4929 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0130 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4977 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0123 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4942 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0122 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5012 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0116 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5037 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5142 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0110 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5183 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0108 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5240 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0113 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5158 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0112 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5310 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0109 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5341 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0109 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5523 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5422 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0105 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5408 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0102 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5556 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0108 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5607 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0106 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5656 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0107 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5535 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0098 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5793 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "4001/4001 [==============================] - 0s 85us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/y6oujhvn\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 5s 370us/step - loss: 0.6730 - acc: 0.5951 - f1_m: 0.5951 - precision_m: 0.5951 - recall_m: 0.5951 - val_loss: 0.6604 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.6512 - acc: 0.6084 - f1_m: 0.6084 - precision_m: 0.6084 - recall_m: 0.6084 - val_loss: 0.6376 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.6108 - acc: 0.6395 - f1_m: 0.6395 - precision_m: 0.6395 - recall_m: 0.6395 - val_loss: 0.5937 - val_acc: 0.6956 - val_f1_m: 0.6956 - val_precision_m: 0.6956 - val_recall_m: 0.6956\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5380 - acc: 0.7599 - f1_m: 0.7599 - precision_m: 0.7599 - recall_m: 0.7599 - val_loss: 0.5278 - val_acc: 0.7612 - val_f1_m: 0.7612 - val_precision_m: 0.7612 - val_recall_m: 0.7612\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.4432 - acc: 0.8311 - f1_m: 0.8311 - precision_m: 0.8311 - recall_m: 0.8311 - val_loss: 0.4660 - val_acc: 0.7900 - val_f1_m: 0.7900 - val_precision_m: 0.7900 - val_recall_m: 0.7900\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.3479 - acc: 0.8770 - f1_m: 0.8770 - precision_m: 0.8770 - recall_m: 0.8770 - val_loss: 0.4150 - val_acc: 0.8116 - val_f1_m: 0.8116 - val_precision_m: 0.8116 - val_recall_m: 0.8116\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2619 - acc: 0.9186 - f1_m: 0.9186 - precision_m: 0.9186 - recall_m: 0.9186 - val_loss: 0.3755 - val_acc: 0.8244 - val_f1_m: 0.8244 - val_precision_m: 0.8244 - val_recall_m: 0.8244\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1896 - acc: 0.9455 - f1_m: 0.9455 - precision_m: 0.9455 - recall_m: 0.9455 - val_loss: 0.3473 - val_acc: 0.8400 - val_f1_m: 0.8400 - val_precision_m: 0.8400 - val_recall_m: 0.8400\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1360 - acc: 0.9676 - f1_m: 0.9676 - precision_m: 0.9676 - recall_m: 0.9676 - val_loss: 0.3337 - val_acc: 0.8525 - val_f1_m: 0.8525 - val_precision_m: 0.8525 - val_recall_m: 0.8525\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0977 - acc: 0.9792 - f1_m: 0.9792 - precision_m: 0.9792 - recall_m: 0.9792 - val_loss: 0.3288 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0716 - acc: 0.9853 - f1_m: 0.9853 - precision_m: 0.9853 - recall_m: 0.9853 - val_loss: 0.3329 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0555 - acc: 0.9880 - f1_m: 0.9880 - precision_m: 0.9880 - recall_m: 0.9880 - val_loss: 0.3356 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0428 - acc: 0.9909 - f1_m: 0.9909 - precision_m: 0.9909 - recall_m: 0.9909 - val_loss: 0.3475 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0353 - acc: 0.9925 - f1_m: 0.9925 - precision_m: 0.9925 - recall_m: 0.9925 - val_loss: 0.3523 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0292 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3693 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0251 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3758 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0226 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3793 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0203 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.3986 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0184 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4034 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0164 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4090 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0153 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4206 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0150 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4236 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0140 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4202 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0133 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4489 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0139 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4365 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0124 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4517 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0134 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4497 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0119 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4575 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0120 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4877 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0129 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4632 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0125 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4854 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0113 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4853 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0111 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4819 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0118 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5049 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4950 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0101 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5009 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5231 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0108 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5036 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0100 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5134 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0105 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5318 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0098 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5148 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0099 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5287 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0096 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5334 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0101 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5355 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0102 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5421 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0094 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5468 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0100 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5413 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0098 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5513 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0097 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5586 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0096 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5523 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "4001/4001 [==============================] - 0s 84us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/5vouanel\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 5s 382us/step - loss: 0.6705 - acc: 0.6026 - f1_m: 0.6026 - precision_m: 0.6026 - recall_m: 0.6026 - val_loss: 0.6568 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.6424 - acc: 0.6084 - f1_m: 0.6084 - precision_m: 0.6084 - recall_m: 0.6084 - val_loss: 0.6244 - val_acc: 0.6125 - val_f1_m: 0.6125 - val_precision_m: 0.6125 - val_recall_m: 0.6125\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.5829 - acc: 0.6693 - f1_m: 0.6693 - precision_m: 0.6693 - recall_m: 0.6693 - val_loss: 0.5607 - val_acc: 0.7225 - val_f1_m: 0.7225 - val_precision_m: 0.7225 - val_recall_m: 0.7225\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.4867 - acc: 0.7941 - f1_m: 0.7941 - precision_m: 0.7941 - recall_m: 0.7941 - val_loss: 0.4851 - val_acc: 0.7775 - val_f1_m: 0.7775 - val_precision_m: 0.7775 - val_recall_m: 0.7775\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.3771 - acc: 0.8613 - f1_m: 0.8613 - precision_m: 0.8613 - recall_m: 0.8613 - val_loss: 0.4259 - val_acc: 0.8013 - val_f1_m: 0.8012 - val_precision_m: 0.8013 - val_recall_m: 0.8013\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.2806 - acc: 0.9084 - f1_m: 0.9084 - precision_m: 0.9084 - recall_m: 0.9084 - val_loss: 0.3757 - val_acc: 0.8259 - val_f1_m: 0.8259 - val_precision_m: 0.8259 - val_recall_m: 0.8259\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.1937 - acc: 0.9460 - f1_m: 0.9460 - precision_m: 0.9460 - recall_m: 0.9460 - val_loss: 0.3438 - val_acc: 0.8441 - val_f1_m: 0.8441 - val_precision_m: 0.8441 - val_recall_m: 0.8441\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1355 - acc: 0.9679 - f1_m: 0.9679 - precision_m: 0.9679 - recall_m: 0.9679 - val_loss: 0.3293 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0963 - acc: 0.9798 - f1_m: 0.9798 - precision_m: 0.9798 - recall_m: 0.9798 - val_loss: 0.3251 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0691 - acc: 0.9853 - f1_m: 0.9853 - precision_m: 0.9853 - recall_m: 0.9853 - val_loss: 0.3225 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0513 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.3332 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0406 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.3405 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0325 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.3616 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0273 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3767 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0231 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3863 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0213 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3851 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0186 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4230 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0174 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4112 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0155 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4465 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0147 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4231 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0142 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4431 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0135 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4778 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0130 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4442 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0133 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4736 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0133 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4915 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0122 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4685 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0113 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5065 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0119 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4914 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0111 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5110 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0116 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4921 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0110 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5080 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0102 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5291 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0106 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5168 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0097 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5273 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0105 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5313 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0101 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5430 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0106 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5292 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0105 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5532 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0098 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5620 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0097 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5565 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0099 - acc: 0.9963 - f1_m: 0.9963 - precision_m: 0.9963 - recall_m: 0.9963 - val_loss: 0.5727 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0094 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5580 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0098 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5719 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0094 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5886 - val_acc: 0.8525 - val_f1_m: 0.8525 - val_precision_m: 0.8525 - val_recall_m: 0.8525\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0095 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5680 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0092 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5900 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0094 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5895 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0091 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5985 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0092 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5768 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0087 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5984 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "4001/4001 [==============================] - 0s 94us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/k1admwv9\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 5s 392us/step - loss: 0.6726 - acc: 0.5968 - f1_m: 0.5968 - precision_m: 0.5968 - recall_m: 0.5968 - val_loss: 0.6572 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.6408 - acc: 0.6069 - f1_m: 0.6069 - precision_m: 0.6069 - recall_m: 0.6069 - val_loss: 0.6255 - val_acc: 0.6125 - val_f1_m: 0.6125 - val_precision_m: 0.6125 - val_recall_m: 0.6125\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.5818 - acc: 0.6593 - f1_m: 0.6593 - precision_m: 0.6593 - recall_m: 0.6593 - val_loss: 0.5615 - val_acc: 0.7250 - val_f1_m: 0.7250 - val_precision_m: 0.7250 - val_recall_m: 0.7250\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.4802 - acc: 0.8212 - f1_m: 0.8212 - precision_m: 0.8212 - recall_m: 0.8212 - val_loss: 0.4828 - val_acc: 0.7759 - val_f1_m: 0.7759 - val_precision_m: 0.7759 - val_recall_m: 0.7759\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.3621 - acc: 0.8720 - f1_m: 0.8720 - precision_m: 0.8720 - recall_m: 0.8720 - val_loss: 0.4221 - val_acc: 0.8037 - val_f1_m: 0.8037 - val_precision_m: 0.8037 - val_recall_m: 0.8037\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2594 - acc: 0.9184 - f1_m: 0.9184 - precision_m: 0.9184 - recall_m: 0.9184 - val_loss: 0.3792 - val_acc: 0.8231 - val_f1_m: 0.8231 - val_precision_m: 0.8231 - val_recall_m: 0.8231\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1776 - acc: 0.9516 - f1_m: 0.9516 - precision_m: 0.9516 - recall_m: 0.9516 - val_loss: 0.3572 - val_acc: 0.8353 - val_f1_m: 0.8353 - val_precision_m: 0.8353 - val_recall_m: 0.8353\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1187 - acc: 0.9721 - f1_m: 0.9721 - precision_m: 0.9721 - recall_m: 0.9721 - val_loss: 0.3361 - val_acc: 0.8516 - val_f1_m: 0.8516 - val_precision_m: 0.8516 - val_recall_m: 0.8516\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0810 - acc: 0.9842 - f1_m: 0.9842 - precision_m: 0.9842 - recall_m: 0.9842 - val_loss: 0.3292 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0573 - acc: 0.9885 - f1_m: 0.9885 - precision_m: 0.9885 - recall_m: 0.9885 - val_loss: 0.3405 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0423 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.3457 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0330 - acc: 0.9929 - f1_m: 0.9929 - precision_m: 0.9929 - recall_m: 0.9929 - val_loss: 0.3527 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0268 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.3575 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0220 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3661 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0194 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3851 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0178 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3836 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0160 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4046 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0150 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.3896 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0151 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4165 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0136 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4249 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0136 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4158 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0122 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4356 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0118 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4362 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0115 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4418 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0111 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.4440 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0106 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4555 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0109 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4524 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0105 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4639 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0107 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4803 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0103 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4641 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0101 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4782 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0102 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4842 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0106 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4913 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0099 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4709 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0098 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4936 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0096 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4956 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0099 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4949 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0099 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5004 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0091 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5067 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0105 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4998 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0103 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5132 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0100 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5113 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0095 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5098 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0094 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5145 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0102 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5003 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0104 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5437 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0097 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5247 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0094 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5212 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0096 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5225 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0091 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5220 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "4001/4001 [==============================] - 0s 91us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/t36fv5ei\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 5s 383us/step - loss: 0.6750 - acc: 0.5913 - f1_m: 0.5913 - precision_m: 0.5913 - recall_m: 0.5913 - val_loss: 0.6664 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6558 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6458 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.6202 - acc: 0.6143 - f1_m: 0.6143 - precision_m: 0.6143 - recall_m: 0.6143 - val_loss: 0.6066 - val_acc: 0.6412 - val_f1_m: 0.6412 - val_precision_m: 0.6412 - val_recall_m: 0.6412\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.5502 - acc: 0.7283 - f1_m: 0.7283 - precision_m: 0.7283 - recall_m: 0.7283 - val_loss: 0.5416 - val_acc: 0.7575 - val_f1_m: 0.7575 - val_precision_m: 0.7575 - val_recall_m: 0.7575\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4454 - acc: 0.8467 - f1_m: 0.8467 - precision_m: 0.8467 - recall_m: 0.8467 - val_loss: 0.4707 - val_acc: 0.7803 - val_f1_m: 0.7803 - val_precision_m: 0.7803 - val_recall_m: 0.7803\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.3359 - acc: 0.8884 - f1_m: 0.8884 - precision_m: 0.8884 - recall_m: 0.8884 - val_loss: 0.4178 - val_acc: 0.8063 - val_f1_m: 0.8062 - val_precision_m: 0.8063 - val_recall_m: 0.8063\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2441 - acc: 0.9250 - f1_m: 0.9250 - precision_m: 0.9250 - recall_m: 0.9250 - val_loss: 0.3812 - val_acc: 0.8244 - val_f1_m: 0.8244 - val_precision_m: 0.8244 - val_recall_m: 0.8244\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1717 - acc: 0.9534 - f1_m: 0.9534 - precision_m: 0.9534 - recall_m: 0.9534 - val_loss: 0.3508 - val_acc: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1196 - acc: 0.9720 - f1_m: 0.9720 - precision_m: 0.9720 - recall_m: 0.9720 - val_loss: 0.3374 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0844 - acc: 0.9822 - f1_m: 0.9822 - precision_m: 0.9822 - recall_m: 0.9822 - val_loss: 0.3368 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0614 - acc: 0.9885 - f1_m: 0.9885 - precision_m: 0.9885 - recall_m: 0.9885 - val_loss: 0.3331 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0458 - acc: 0.9912 - f1_m: 0.9912 - precision_m: 0.9912 - recall_m: 0.9912 - val_loss: 0.3310 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0359 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3392 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0289 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.3458 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0243 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.3516 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0209 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3644 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0188 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.3720 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0168 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3679 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0156 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3806 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0147 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3859 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0137 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3962 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0134 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4022 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0134 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4087 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0123 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4027 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0120 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4174 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0113 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4237 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0111 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4120 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0110 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4346 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0114 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4207 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0106 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4399 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0107 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4325 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0106 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4481 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0102 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4413 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0099 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4500 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0106 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4466 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0102 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4589 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0100 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.4567 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0095 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4589 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0096 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4678 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0097 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4631 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0097 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4651 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0096 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4709 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0104 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4663 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0096 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4761 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0095 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4702 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0092 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4847 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0093 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4842 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0097 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4807 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0091 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4848 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0090 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4869 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "4001/4001 [==============================] - 0s 82us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/lxv5eyv5\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 5s 414us/step - loss: 0.6719 - acc: 0.5977 - f1_m: 0.5977 - precision_m: 0.5977 - recall_m: 0.5977 - val_loss: 0.6577 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.6433 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6295 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.5891 - acc: 0.6618 - f1_m: 0.6618 - precision_m: 0.6618 - recall_m: 0.6618 - val_loss: 0.5679 - val_acc: 0.7063 - val_f1_m: 0.7062 - val_precision_m: 0.7063 - val_recall_m: 0.7063\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.4923 - acc: 0.8064 - f1_m: 0.8064 - precision_m: 0.8064 - recall_m: 0.8064 - val_loss: 0.4941 - val_acc: 0.7731 - val_f1_m: 0.7731 - val_precision_m: 0.7731 - val_recall_m: 0.7731\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.3822 - acc: 0.8677 - f1_m: 0.8677 - precision_m: 0.8677 - recall_m: 0.8677 - val_loss: 0.4317 - val_acc: 0.8009 - val_f1_m: 0.8009 - val_precision_m: 0.8009 - val_recall_m: 0.8009\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2812 - acc: 0.9115 - f1_m: 0.9115 - precision_m: 0.9115 - recall_m: 0.9115 - val_loss: 0.3877 - val_acc: 0.8241 - val_f1_m: 0.8241 - val_precision_m: 0.8241 - val_recall_m: 0.8241\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1997 - acc: 0.9459 - f1_m: 0.9459 - precision_m: 0.9459 - recall_m: 0.9459 - val_loss: 0.3556 - val_acc: 0.8378 - val_f1_m: 0.8378 - val_precision_m: 0.8378 - val_recall_m: 0.8378\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1378 - acc: 0.9658 - f1_m: 0.9658 - precision_m: 0.9658 - recall_m: 0.9658 - val_loss: 0.3376 - val_acc: 0.8525 - val_f1_m: 0.8525 - val_precision_m: 0.8525 - val_recall_m: 0.8525\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0967 - acc: 0.9795 - f1_m: 0.9795 - precision_m: 0.9795 - recall_m: 0.9795 - val_loss: 0.3247 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0688 - acc: 0.9862 - f1_m: 0.9862 - precision_m: 0.9862 - recall_m: 0.9862 - val_loss: 0.3210 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0518 - acc: 0.9887 - f1_m: 0.9887 - precision_m: 0.9887 - recall_m: 0.9887 - val_loss: 0.3289 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0393 - acc: 0.9926 - f1_m: 0.9926 - precision_m: 0.9926 - recall_m: 0.9926 - val_loss: 0.3399 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0318 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3378 - val_acc: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0264 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3687 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0224 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.3732 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0204 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3711 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0185 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3945 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0161 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3967 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0145 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4054 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0140 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4123 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0129 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4173 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0129 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4398 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0124 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4324 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0125 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4456 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0123 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4273 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0119 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4681 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0127 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4652 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0132 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4502 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0113 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4599 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0115 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5002 - val_acc: 0.8478 - val_f1_m: 0.8478 - val_precision_m: 0.8478 - val_recall_m: 0.8478\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0115 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4533 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0101 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4879 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0106 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4856 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0111 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4795 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0107 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4977 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0098 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5000 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0100 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4947 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0100 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4969 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0100 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5163 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0100 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5078 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0091 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5140 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0093 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5155 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0093 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5202 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0093 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5157 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0094 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5292 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0095 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5234 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0100 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5497 - val_acc: 0.8525 - val_f1_m: 0.8525 - val_precision_m: 0.8525 - val_recall_m: 0.8525\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0098 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5308 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0101 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5325 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0096 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5266 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "4001/4001 [==============================] - 0s 85us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/pqwiw701\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 5s 408us/step - loss: 0.6728 - acc: 0.5959 - f1_m: 0.5959 - precision_m: 0.5959 - recall_m: 0.5959 - val_loss: 0.6577 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.6436 - acc: 0.6070 - f1_m: 0.6070 - precision_m: 0.6070 - recall_m: 0.6070 - val_loss: 0.6268 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.5919 - acc: 0.6461 - f1_m: 0.6461 - precision_m: 0.6461 - recall_m: 0.6461 - val_loss: 0.5728 - val_acc: 0.7100 - val_f1_m: 0.7100 - val_precision_m: 0.7100 - val_recall_m: 0.7100\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.5100 - acc: 0.7834 - f1_m: 0.7834 - precision_m: 0.7834 - recall_m: 0.7834 - val_loss: 0.5055 - val_acc: 0.7700 - val_f1_m: 0.7700 - val_precision_m: 0.7700 - val_recall_m: 0.7700\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.4170 - acc: 0.8430 - f1_m: 0.8430 - precision_m: 0.8430 - recall_m: 0.8430 - val_loss: 0.4490 - val_acc: 0.7909 - val_f1_m: 0.7909 - val_precision_m: 0.7909 - val_recall_m: 0.7909\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.3294 - acc: 0.8864 - f1_m: 0.8864 - precision_m: 0.8864 - recall_m: 0.8864 - val_loss: 0.4014 - val_acc: 0.8137 - val_f1_m: 0.8137 - val_precision_m: 0.8137 - val_recall_m: 0.8137\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.2508 - acc: 0.9240 - f1_m: 0.9240 - precision_m: 0.9240 - recall_m: 0.9240 - val_loss: 0.3651 - val_acc: 0.8416 - val_f1_m: 0.8416 - val_precision_m: 0.8416 - val_recall_m: 0.8416\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1895 - acc: 0.9491 - f1_m: 0.9491 - precision_m: 0.9491 - recall_m: 0.9491 - val_loss: 0.3406 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1464 - acc: 0.9645 - f1_m: 0.9645 - precision_m: 0.9645 - recall_m: 0.9645 - val_loss: 0.3249 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.1062 - acc: 0.9759 - f1_m: 0.9759 - precision_m: 0.9759 - recall_m: 0.9759 - val_loss: 0.3232 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0798 - acc: 0.9836 - f1_m: 0.9836 - precision_m: 0.9836 - recall_m: 0.9836 - val_loss: 0.3296 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0657 - acc: 0.9882 - f1_m: 0.9882 - precision_m: 0.9882 - recall_m: 0.9882 - val_loss: 0.3348 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0496 - acc: 0.9905 - f1_m: 0.9905 - precision_m: 0.9905 - recall_m: 0.9905 - val_loss: 0.3460 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0416 - acc: 0.9917 - f1_m: 0.9917 - precision_m: 0.9917 - recall_m: 0.9917 - val_loss: 0.3542 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0340 - acc: 0.9927 - f1_m: 0.9927 - precision_m: 0.9927 - recall_m: 0.9927 - val_loss: 0.3483 - val_acc: 0.8791 - val_f1_m: 0.8791 - val_precision_m: 0.8791 - val_recall_m: 0.8791\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0291 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.3685 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0250 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.3988 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0223 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3786 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0201 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4230 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0199 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4075 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0163 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4231 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0163 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4304 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0156 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4448 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0152 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4467 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0143 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4615 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0140 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4699 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0129 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4641 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0122 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4696 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0123 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4883 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0116 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.4834 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0121 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5022 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0118 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5042 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0114 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5044 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0114 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4984 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5275 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0110 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5189 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0109 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5203 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0103 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5475 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0106 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5206 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0108 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5323 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0102 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5534 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0096 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5400 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0102 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5657 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0102 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5563 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0096 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5709 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0099 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5624 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0096 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5695 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0095 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5851 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0095 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5773 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0094 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5927 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "4001/4001 [==============================] - 0s 89us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/39617p4h\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 5s 402us/step - loss: 0.6839 - acc: 0.5684 - f1_m: 0.5684 - precision_m: 0.5684 - recall_m: 0.5684 - val_loss: 0.6676 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6651 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6577 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.6485 - acc: 0.6073 - f1_m: 0.6073 - precision_m: 0.6073 - recall_m: 0.6073 - val_loss: 0.6382 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.6133 - acc: 0.6284 - f1_m: 0.6284 - precision_m: 0.6284 - recall_m: 0.6284 - val_loss: 0.6012 - val_acc: 0.6488 - val_f1_m: 0.6487 - val_precision_m: 0.6488 - val_recall_m: 0.6488\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.5543 - acc: 0.7246 - f1_m: 0.7246 - precision_m: 0.7246 - recall_m: 0.7246 - val_loss: 0.5479 - val_acc: 0.7316 - val_f1_m: 0.7316 - val_precision_m: 0.7316 - val_recall_m: 0.7316\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.4741 - acc: 0.8082 - f1_m: 0.8082 - precision_m: 0.8082 - recall_m: 0.8082 - val_loss: 0.4925 - val_acc: 0.7831 - val_f1_m: 0.7831 - val_precision_m: 0.7831 - val_recall_m: 0.7831\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.3930 - acc: 0.8558 - f1_m: 0.8558 - precision_m: 0.8558 - recall_m: 0.8558 - val_loss: 0.4464 - val_acc: 0.8009 - val_f1_m: 0.8009 - val_precision_m: 0.8009 - val_recall_m: 0.8009\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.3116 - acc: 0.9005 - f1_m: 0.9005 - precision_m: 0.9005 - recall_m: 0.9005 - val_loss: 0.4070 - val_acc: 0.8141 - val_f1_m: 0.8141 - val_precision_m: 0.8141 - val_recall_m: 0.8141\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2452 - acc: 0.9240 - f1_m: 0.9240 - precision_m: 0.9240 - recall_m: 0.9240 - val_loss: 0.3772 - val_acc: 0.8316 - val_f1_m: 0.8316 - val_precision_m: 0.8316 - val_recall_m: 0.8316\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1884 - acc: 0.9459 - f1_m: 0.9459 - precision_m: 0.9459 - recall_m: 0.9459 - val_loss: 0.3588 - val_acc: 0.8425 - val_f1_m: 0.8425 - val_precision_m: 0.8425 - val_recall_m: 0.8425\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1440 - acc: 0.9641 - f1_m: 0.9641 - precision_m: 0.9641 - recall_m: 0.9641 - val_loss: 0.3479 - val_acc: 0.8453 - val_f1_m: 0.8453 - val_precision_m: 0.8453 - val_recall_m: 0.8453\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1095 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - val_loss: 0.3412 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0867 - acc: 0.9790 - f1_m: 0.9790 - precision_m: 0.9790 - recall_m: 0.9790 - val_loss: 0.3491 - val_acc: 0.8488 - val_f1_m: 0.8487 - val_precision_m: 0.8488 - val_recall_m: 0.8488\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0693 - acc: 0.9838 - f1_m: 0.9838 - precision_m: 0.9838 - recall_m: 0.9838 - val_loss: 0.3441 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0584 - acc: 0.9882 - f1_m: 0.9882 - precision_m: 0.9882 - recall_m: 0.9882 - val_loss: 0.3502 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0483 - acc: 0.9898 - f1_m: 0.9898 - precision_m: 0.9898 - recall_m: 0.9898 - val_loss: 0.3638 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0412 - acc: 0.9909 - f1_m: 0.9909 - precision_m: 0.9909 - recall_m: 0.9909 - val_loss: 0.3707 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0362 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3776 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0310 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.3845 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0275 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3941 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0250 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.4055 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0230 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4096 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0217 - acc: 0.9938 - f1_m: 0.9938 - precision_m: 0.9938 - recall_m: 0.9938 - val_loss: 0.4259 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0188 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4267 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0193 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4337 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0174 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4462 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0171 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4443 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0163 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4562 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0155 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4634 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0148 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4677 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0142 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4734 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0141 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4842 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0139 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4860 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0130 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4884 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0129 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4967 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0121 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4954 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0126 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5056 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0121 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5091 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0115 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5173 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0113 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5229 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0114 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5215 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0110 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5300 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0112 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5364 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0111 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5401 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0114 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5435 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0110 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5526 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0111 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5408 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0106 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5565 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5602 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0108 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5710 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "4001/4001 [==============================] - 0s 97us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/u0cw1erz\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 5s 404us/step - loss: 0.6738 - acc: 0.6047 - f1_m: 0.6047 - precision_m: 0.6047 - recall_m: 0.6047 - val_loss: 0.6648 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6596 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6518 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6352 - acc: 0.6077 - f1_m: 0.6077 - precision_m: 0.6077 - recall_m: 0.6077 - val_loss: 0.6221 - val_acc: 0.6166 - val_f1_m: 0.6166 - val_precision_m: 0.6166 - val_recall_m: 0.6166\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.5804 - acc: 0.6708 - f1_m: 0.6708 - precision_m: 0.6708 - recall_m: 0.6708 - val_loss: 0.5641 - val_acc: 0.7097 - val_f1_m: 0.7097 - val_precision_m: 0.7097 - val_recall_m: 0.7097\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.4933 - acc: 0.7937 - f1_m: 0.7937 - precision_m: 0.7937 - recall_m: 0.7937 - val_loss: 0.4978 - val_acc: 0.7694 - val_f1_m: 0.7694 - val_precision_m: 0.7694 - val_recall_m: 0.7694\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3966 - acc: 0.8555 - f1_m: 0.8555 - precision_m: 0.8555 - recall_m: 0.8555 - val_loss: 0.4448 - val_acc: 0.7919 - val_f1_m: 0.7919 - val_precision_m: 0.7919 - val_recall_m: 0.7919\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3064 - acc: 0.8957 - f1_m: 0.8957 - precision_m: 0.8957 - recall_m: 0.8957 - val_loss: 0.4009 - val_acc: 0.8197 - val_f1_m: 0.8197 - val_precision_m: 0.8197 - val_recall_m: 0.8197\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2280 - acc: 0.9307 - f1_m: 0.9307 - precision_m: 0.9307 - recall_m: 0.9307 - val_loss: 0.3679 - val_acc: 0.8384 - val_f1_m: 0.8384 - val_precision_m: 0.8384 - val_recall_m: 0.8384\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1681 - acc: 0.9527 - f1_m: 0.9527 - precision_m: 0.9527 - recall_m: 0.9527 - val_loss: 0.3487 - val_acc: 0.8500 - val_f1_m: 0.8500 - val_precision_m: 0.8500 - val_recall_m: 0.8500\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1196 - acc: 0.9704 - f1_m: 0.9704 - precision_m: 0.9704 - recall_m: 0.9704 - val_loss: 0.3403 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0874 - acc: 0.9798 - f1_m: 0.9798 - precision_m: 0.9798 - recall_m: 0.9798 - val_loss: 0.3390 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0657 - acc: 0.9861 - f1_m: 0.9861 - precision_m: 0.9861 - recall_m: 0.9861 - val_loss: 0.3432 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0498 - acc: 0.9895 - f1_m: 0.9895 - precision_m: 0.9895 - recall_m: 0.9895 - val_loss: 0.3486 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0407 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.3578 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0351 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3701 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0303 - acc: 0.9927 - f1_m: 0.9927 - precision_m: 0.9927 - recall_m: 0.9927 - val_loss: 0.3813 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0263 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.3759 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0224 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.3957 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0201 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4056 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0185 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4013 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0170 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4258 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0157 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4207 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0154 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4334 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0142 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4319 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0143 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4468 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0134 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4424 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0126 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4583 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0131 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4592 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0132 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4680 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0124 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4658 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0125 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4774 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0119 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4754 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0115 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4885 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0108 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4848 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0116 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5065 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0113 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4950 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0108 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5064 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0104 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5043 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0106 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5226 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0105 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5114 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0105 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5264 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0101 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5200 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0102 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5332 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0093 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5355 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0103 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5313 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0103 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5313 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0099 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5415 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0099 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5510 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0097 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5453 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0091 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5461 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "4001/4001 [==============================] - 0s 103us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/bfsos49p\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 5s 427us/step - loss: 0.6755 - acc: 0.5947 - f1_m: 0.5947 - precision_m: 0.5947 - recall_m: 0.5947 - val_loss: 0.6636 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.6600 - acc: 0.6081 - f1_m: 0.6081 - precision_m: 0.6081 - recall_m: 0.6081 - val_loss: 0.6505 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6382 - acc: 0.6091 - f1_m: 0.6091 - precision_m: 0.6091 - recall_m: 0.6091 - val_loss: 0.6255 - val_acc: 0.6125 - val_f1_m: 0.6125 - val_precision_m: 0.6125 - val_recall_m: 0.6125\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.5974 - acc: 0.6569 - f1_m: 0.6569 - precision_m: 0.6569 - recall_m: 0.6569 - val_loss: 0.5834 - val_acc: 0.6650 - val_f1_m: 0.6650 - val_precision_m: 0.6650 - val_recall_m: 0.6650\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.5379 - acc: 0.7352 - f1_m: 0.7352 - precision_m: 0.7352 - recall_m: 0.7352 - val_loss: 0.5300 - val_acc: 0.7403 - val_f1_m: 0.7403 - val_precision_m: 0.7403 - val_recall_m: 0.7403\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.4637 - acc: 0.8023 - f1_m: 0.8023 - precision_m: 0.8023 - recall_m: 0.8023 - val_loss: 0.4792 - val_acc: 0.7803 - val_f1_m: 0.7803 - val_precision_m: 0.7803 - val_recall_m: 0.7803\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3910 - acc: 0.8521 - f1_m: 0.8521 - precision_m: 0.8521 - recall_m: 0.8521 - val_loss: 0.4340 - val_acc: 0.8041 - val_f1_m: 0.8041 - val_precision_m: 0.8041 - val_recall_m: 0.8041\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3182 - acc: 0.8928 - f1_m: 0.8928 - precision_m: 0.8928 - recall_m: 0.8928 - val_loss: 0.3966 - val_acc: 0.8231 - val_f1_m: 0.8231 - val_precision_m: 0.8231 - val_recall_m: 0.8231\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2516 - acc: 0.9256 - f1_m: 0.9256 - precision_m: 0.9256 - recall_m: 0.9256 - val_loss: 0.3648 - val_acc: 0.8375 - val_f1_m: 0.8375 - val_precision_m: 0.8375 - val_recall_m: 0.8375\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1986 - acc: 0.9468 - f1_m: 0.9468 - precision_m: 0.9468 - recall_m: 0.9468 - val_loss: 0.3440 - val_acc: 0.8497 - val_f1_m: 0.8497 - val_precision_m: 0.8497 - val_recall_m: 0.8497\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1534 - acc: 0.9631 - f1_m: 0.9631 - precision_m: 0.9631 - recall_m: 0.9631 - val_loss: 0.3293 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1208 - acc: 0.9734 - f1_m: 0.9734 - precision_m: 0.9734 - recall_m: 0.9734 - val_loss: 0.3276 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0996 - acc: 0.9785 - f1_m: 0.9785 - precision_m: 0.9785 - recall_m: 0.9785 - val_loss: 0.3314 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0789 - acc: 0.9830 - f1_m: 0.9830 - precision_m: 0.9830 - recall_m: 0.9830 - val_loss: 0.3279 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0672 - acc: 0.9860 - f1_m: 0.9860 - precision_m: 0.9860 - recall_m: 0.9860 - val_loss: 0.3375 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0558 - acc: 0.9891 - f1_m: 0.9891 - precision_m: 0.9891 - recall_m: 0.9891 - val_loss: 0.3488 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0467 - acc: 0.9913 - f1_m: 0.9912 - precision_m: 0.9913 - recall_m: 0.9913 - val_loss: 0.3518 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0425 - acc: 0.9908 - f1_m: 0.9908 - precision_m: 0.9908 - recall_m: 0.9908 - val_loss: 0.3603 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0376 - acc: 0.9929 - f1_m: 0.9929 - precision_m: 0.9929 - recall_m: 0.9929 - val_loss: 0.3713 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0332 - acc: 0.9928 - f1_m: 0.9928 - precision_m: 0.9928 - recall_m: 0.9928 - val_loss: 0.3829 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0301 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3985 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0278 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3934 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0259 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.4206 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0238 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4117 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0224 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.4398 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0206 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4301 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0199 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4591 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0192 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4543 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0185 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4718 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0168 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4711 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0172 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4928 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0172 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4910 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0161 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4984 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0161 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5075 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0162 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5070 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0155 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5108 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0146 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5328 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0137 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5359 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0140 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5399 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0133 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5549 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0137 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5515 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0135 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5470 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0130 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5600 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0126 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5725 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0116 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5771 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0129 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5827 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0118 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5802 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0117 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5902 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0125 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5952 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0118 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5974 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "4001/4001 [==============================] - 0s 94us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/7hhomw42\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 6s 445us/step - loss: 0.6753 - acc: 0.5990 - f1_m: 0.5989 - precision_m: 0.5989 - recall_m: 0.5989 - val_loss: 0.6613 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.6525 - acc: 0.6086 - f1_m: 0.6086 - precision_m: 0.6086 - recall_m: 0.6086 - val_loss: 0.6386 - val_acc: 0.6128 - val_f1_m: 0.6128 - val_precision_m: 0.6128 - val_recall_m: 0.6128\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.6175 - acc: 0.6277 - f1_m: 0.6277 - precision_m: 0.6277 - recall_m: 0.6277 - val_loss: 0.6020 - val_acc: 0.6428 - val_f1_m: 0.6428 - val_precision_m: 0.6428 - val_recall_m: 0.6428\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.5634 - acc: 0.6998 - f1_m: 0.6998 - precision_m: 0.6998 - recall_m: 0.6998 - val_loss: 0.5522 - val_acc: 0.7319 - val_f1_m: 0.7319 - val_precision_m: 0.7319 - val_recall_m: 0.7319\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.4979 - acc: 0.7645 - f1_m: 0.7645 - precision_m: 0.7645 - recall_m: 0.7645 - val_loss: 0.5030 - val_acc: 0.7769 - val_f1_m: 0.7769 - val_precision_m: 0.7769 - val_recall_m: 0.7769\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.4338 - acc: 0.7937 - f1_m: 0.7937 - precision_m: 0.7937 - recall_m: 0.7937 - val_loss: 0.4608 - val_acc: 0.8009 - val_f1_m: 0.8009 - val_precision_m: 0.8009 - val_recall_m: 0.8009\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.3682 - acc: 0.8637 - f1_m: 0.8637 - precision_m: 0.8637 - recall_m: 0.8637 - val_loss: 0.4230 - val_acc: 0.8231 - val_f1_m: 0.8231 - val_precision_m: 0.8231 - val_recall_m: 0.8231\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.3126 - acc: 0.8991 - f1_m: 0.8991 - precision_m: 0.8991 - recall_m: 0.8991 - val_loss: 0.3904 - val_acc: 0.8387 - val_f1_m: 0.8387 - val_precision_m: 0.8387 - val_recall_m: 0.8387\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2570 - acc: 0.9306 - f1_m: 0.9306 - precision_m: 0.9306 - recall_m: 0.9306 - val_loss: 0.3644 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2130 - acc: 0.9497 - f1_m: 0.9497 - precision_m: 0.9497 - recall_m: 0.9497 - val_loss: 0.3427 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1772 - acc: 0.9612 - f1_m: 0.9612 - precision_m: 0.9612 - recall_m: 0.9612 - val_loss: 0.3284 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1455 - acc: 0.9691 - f1_m: 0.9691 - precision_m: 0.9691 - recall_m: 0.9691 - val_loss: 0.3168 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1235 - acc: 0.9771 - f1_m: 0.9771 - precision_m: 0.9771 - recall_m: 0.9771 - val_loss: 0.3131 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1023 - acc: 0.9803 - f1_m: 0.9803 - precision_m: 0.9803 - recall_m: 0.9803 - val_loss: 0.3122 - val_acc: 0.8825 - val_f1_m: 0.8825 - val_precision_m: 0.8825 - val_recall_m: 0.8825\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0882 - acc: 0.9824 - f1_m: 0.9824 - precision_m: 0.9824 - recall_m: 0.9824 - val_loss: 0.3128 - val_acc: 0.8822 - val_f1_m: 0.8822 - val_precision_m: 0.8822 - val_recall_m: 0.8822\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0768 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - val_loss: 0.3242 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0687 - acc: 0.9884 - f1_m: 0.9884 - precision_m: 0.9884 - recall_m: 0.9884 - val_loss: 0.3244 - val_acc: 0.8834 - val_f1_m: 0.8834 - val_precision_m: 0.8834 - val_recall_m: 0.8834\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0595 - acc: 0.9894 - f1_m: 0.9894 - precision_m: 0.9894 - recall_m: 0.9894 - val_loss: 0.3312 - val_acc: 0.8831 - val_f1_m: 0.8831 - val_precision_m: 0.8831 - val_recall_m: 0.8831\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0529 - acc: 0.9903 - f1_m: 0.9903 - precision_m: 0.9903 - recall_m: 0.9903 - val_loss: 0.3389 - val_acc: 0.8819 - val_f1_m: 0.8819 - val_precision_m: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0491 - acc: 0.9910 - f1_m: 0.9910 - precision_m: 0.9910 - recall_m: 0.9910 - val_loss: 0.3420 - val_acc: 0.8869 - val_f1_m: 0.8869 - val_precision_m: 0.8869 - val_recall_m: 0.8869\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0448 - acc: 0.9921 - f1_m: 0.9921 - precision_m: 0.9921 - recall_m: 0.9921 - val_loss: 0.3579 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0419 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.3653 - val_acc: 0.8788 - val_f1_m: 0.8787 - val_precision_m: 0.8788 - val_recall_m: 0.8788\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0376 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3712 - val_acc: 0.8797 - val_f1_m: 0.8797 - val_precision_m: 0.8797 - val_recall_m: 0.8797\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0349 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3839 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0308 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.3884 - val_acc: 0.8778 - val_f1_m: 0.8778 - val_precision_m: 0.8778 - val_recall_m: 0.8778\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0295 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.3968 - val_acc: 0.8769 - val_f1_m: 0.8769 - val_precision_m: 0.8769 - val_recall_m: 0.8769\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0259 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.4111 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0260 - acc: 0.9938 - f1_m: 0.9938 - precision_m: 0.9938 - recall_m: 0.9938 - val_loss: 0.4119 - val_acc: 0.8759 - val_f1_m: 0.8759 - val_precision_m: 0.8759 - val_recall_m: 0.8759\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0237 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4232 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0216 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4314 - val_acc: 0.8769 - val_f1_m: 0.8769 - val_precision_m: 0.8769 - val_recall_m: 0.8769\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0215 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4419 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0205 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4477 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0204 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4578 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0189 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4607 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0186 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4761 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0178 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4857 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0175 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4897 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0180 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4981 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0169 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5045 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0174 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5088 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0169 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5198 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0170 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5269 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0164 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5310 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0149 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5367 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0163 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5415 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0155 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5481 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0142 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5566 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0141 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5665 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0154 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5611 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0141 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5625 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "4001/4001 [==============================] - 0s 95us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/nsyymbf9\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 6s 445us/step - loss: 0.6717 - acc: 0.6020 - f1_m: 0.6020 - precision_m: 0.6020 - recall_m: 0.6020 - val_loss: 0.6570 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.6409 - acc: 0.6073 - f1_m: 0.6073 - precision_m: 0.6073 - recall_m: 0.6073 - val_loss: 0.6258 - val_acc: 0.6144 - val_f1_m: 0.6144 - val_precision_m: 0.6144 - val_recall_m: 0.6144\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.5845 - acc: 0.6738 - f1_m: 0.6738 - precision_m: 0.6738 - recall_m: 0.6738 - val_loss: 0.5653 - val_acc: 0.7206 - val_f1_m: 0.7206 - val_precision_m: 0.7206 - val_recall_m: 0.7206\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.4906 - acc: 0.8033 - f1_m: 0.8033 - precision_m: 0.8033 - recall_m: 0.8033 - val_loss: 0.4946 - val_acc: 0.7784 - val_f1_m: 0.7784 - val_precision_m: 0.7784 - val_recall_m: 0.7784\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.3876 - acc: 0.8671 - f1_m: 0.8671 - precision_m: 0.8671 - recall_m: 0.8671 - val_loss: 0.4355 - val_acc: 0.8016 - val_f1_m: 0.8016 - val_precision_m: 0.8016 - val_recall_m: 0.8016\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.2887 - acc: 0.9088 - f1_m: 0.9087 - precision_m: 0.9088 - recall_m: 0.9088 - val_loss: 0.3874 - val_acc: 0.8222 - val_f1_m: 0.8222 - val_precision_m: 0.8222 - val_recall_m: 0.8222\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.2065 - acc: 0.9441 - f1_m: 0.9441 - precision_m: 0.9441 - recall_m: 0.9441 - val_loss: 0.3518 - val_acc: 0.8400 - val_f1_m: 0.8400 - val_precision_m: 0.8400 - val_recall_m: 0.8400\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.1426 - acc: 0.9666 - f1_m: 0.9666 - precision_m: 0.9666 - recall_m: 0.9666 - val_loss: 0.3320 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.0988 - acc: 0.9788 - f1_m: 0.9788 - precision_m: 0.9788 - recall_m: 0.9788 - val_loss: 0.3225 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0692 - acc: 0.9872 - f1_m: 0.9872 - precision_m: 0.9872 - recall_m: 0.9872 - val_loss: 0.3238 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0516 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.3303 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0395 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.3461 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0325 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.3406 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0265 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3531 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0224 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3642 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0204 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3557 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0179 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3784 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0166 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3667 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0156 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4008 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0147 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.3871 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0139 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4009 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0130 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4005 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0124 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4139 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0129 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4145 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.0121 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4192 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0115 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.4236 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0119 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4275 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0110 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4515 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0119 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4269 - val_acc: 0.8744 - val_f1_m: 0.8744 - val_precision_m: 0.8744 - val_recall_m: 0.8744\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0117 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4473 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0114 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4452 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0108 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4414 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0107 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4568 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4490 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0106 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4735 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0103 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4564 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0106 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4716 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0100 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4693 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0100 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.4613 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0097 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4835 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0102 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4718 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0102 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4810 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0096 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4828 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0098 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4918 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0096 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4860 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0098 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5090 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0100 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4828 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0095 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4929 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0095 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5049 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0100 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4968 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "4001/4001 [==============================] - 0s 98us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/vlqqjn8i\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 6s 442us/step - loss: 0.6760 - acc: 0.6017 - f1_m: 0.6017 - precision_m: 0.6017 - recall_m: 0.6017 - val_loss: 0.6655 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.6609 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6536 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6412 - acc: 0.6080 - f1_m: 0.6080 - precision_m: 0.6080 - recall_m: 0.6080 - val_loss: 0.6296 - val_acc: 0.6150 - val_f1_m: 0.6150 - val_precision_m: 0.6150 - val_recall_m: 0.6150\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6004 - acc: 0.6511 - f1_m: 0.6511 - precision_m: 0.6511 - recall_m: 0.6511 - val_loss: 0.5881 - val_acc: 0.6578 - val_f1_m: 0.6578 - val_precision_m: 0.6578 - val_recall_m: 0.6578\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.5341 - acc: 0.7488 - f1_m: 0.7488 - precision_m: 0.7488 - recall_m: 0.7488 - val_loss: 0.5308 - val_acc: 0.7588 - val_f1_m: 0.7587 - val_precision_m: 0.7588 - val_recall_m: 0.7588\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.4520 - acc: 0.8261 - f1_m: 0.8261 - precision_m: 0.8261 - recall_m: 0.8261 - val_loss: 0.4757 - val_acc: 0.7847 - val_f1_m: 0.7847 - val_precision_m: 0.7847 - val_recall_m: 0.7847\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3728 - acc: 0.8658 - f1_m: 0.8658 - precision_m: 0.8658 - recall_m: 0.8658 - val_loss: 0.4317 - val_acc: 0.8013 - val_f1_m: 0.8012 - val_precision_m: 0.8013 - val_recall_m: 0.8013\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2934 - acc: 0.9033 - f1_m: 0.9033 - precision_m: 0.9033 - recall_m: 0.9033 - val_loss: 0.3975 - val_acc: 0.8134 - val_f1_m: 0.8134 - val_precision_m: 0.8134 - val_recall_m: 0.8134\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.2228 - acc: 0.9346 - f1_m: 0.9346 - precision_m: 0.9346 - recall_m: 0.9346 - val_loss: 0.3729 - val_acc: 0.8309 - val_f1_m: 0.8309 - val_precision_m: 0.8309 - val_recall_m: 0.8309\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1704 - acc: 0.9550 - f1_m: 0.9550 - precision_m: 0.9550 - recall_m: 0.9550 - val_loss: 0.3549 - val_acc: 0.8431 - val_f1_m: 0.8431 - val_precision_m: 0.8431 - val_recall_m: 0.8431\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1322 - acc: 0.9670 - f1_m: 0.9670 - precision_m: 0.9670 - recall_m: 0.9670 - val_loss: 0.3425 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1038 - acc: 0.9755 - f1_m: 0.9755 - precision_m: 0.9755 - recall_m: 0.9755 - val_loss: 0.3443 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0799 - acc: 0.9845 - f1_m: 0.9845 - precision_m: 0.9845 - recall_m: 0.9845 - val_loss: 0.3439 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0666 - acc: 0.9862 - f1_m: 0.9862 - precision_m: 0.9862 - recall_m: 0.9862 - val_loss: 0.3521 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0558 - acc: 0.9893 - f1_m: 0.9893 - precision_m: 0.9893 - recall_m: 0.9893 - val_loss: 0.3514 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0459 - acc: 0.9918 - f1_m: 0.9918 - precision_m: 0.9918 - recall_m: 0.9918 - val_loss: 0.3675 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0398 - acc: 0.9917 - f1_m: 0.9917 - precision_m: 0.9917 - recall_m: 0.9917 - val_loss: 0.3677 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0348 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3857 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0318 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3871 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0281 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.4012 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0254 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.4035 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0226 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4227 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0221 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4236 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0215 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4364 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0198 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4433 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0182 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4526 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0174 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4494 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0170 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4627 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0162 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4733 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0149 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4734 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0147 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4792 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0139 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4877 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0144 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5082 - val_acc: 0.8506 - val_f1_m: 0.8506 - val_precision_m: 0.8506 - val_recall_m: 0.8506\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0137 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4925 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0126 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5110 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0135 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5254 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0128 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5172 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0124 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5111 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0120 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5385 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0112 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5346 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0112 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5318 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0116 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5457 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0111 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5530 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0118 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5595 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0110 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5612 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0109 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5685 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0116 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5658 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0108 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5826 - val_acc: 0.8491 - val_f1_m: 0.8491 - val_precision_m: 0.8491 - val_recall_m: 0.8491\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0106 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5765 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0107 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5756 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "4001/4001 [==============================] - 0s 99us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/fqxtru91\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 6s 456us/step - loss: 0.6701 - acc: 0.6052 - f1_m: 0.6052 - precision_m: 0.6052 - recall_m: 0.6052 - val_loss: 0.6583 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6459 - acc: 0.6080 - f1_m: 0.6080 - precision_m: 0.6080 - recall_m: 0.6080 - val_loss: 0.6365 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6097 - acc: 0.6303 - f1_m: 0.6303 - precision_m: 0.6303 - recall_m: 0.6303 - val_loss: 0.5984 - val_acc: 0.6644 - val_f1_m: 0.6644 - val_precision_m: 0.6644 - val_recall_m: 0.6644\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.5476 - acc: 0.7530 - f1_m: 0.7530 - precision_m: 0.7530 - recall_m: 0.7530 - val_loss: 0.5441 - val_acc: 0.7431 - val_f1_m: 0.7431 - val_precision_m: 0.7431 - val_recall_m: 0.7431\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.4669 - acc: 0.8265 - f1_m: 0.8265 - precision_m: 0.8265 - recall_m: 0.8265 - val_loss: 0.4917 - val_acc: 0.7822 - val_f1_m: 0.7822 - val_precision_m: 0.7822 - val_recall_m: 0.7822\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3876 - acc: 0.8680 - f1_m: 0.8680 - precision_m: 0.8680 - recall_m: 0.8680 - val_loss: 0.4461 - val_acc: 0.8013 - val_f1_m: 0.8012 - val_precision_m: 0.8013 - val_recall_m: 0.8013\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3154 - acc: 0.8972 - f1_m: 0.8972 - precision_m: 0.8972 - recall_m: 0.8972 - val_loss: 0.4089 - val_acc: 0.8200 - val_f1_m: 0.8200 - val_precision_m: 0.8200 - val_recall_m: 0.8200\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2482 - acc: 0.9287 - f1_m: 0.9287 - precision_m: 0.9287 - recall_m: 0.9287 - val_loss: 0.3795 - val_acc: 0.8300 - val_f1_m: 0.8300 - val_precision_m: 0.8300 - val_recall_m: 0.8300\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1932 - acc: 0.9478 - f1_m: 0.9478 - precision_m: 0.9478 - recall_m: 0.9478 - val_loss: 0.3579 - val_acc: 0.8475 - val_f1_m: 0.8475 - val_precision_m: 0.8475 - val_recall_m: 0.8475\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1491 - acc: 0.9640 - f1_m: 0.9640 - precision_m: 0.9640 - recall_m: 0.9640 - val_loss: 0.3394 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1162 - acc: 0.9745 - f1_m: 0.9745 - precision_m: 0.9745 - recall_m: 0.9745 - val_loss: 0.3310 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0919 - acc: 0.9820 - f1_m: 0.9820 - precision_m: 0.9820 - recall_m: 0.9820 - val_loss: 0.3287 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0742 - acc: 0.9847 - f1_m: 0.9847 - precision_m: 0.9847 - recall_m: 0.9847 - val_loss: 0.3221 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0610 - acc: 0.9883 - f1_m: 0.9883 - precision_m: 0.9883 - recall_m: 0.9883 - val_loss: 0.3258 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0501 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.3277 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0435 - acc: 0.9915 - f1_m: 0.9915 - precision_m: 0.9915 - recall_m: 0.9915 - val_loss: 0.3385 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0376 - acc: 0.9925 - f1_m: 0.9925 - precision_m: 0.9925 - recall_m: 0.9925 - val_loss: 0.3358 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 1s 68us/step - loss: 0.0326 - acc: 0.9928 - f1_m: 0.9928 - precision_m: 0.9928 - recall_m: 0.9928 - val_loss: 0.3484 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0292 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3439 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0266 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.3579 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0242 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3571 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0235 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.3666 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0216 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3764 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0204 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.3710 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0187 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3776 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0173 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.3884 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0161 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.3915 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0161 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.3920 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0149 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4000 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0147 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4017 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0141 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4037 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0144 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4095 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0131 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4136 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0133 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4176 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0132 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4196 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0127 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4252 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0129 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4326 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0123 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4314 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0125 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4366 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0124 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4340 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0116 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4421 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0113 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4407 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0111 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4479 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0115 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4557 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0112 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4609 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0112 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4516 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0114 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4645 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0116 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4643 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0110 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4674 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0105 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4650 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "4001/4001 [==============================] - 0s 98us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/1xpoxqt8\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 6s 476us/step - loss: 0.6805 - acc: 0.5736 - f1_m: 0.5736 - precision_m: 0.5736 - recall_m: 0.5736 - val_loss: 0.6663 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.6571 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6461 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.6239 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6108 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.5659 - acc: 0.6087 - f1_m: 0.6087 - precision_m: 0.6087 - recall_m: 0.6087 - val_loss: 0.5609 - val_acc: 0.6197 - val_f1_m: 0.6197 - val_precision_m: 0.6197 - val_recall_m: 0.6197\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.4943 - acc: 0.7263 - f1_m: 0.7262 - precision_m: 0.7263 - recall_m: 0.7263 - val_loss: 0.5086 - val_acc: 0.7666 - val_f1_m: 0.7666 - val_precision_m: 0.7666 - val_recall_m: 0.7666\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.4059 - acc: 0.8733 - f1_m: 0.8733 - precision_m: 0.8733 - recall_m: 0.8733 - val_loss: 0.4461 - val_acc: 0.8137 - val_f1_m: 0.8137 - val_precision_m: 0.8137 - val_recall_m: 0.8137\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.3072 - acc: 0.9309 - f1_m: 0.9309 - precision_m: 0.9309 - recall_m: 0.9309 - val_loss: 0.3925 - val_acc: 0.8309 - val_f1_m: 0.8309 - val_precision_m: 0.8309 - val_recall_m: 0.8309\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2231 - acc: 0.9519 - f1_m: 0.9519 - precision_m: 0.9519 - recall_m: 0.9519 - val_loss: 0.3558 - val_acc: 0.8425 - val_f1_m: 0.8425 - val_precision_m: 0.8425 - val_recall_m: 0.8425\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1561 - acc: 0.9695 - f1_m: 0.9695 - precision_m: 0.9695 - recall_m: 0.9695 - val_loss: 0.3372 - val_acc: 0.8503 - val_f1_m: 0.8503 - val_precision_m: 0.8503 - val_recall_m: 0.8503\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1108 - acc: 0.9782 - f1_m: 0.9782 - precision_m: 0.9782 - recall_m: 0.9782 - val_loss: 0.3262 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0781 - acc: 0.9837 - f1_m: 0.9837 - precision_m: 0.9837 - recall_m: 0.9837 - val_loss: 0.3262 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0582 - acc: 0.9896 - f1_m: 0.9896 - precision_m: 0.9896 - recall_m: 0.9896 - val_loss: 0.3249 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0438 - acc: 0.9914 - f1_m: 0.9914 - precision_m: 0.9914 - recall_m: 0.9914 - val_loss: 0.3314 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0355 - acc: 0.9924 - f1_m: 0.9924 - precision_m: 0.9924 - recall_m: 0.9924 - val_loss: 0.3325 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0292 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3442 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0251 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3632 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0225 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.3513 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0196 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3704 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0183 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3716 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0165 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3810 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0153 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3793 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0147 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3944 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0144 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3900 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0135 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.3980 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0129 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4147 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0122 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4038 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0117 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4206 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0119 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4157 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0121 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4286 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0107 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.4241 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0109 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4360 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0111 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4369 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0107 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4393 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0108 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4397 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0107 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4493 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0109 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.4506 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0106 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4604 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0105 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4530 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0102 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4638 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0100 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4616 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0103 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4717 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0096 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4704 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0100 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4662 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0096 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4852 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0097 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4856 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0094 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4800 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0095 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4892 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0095 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5032 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0102 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4933 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0097 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5014 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "4001/4001 [==============================] - 0s 97us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/dqvktopi\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 6s 479us/step - loss: 0.6779 - acc: 0.5892 - f1_m: 0.5892 - precision_m: 0.5892 - recall_m: 0.5892 - val_loss: 0.6625 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.6574 - acc: 0.6083 - f1_m: 0.6083 - precision_m: 0.6083 - recall_m: 0.6083 - val_loss: 0.6456 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.6316 - acc: 0.6189 - f1_m: 0.6189 - precision_m: 0.6189 - recall_m: 0.6189 - val_loss: 0.6161 - val_acc: 0.6153 - val_f1_m: 0.6153 - val_precision_m: 0.6153 - val_recall_m: 0.6153\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.5889 - acc: 0.6645 - f1_m: 0.6645 - precision_m: 0.6645 - recall_m: 0.6645 - val_loss: 0.5727 - val_acc: 0.6887 - val_f1_m: 0.6887 - val_precision_m: 0.6887 - val_recall_m: 0.6887\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.5321 - acc: 0.7366 - f1_m: 0.7366 - precision_m: 0.7366 - recall_m: 0.7366 - val_loss: 0.5227 - val_acc: 0.7653 - val_f1_m: 0.7653 - val_precision_m: 0.7653 - val_recall_m: 0.7653\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.4657 - acc: 0.7958 - f1_m: 0.7958 - precision_m: 0.7958 - recall_m: 0.7958 - val_loss: 0.4786 - val_acc: 0.7875 - val_f1_m: 0.7875 - val_precision_m: 0.7875 - val_recall_m: 0.7875\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.3983 - acc: 0.8236 - f1_m: 0.8236 - precision_m: 0.8236 - recall_m: 0.8236 - val_loss: 0.4384 - val_acc: 0.8113 - val_f1_m: 0.8112 - val_precision_m: 0.8113 - val_recall_m: 0.8113\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.3396 - acc: 0.8725 - f1_m: 0.8725 - precision_m: 0.8725 - recall_m: 0.8725 - val_loss: 0.4051 - val_acc: 0.8272 - val_f1_m: 0.8272 - val_precision_m: 0.8272 - val_recall_m: 0.8272\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2837 - acc: 0.9098 - f1_m: 0.9098 - precision_m: 0.9098 - recall_m: 0.9098 - val_loss: 0.3762 - val_acc: 0.8403 - val_f1_m: 0.8403 - val_precision_m: 0.8403 - val_recall_m: 0.8403\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2335 - acc: 0.9340 - f1_m: 0.9340 - precision_m: 0.9340 - recall_m: 0.9340 - val_loss: 0.3528 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1953 - acc: 0.9537 - f1_m: 0.9537 - precision_m: 0.9537 - recall_m: 0.9537 - val_loss: 0.3380 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1559 - acc: 0.9654 - f1_m: 0.9654 - precision_m: 0.9654 - recall_m: 0.9654 - val_loss: 0.3282 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1249 - acc: 0.9735 - f1_m: 0.9735 - precision_m: 0.9735 - recall_m: 0.9735 - val_loss: 0.3247 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1003 - acc: 0.9799 - f1_m: 0.9799 - precision_m: 0.9799 - recall_m: 0.9799 - val_loss: 0.3289 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0863 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - val_loss: 0.3419 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0735 - acc: 0.9866 - f1_m: 0.9866 - precision_m: 0.9866 - recall_m: 0.9866 - val_loss: 0.3454 - val_acc: 0.8744 - val_f1_m: 0.8744 - val_precision_m: 0.8744 - val_recall_m: 0.8744\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0642 - acc: 0.9882 - f1_m: 0.9882 - precision_m: 0.9882 - recall_m: 0.9882 - val_loss: 0.3512 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0562 - acc: 0.9898 - f1_m: 0.9898 - precision_m: 0.9898 - recall_m: 0.9898 - val_loss: 0.3643 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0488 - acc: 0.9907 - f1_m: 0.9907 - precision_m: 0.9907 - recall_m: 0.9907 - val_loss: 0.3820 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0438 - acc: 0.9917 - f1_m: 0.9917 - precision_m: 0.9917 - recall_m: 0.9917 - val_loss: 0.3844 - val_acc: 0.8803 - val_f1_m: 0.8803 - val_precision_m: 0.8803 - val_recall_m: 0.8803\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0399 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.4034 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0370 - acc: 0.9928 - f1_m: 0.9928 - precision_m: 0.9928 - recall_m: 0.9928 - val_loss: 0.4081 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0345 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.4247 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0313 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.4345 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0307 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.4362 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0275 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4500 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0283 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.4656 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0267 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.4627 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0261 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4795 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0228 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.4843 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0243 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.5031 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0232 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.5048 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0229 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.5171 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0205 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5254 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0198 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5304 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0197 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5477 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0197 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.5588 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0191 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5619 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0186 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5615 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0177 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5751 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0170 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5851 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0167 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5952 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0168 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5992 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0162 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.6139 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0150 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6082 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0158 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.6425 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0156 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.6324 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0153 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.6219 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0139 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.6499 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0142 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6639 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "4001/4001 [==============================] - 0s 106us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/dtyja4ko\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 6s 466us/step - loss: 0.6831 - acc: 0.5706 - f1_m: 0.5706 - precision_m: 0.5706 - recall_m: 0.5706 - val_loss: 0.6694 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6696 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6636 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.6594 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6543 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6434 - acc: 0.6099 - f1_m: 0.6099 - precision_m: 0.6099 - recall_m: 0.6099 - val_loss: 0.6362 - val_acc: 0.6119 - val_f1_m: 0.6119 - val_precision_m: 0.6119 - val_recall_m: 0.6119\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6141 - acc: 0.6433 - f1_m: 0.6433 - precision_m: 0.6433 - recall_m: 0.6433 - val_loss: 0.6043 - val_acc: 0.6622 - val_f1_m: 0.6622 - val_precision_m: 0.6622 - val_recall_m: 0.6622\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.5614 - acc: 0.7283 - f1_m: 0.7283 - precision_m: 0.7283 - recall_m: 0.7283 - val_loss: 0.5583 - val_acc: 0.7325 - val_f1_m: 0.7325 - val_precision_m: 0.7325 - val_recall_m: 0.7325\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.4938 - acc: 0.7998 - f1_m: 0.7998 - precision_m: 0.7998 - recall_m: 0.7998 - val_loss: 0.5086 - val_acc: 0.7622 - val_f1_m: 0.7622 - val_precision_m: 0.7622 - val_recall_m: 0.7622\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.4173 - acc: 0.8443 - f1_m: 0.8443 - precision_m: 0.8443 - recall_m: 0.8443 - val_loss: 0.4646 - val_acc: 0.7825 - val_f1_m: 0.7825 - val_precision_m: 0.7825 - val_recall_m: 0.7825\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.3485 - acc: 0.8773 - f1_m: 0.8773 - precision_m: 0.8773 - recall_m: 0.8773 - val_loss: 0.4286 - val_acc: 0.7969 - val_f1_m: 0.7969 - val_precision_m: 0.7969 - val_recall_m: 0.7969\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.2853 - acc: 0.9067 - f1_m: 0.9067 - precision_m: 0.9067 - recall_m: 0.9067 - val_loss: 0.4024 - val_acc: 0.8122 - val_f1_m: 0.8122 - val_precision_m: 0.8122 - val_recall_m: 0.8122\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2255 - acc: 0.9320 - f1_m: 0.9320 - precision_m: 0.9320 - recall_m: 0.9320 - val_loss: 0.3788 - val_acc: 0.8231 - val_f1_m: 0.8231 - val_precision_m: 0.8231 - val_recall_m: 0.8231\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.1794 - acc: 0.9525 - f1_m: 0.9525 - precision_m: 0.9525 - recall_m: 0.9525 - val_loss: 0.3638 - val_acc: 0.8397 - val_f1_m: 0.8397 - val_precision_m: 0.8397 - val_recall_m: 0.8397\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.1463 - acc: 0.9645 - f1_m: 0.9645 - precision_m: 0.9645 - recall_m: 0.9645 - val_loss: 0.3527 - val_acc: 0.8456 - val_f1_m: 0.8456 - val_precision_m: 0.8456 - val_recall_m: 0.8456\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1157 - acc: 0.9727 - f1_m: 0.9727 - precision_m: 0.9727 - recall_m: 0.9727 - val_loss: 0.3451 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0963 - acc: 0.9773 - f1_m: 0.9773 - precision_m: 0.9773 - recall_m: 0.9773 - val_loss: 0.3494 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0810 - acc: 0.9823 - f1_m: 0.9823 - precision_m: 0.9823 - recall_m: 0.9823 - val_loss: 0.3457 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0690 - acc: 0.9853 - f1_m: 0.9853 - precision_m: 0.9853 - recall_m: 0.9853 - val_loss: 0.3498 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0583 - acc: 0.9878 - f1_m: 0.9878 - precision_m: 0.9878 - recall_m: 0.9878 - val_loss: 0.3509 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0493 - acc: 0.9907 - f1_m: 0.9907 - precision_m: 0.9907 - recall_m: 0.9907 - val_loss: 0.3589 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0442 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.3698 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0379 - acc: 0.9922 - f1_m: 0.9922 - precision_m: 0.9922 - recall_m: 0.9922 - val_loss: 0.3721 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0358 - acc: 0.9919 - f1_m: 0.9919 - precision_m: 0.9919 - recall_m: 0.9919 - val_loss: 0.3849 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0311 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9932 - recall_m: 0.9932 - val_loss: 0.3856 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0289 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3985 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0264 - acc: 0.9938 - f1_m: 0.9938 - precision_m: 0.9938 - recall_m: 0.9938 - val_loss: 0.4012 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0256 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.4182 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0230 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.4156 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0214 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4275 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0206 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4331 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0194 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4297 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0183 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4483 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0180 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4463 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0174 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4573 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0167 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4585 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0160 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4678 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0156 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4735 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0155 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4729 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0156 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4743 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0157 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4862 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0151 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4893 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0140 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4920 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0136 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5035 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0137 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5032 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0130 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5145 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0128 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5128 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0129 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5163 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0123 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5231 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0119 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5269 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0124 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5357 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0117 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5339 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "4001/4001 [==============================] - 0s 103us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/4dlha7ej\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 6s 479us/step - loss: 0.6742 - acc: 0.5948 - f1_m: 0.5948 - precision_m: 0.5948 - recall_m: 0.5948 - val_loss: 0.6624 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6564 - acc: 0.6083 - f1_m: 0.6083 - precision_m: 0.6083 - recall_m: 0.6083 - val_loss: 0.6455 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6259 - acc: 0.6178 - f1_m: 0.6178 - precision_m: 0.6178 - recall_m: 0.6178 - val_loss: 0.6123 - val_acc: 0.6300 - val_f1_m: 0.6300 - val_precision_m: 0.6300 - val_recall_m: 0.6300\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5739 - acc: 0.6947 - f1_m: 0.6947 - precision_m: 0.6947 - recall_m: 0.6947 - val_loss: 0.5603 - val_acc: 0.7281 - val_f1_m: 0.7281 - val_precision_m: 0.7281 - val_recall_m: 0.7281\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.4953 - acc: 0.7920 - f1_m: 0.7920 - precision_m: 0.7920 - recall_m: 0.7920 - val_loss: 0.5008 - val_acc: 0.7716 - val_f1_m: 0.7716 - val_precision_m: 0.7716 - val_recall_m: 0.7716\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.4114 - acc: 0.8427 - f1_m: 0.8427 - precision_m: 0.8427 - recall_m: 0.8427 - val_loss: 0.4497 - val_acc: 0.7934 - val_f1_m: 0.7934 - val_precision_m: 0.7934 - val_recall_m: 0.7934\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3275 - acc: 0.8884 - f1_m: 0.8884 - precision_m: 0.8884 - recall_m: 0.8884 - val_loss: 0.4079 - val_acc: 0.8116 - val_f1_m: 0.8116 - val_precision_m: 0.8116 - val_recall_m: 0.8116\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.2561 - acc: 0.9213 - f1_m: 0.9212 - precision_m: 0.9213 - recall_m: 0.9213 - val_loss: 0.3750 - val_acc: 0.8303 - val_f1_m: 0.8303 - val_precision_m: 0.8303 - val_recall_m: 0.8303\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1933 - acc: 0.9472 - f1_m: 0.9472 - precision_m: 0.9472 - recall_m: 0.9472 - val_loss: 0.3543 - val_acc: 0.8416 - val_f1_m: 0.8416 - val_precision_m: 0.8416 - val_recall_m: 0.8416\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1475 - acc: 0.9622 - f1_m: 0.9622 - precision_m: 0.9622 - recall_m: 0.9622 - val_loss: 0.3384 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1103 - acc: 0.9764 - f1_m: 0.9764 - precision_m: 0.9764 - recall_m: 0.9764 - val_loss: 0.3343 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0884 - acc: 0.9816 - f1_m: 0.9816 - precision_m: 0.9816 - recall_m: 0.9816 - val_loss: 0.3355 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0706 - acc: 0.9855 - f1_m: 0.9855 - precision_m: 0.9855 - recall_m: 0.9855 - val_loss: 0.3351 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0566 - acc: 0.9893 - f1_m: 0.9893 - precision_m: 0.9893 - recall_m: 0.9893 - val_loss: 0.3432 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0484 - acc: 0.9897 - f1_m: 0.9897 - precision_m: 0.9897 - recall_m: 0.9897 - val_loss: 0.3491 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0408 - acc: 0.9924 - f1_m: 0.9924 - precision_m: 0.9924 - recall_m: 0.9924 - val_loss: 0.3658 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0370 - acc: 0.9926 - f1_m: 0.9926 - precision_m: 0.9926 - recall_m: 0.9926 - val_loss: 0.3662 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0322 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3723 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0267 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3783 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0258 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3924 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0244 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3974 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0206 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4066 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0203 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4266 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0182 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4244 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0180 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4326 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0165 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4412 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0155 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4530 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0150 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4503 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0142 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4702 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0140 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4588 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0150 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4721 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0136 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4863 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0133 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4827 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0125 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4955 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0126 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5043 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0123 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5031 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0121 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5056 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0124 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5166 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0122 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5216 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0117 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5246 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0118 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5263 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0118 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5440 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0120 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5333 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0109 - acc: 0.9964 - f1_m: 0.9964 - precision_m: 0.9964 - recall_m: 0.9964 - val_loss: 0.5443 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0121 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5485 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0117 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5490 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0108 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5573 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0112 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5620 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0113 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5651 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0108 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5691 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "4001/4001 [==============================] - 0s 109us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/u2ulyv18\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 7s 515us/step - loss: 0.6745 - acc: 0.5964 - f1_m: 0.5964 - precision_m: 0.5964 - recall_m: 0.5964 - val_loss: 0.6612 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6528 - acc: 0.6074 - f1_m: 0.6074 - precision_m: 0.6074 - recall_m: 0.6074 - val_loss: 0.6405 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6179 - acc: 0.6211 - f1_m: 0.6211 - precision_m: 0.6211 - recall_m: 0.6211 - val_loss: 0.5996 - val_acc: 0.6453 - val_f1_m: 0.6453 - val_precision_m: 0.6453 - val_recall_m: 0.6453\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.5521 - acc: 0.7227 - f1_m: 0.7227 - precision_m: 0.7227 - recall_m: 0.7227 - val_loss: 0.5389 - val_acc: 0.7403 - val_f1_m: 0.7403 - val_precision_m: 0.7403 - val_recall_m: 0.7403\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.4680 - acc: 0.8081 - f1_m: 0.8081 - precision_m: 0.8081 - recall_m: 0.8081 - val_loss: 0.4816 - val_acc: 0.7800 - val_f1_m: 0.7800 - val_precision_m: 0.7800 - val_recall_m: 0.7800\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.3838 - acc: 0.8562 - f1_m: 0.8562 - precision_m: 0.8562 - recall_m: 0.8562 - val_loss: 0.4334 - val_acc: 0.7994 - val_f1_m: 0.7994 - val_precision_m: 0.7994 - val_recall_m: 0.7994\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2995 - acc: 0.9007 - f1_m: 0.9007 - precision_m: 0.9007 - recall_m: 0.9007 - val_loss: 0.3927 - val_acc: 0.8209 - val_f1_m: 0.8209 - val_precision_m: 0.8209 - val_recall_m: 0.8209\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.2300 - acc: 0.9328 - f1_m: 0.9328 - precision_m: 0.9328 - recall_m: 0.9328 - val_loss: 0.3616 - val_acc: 0.8425 - val_f1_m: 0.8425 - val_precision_m: 0.8425 - val_recall_m: 0.8425\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1716 - acc: 0.9557 - f1_m: 0.9557 - precision_m: 0.9557 - recall_m: 0.9557 - val_loss: 0.3437 - val_acc: 0.8500 - val_f1_m: 0.8500 - val_precision_m: 0.8500 - val_recall_m: 0.8500\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1280 - acc: 0.9698 - f1_m: 0.9698 - precision_m: 0.9698 - recall_m: 0.9698 - val_loss: 0.3330 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0970 - acc: 0.9804 - f1_m: 0.9804 - precision_m: 0.9804 - recall_m: 0.9804 - val_loss: 0.3289 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0752 - acc: 0.9848 - f1_m: 0.9848 - precision_m: 0.9848 - recall_m: 0.9848 - val_loss: 0.3370 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0602 - acc: 0.9873 - f1_m: 0.9873 - precision_m: 0.9873 - recall_m: 0.9873 - val_loss: 0.3407 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0479 - acc: 0.9911 - f1_m: 0.9911 - precision_m: 0.9911 - recall_m: 0.9911 - val_loss: 0.3528 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0412 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.3611 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0372 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3690 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0306 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9932 - recall_m: 0.9932 - val_loss: 0.3762 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0290 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.3937 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0262 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.4140 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0238 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3977 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0209 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4253 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0205 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4318 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0198 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.4323 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0178 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4500 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0171 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4472 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0161 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4712 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0143 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4695 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0143 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4849 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0138 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4869 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0130 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4989 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0124 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5080 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0135 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5143 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0129 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5169 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0118 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5263 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0119 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5455 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0118 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5331 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0130 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5653 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0120 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5525 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0124 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5508 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0109 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5727 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0109 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5755 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0104 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5924 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0106 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5756 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0106 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5997 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0100 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5994 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0104 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5903 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0110 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6049 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0108 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6132 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0104 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.6139 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0104 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.6090 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "4001/4001 [==============================] - 0s 107us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/m38v7d8v\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 6s 497us/step - loss: 0.6736 - acc: 0.6045 - f1_m: 0.6045 - precision_m: 0.6045 - recall_m: 0.6045 - val_loss: 0.6646 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.6609 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6525 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6364 - acc: 0.6084 - f1_m: 0.6084 - precision_m: 0.6084 - recall_m: 0.6084 - val_loss: 0.6253 - val_acc: 0.6125 - val_f1_m: 0.6125 - val_precision_m: 0.6125 - val_recall_m: 0.6125\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.5881 - acc: 0.6656 - f1_m: 0.6656 - precision_m: 0.6656 - recall_m: 0.6656 - val_loss: 0.5748 - val_acc: 0.7294 - val_f1_m: 0.7294 - val_precision_m: 0.7294 - val_recall_m: 0.7294\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5086 - acc: 0.7852 - f1_m: 0.7852 - precision_m: 0.7852 - recall_m: 0.7852 - val_loss: 0.5094 - val_acc: 0.7697 - val_f1_m: 0.7697 - val_precision_m: 0.7697 - val_recall_m: 0.7697\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4150 - acc: 0.8436 - f1_m: 0.8436 - precision_m: 0.8436 - recall_m: 0.8436 - val_loss: 0.4540 - val_acc: 0.7872 - val_f1_m: 0.7872 - val_precision_m: 0.7872 - val_recall_m: 0.7872\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3257 - acc: 0.8855 - f1_m: 0.8855 - precision_m: 0.8855 - recall_m: 0.8855 - val_loss: 0.4096 - val_acc: 0.8087 - val_f1_m: 0.8087 - val_precision_m: 0.8087 - val_recall_m: 0.8087\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2450 - acc: 0.9248 - f1_m: 0.9248 - precision_m: 0.9248 - recall_m: 0.9248 - val_loss: 0.3746 - val_acc: 0.8281 - val_f1_m: 0.8281 - val_precision_m: 0.8281 - val_recall_m: 0.8281\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1811 - acc: 0.9490 - f1_m: 0.9490 - precision_m: 0.9490 - recall_m: 0.9490 - val_loss: 0.3554 - val_acc: 0.8391 - val_f1_m: 0.8391 - val_precision_m: 0.8391 - val_recall_m: 0.8391\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1337 - acc: 0.9684 - f1_m: 0.9684 - precision_m: 0.9684 - recall_m: 0.9684 - val_loss: 0.3443 - val_acc: 0.8472 - val_f1_m: 0.8472 - val_precision_m: 0.8472 - val_recall_m: 0.8472\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0990 - acc: 0.9763 - f1_m: 0.9763 - precision_m: 0.9763 - recall_m: 0.9763 - val_loss: 0.3373 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0750 - acc: 0.9834 - f1_m: 0.9834 - precision_m: 0.9834 - recall_m: 0.9834 - val_loss: 0.3424 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0596 - acc: 0.9878 - f1_m: 0.9878 - precision_m: 0.9878 - recall_m: 0.9878 - val_loss: 0.3463 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0473 - acc: 0.9898 - f1_m: 0.9898 - precision_m: 0.9898 - recall_m: 0.9898 - val_loss: 0.3516 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0392 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.3556 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0331 - acc: 0.9928 - f1_m: 0.9928 - precision_m: 0.9928 - recall_m: 0.9928 - val_loss: 0.3681 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0285 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3648 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0247 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.3849 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0227 - acc: 0.9938 - f1_m: 0.9938 - precision_m: 0.9938 - recall_m: 0.9938 - val_loss: 0.3914 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0212 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3905 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0185 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4161 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0174 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4016 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0164 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4267 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0159 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4228 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0158 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4435 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0159 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4282 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0147 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4620 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0138 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4448 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0128 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4579 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0137 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4776 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0127 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4652 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0112 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.4825 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0121 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4831 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0124 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4934 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0112 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4938 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0114 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.4963 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0112 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4991 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0114 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5076 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0113 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5275 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0105 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5183 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0101 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5222 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0107 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5388 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0110 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5322 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0105 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5302 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0108 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5530 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0101 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5436 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0098 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5449 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0102 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5529 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0095 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5595 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0095 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5627 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "4001/4001 [==============================] - 0s 101us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/hcmbj08f\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 7s 523us/step - loss: 0.6797 - acc: 0.5843 - f1_m: 0.5843 - precision_m: 0.5843 - recall_m: 0.5843 - val_loss: 0.6638 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.6607 - acc: 0.6066 - f1_m: 0.6066 - precision_m: 0.6066 - recall_m: 0.6066 - val_loss: 0.6504 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.6392 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6247 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.5961 - acc: 0.6233 - f1_m: 0.6233 - precision_m: 0.6233 - recall_m: 0.6233 - val_loss: 0.5829 - val_acc: 0.6488 - val_f1_m: 0.6487 - val_precision_m: 0.6488 - val_recall_m: 0.6488\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.5393 - acc: 0.7077 - f1_m: 0.7077 - precision_m: 0.7077 - recall_m: 0.7077 - val_loss: 0.5318 - val_acc: 0.7422 - val_f1_m: 0.7422 - val_precision_m: 0.7422 - val_recall_m: 0.7422\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.4722 - acc: 0.7758 - f1_m: 0.7758 - precision_m: 0.7758 - recall_m: 0.7758 - val_loss: 0.4837 - val_acc: 0.7919 - val_f1_m: 0.7919 - val_precision_m: 0.7919 - val_recall_m: 0.7919\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.3996 - acc: 0.8450 - f1_m: 0.8450 - precision_m: 0.8450 - recall_m: 0.8450 - val_loss: 0.4391 - val_acc: 0.8134 - val_f1_m: 0.8134 - val_precision_m: 0.8134 - val_recall_m: 0.8134\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.3381 - acc: 0.8844 - f1_m: 0.8844 - precision_m: 0.8844 - recall_m: 0.8844 - val_loss: 0.4017 - val_acc: 0.8328 - val_f1_m: 0.8328 - val_precision_m: 0.8328 - val_recall_m: 0.8328\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2747 - acc: 0.9175 - f1_m: 0.9175 - precision_m: 0.9175 - recall_m: 0.9175 - val_loss: 0.3686 - val_acc: 0.8441 - val_f1_m: 0.8441 - val_precision_m: 0.8441 - val_recall_m: 0.8441\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2199 - acc: 0.9435 - f1_m: 0.9435 - precision_m: 0.9435 - recall_m: 0.9435 - val_loss: 0.3455 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.1740 - acc: 0.9602 - f1_m: 0.9602 - precision_m: 0.9602 - recall_m: 0.9602 - val_loss: 0.3295 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1448 - acc: 0.9695 - f1_m: 0.9695 - precision_m: 0.9695 - recall_m: 0.9695 - val_loss: 0.3250 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1145 - acc: 0.9772 - f1_m: 0.9772 - precision_m: 0.9772 - recall_m: 0.9772 - val_loss: 0.3228 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0916 - acc: 0.9822 - f1_m: 0.9822 - precision_m: 0.9822 - recall_m: 0.9822 - val_loss: 0.3236 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0777 - acc: 0.9849 - f1_m: 0.9849 - precision_m: 0.9849 - recall_m: 0.9849 - val_loss: 0.3326 - val_acc: 0.8744 - val_f1_m: 0.8744 - val_precision_m: 0.8744 - val_recall_m: 0.8744\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0656 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 0.3407 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0568 - acc: 0.9888 - f1_m: 0.9888 - precision_m: 0.9888 - recall_m: 0.9888 - val_loss: 0.3527 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0478 - acc: 0.9912 - f1_m: 0.9912 - precision_m: 0.9912 - recall_m: 0.9912 - val_loss: 0.3676 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0441 - acc: 0.9912 - f1_m: 0.9912 - precision_m: 0.9912 - recall_m: 0.9912 - val_loss: 0.3675 - val_acc: 0.8819 - val_f1_m: 0.8819 - val_precision_m: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0384 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.3957 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0350 - acc: 0.9929 - f1_m: 0.9929 - precision_m: 0.9929 - recall_m: 0.9929 - val_loss: 0.3898 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0311 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.4192 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0295 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.4197 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0260 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4337 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0252 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4429 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0229 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4532 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0218 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.4736 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0209 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4704 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0198 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4832 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0181 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4945 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0173 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5055 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0175 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5156 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0153 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5241 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0158 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5322 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0159 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5500 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0145 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5595 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0145 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5625 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0140 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5670 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0137 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5795 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0131 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5929 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0132 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5912 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0129 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5999 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0119 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5993 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0117 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.6198 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0124 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6062 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0116 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6154 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0115 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.6383 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0115 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.6350 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0118 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.6351 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0116 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6451 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "4001/4001 [==============================] - 0s 102us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/0b4tjwtv\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 7s 513us/step - loss: 0.6756 - acc: 0.6064 - f1_m: 0.6064 - precision_m: 0.6064 - recall_m: 0.6064 - val_loss: 0.6628 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.6553 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6481 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.6308 - acc: 0.6069 - f1_m: 0.6069 - precision_m: 0.6069 - recall_m: 0.6069 - val_loss: 0.6230 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.5866 - acc: 0.6366 - f1_m: 0.6366 - precision_m: 0.6366 - recall_m: 0.6366 - val_loss: 0.5813 - val_acc: 0.6713 - val_f1_m: 0.6712 - val_precision_m: 0.6713 - val_recall_m: 0.6713\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5231 - acc: 0.7543 - f1_m: 0.7543 - precision_m: 0.7543 - recall_m: 0.7543 - val_loss: 0.5328 - val_acc: 0.7488 - val_f1_m: 0.7487 - val_precision_m: 0.7488 - val_recall_m: 0.7488\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.4514 - acc: 0.8352 - f1_m: 0.8352 - precision_m: 0.8352 - recall_m: 0.8352 - val_loss: 0.4849 - val_acc: 0.7822 - val_f1_m: 0.7822 - val_precision_m: 0.7822 - val_recall_m: 0.7822\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3782 - acc: 0.8793 - f1_m: 0.8793 - precision_m: 0.8793 - recall_m: 0.8793 - val_loss: 0.4401 - val_acc: 0.8128 - val_f1_m: 0.8128 - val_precision_m: 0.8128 - val_recall_m: 0.8128\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.3082 - acc: 0.9105 - f1_m: 0.9105 - precision_m: 0.9105 - recall_m: 0.9105 - val_loss: 0.4025 - val_acc: 0.8294 - val_f1_m: 0.8294 - val_precision_m: 0.8294 - val_recall_m: 0.8294\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2490 - acc: 0.9324 - f1_m: 0.9324 - precision_m: 0.9324 - recall_m: 0.9324 - val_loss: 0.3733 - val_acc: 0.8384 - val_f1_m: 0.8384 - val_precision_m: 0.8384 - val_recall_m: 0.8384\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1964 - acc: 0.9513 - f1_m: 0.9512 - precision_m: 0.9513 - recall_m: 0.9513 - val_loss: 0.3487 - val_acc: 0.8525 - val_f1_m: 0.8525 - val_precision_m: 0.8525 - val_recall_m: 0.8525\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1500 - acc: 0.9650 - f1_m: 0.9650 - precision_m: 0.9650 - recall_m: 0.9650 - val_loss: 0.3364 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1174 - acc: 0.9729 - f1_m: 0.9729 - precision_m: 0.9729 - recall_m: 0.9729 - val_loss: 0.3296 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0908 - acc: 0.9808 - f1_m: 0.9808 - precision_m: 0.9808 - recall_m: 0.9808 - val_loss: 0.3258 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0720 - acc: 0.9859 - f1_m: 0.9859 - precision_m: 0.9859 - recall_m: 0.9859 - val_loss: 0.3335 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0604 - acc: 0.9876 - f1_m: 0.9876 - precision_m: 0.9876 - recall_m: 0.9876 - val_loss: 0.3259 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0510 - acc: 0.9893 - f1_m: 0.9893 - precision_m: 0.9893 - recall_m: 0.9893 - val_loss: 0.3347 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0427 - acc: 0.9914 - f1_m: 0.9914 - precision_m: 0.9914 - recall_m: 0.9914 - val_loss: 0.3413 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0369 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.3538 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0319 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3567 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0293 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.3657 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0262 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.3687 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0230 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3770 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0225 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3904 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0200 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3879 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0186 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4045 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0170 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3982 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0169 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4181 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0144 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4228 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0158 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4223 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0146 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4415 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0138 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4350 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0134 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4500 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0134 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4523 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0126 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4591 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0122 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4587 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0115 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4676 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0117 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4799 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0121 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4831 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0115 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4781 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0112 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4850 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0111 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4999 - val_acc: 0.8522 - val_f1_m: 0.8522 - val_precision_m: 0.8522 - val_recall_m: 0.8522\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0106 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5030 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0113 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4963 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0104 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5109 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0107 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5084 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0103 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5210 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0113 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5217 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0108 - acc: 0.9963 - f1_m: 0.9963 - precision_m: 0.9963 - recall_m: 0.9963 - val_loss: 0.5306 - val_acc: 0.8500 - val_f1_m: 0.8500 - val_precision_m: 0.8500 - val_recall_m: 0.8500\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0109 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5179 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0112 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5288 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "4001/4001 [==============================] - 0s 118us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/rjrcyt6k\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 7s 526us/step - loss: 0.6869 - acc: 0.5845 - f1_m: 0.5812 - precision_m: 0.5837 - recall_m: 0.5790 - val_loss: 0.6742 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6686 - acc: 0.6077 - f1_m: 0.6077 - precision_m: 0.6077 - recall_m: 0.6077 - val_loss: 0.6595 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6562 - acc: 0.6123 - f1_m: 0.6123 - precision_m: 0.6123 - recall_m: 0.6123 - val_loss: 0.6452 - val_acc: 0.6138 - val_f1_m: 0.6137 - val_precision_m: 0.6138 - val_recall_m: 0.6138\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6344 - acc: 0.6348 - f1_m: 0.6348 - precision_m: 0.6348 - recall_m: 0.6348 - val_loss: 0.6255 - val_acc: 0.6334 - val_f1_m: 0.6334 - val_precision_m: 0.6334 - val_recall_m: 0.6334\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6076 - acc: 0.6598 - f1_m: 0.6598 - precision_m: 0.6598 - recall_m: 0.6598 - val_loss: 0.6001 - val_acc: 0.6756 - val_f1_m: 0.6756 - val_precision_m: 0.6756 - val_recall_m: 0.6756\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5797 - acc: 0.6727 - f1_m: 0.6727 - precision_m: 0.6727 - recall_m: 0.6727 - val_loss: 0.5730 - val_acc: 0.7194 - val_f1_m: 0.7194 - val_precision_m: 0.7194 - val_recall_m: 0.7194\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.5466 - acc: 0.6838 - f1_m: 0.6838 - precision_m: 0.6838 - recall_m: 0.6838 - val_loss: 0.5442 - val_acc: 0.7422 - val_f1_m: 0.7422 - val_precision_m: 0.7422 - val_recall_m: 0.7422\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.5155 - acc: 0.6898 - f1_m: 0.6898 - precision_m: 0.6898 - recall_m: 0.6898 - val_loss: 0.5174 - val_acc: 0.7684 - val_f1_m: 0.7684 - val_precision_m: 0.7684 - val_recall_m: 0.7684\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.4749 - acc: 0.7461 - f1_m: 0.7461 - precision_m: 0.7461 - recall_m: 0.7461 - val_loss: 0.4865 - val_acc: 0.7997 - val_f1_m: 0.7997 - val_precision_m: 0.7997 - val_recall_m: 0.7997\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.4303 - acc: 0.7702 - f1_m: 0.7702 - precision_m: 0.7702 - recall_m: 0.7702 - val_loss: 0.4570 - val_acc: 0.8119 - val_f1_m: 0.8119 - val_precision_m: 0.8119 - val_recall_m: 0.8119\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.3917 - acc: 0.7950 - f1_m: 0.7950 - precision_m: 0.7950 - recall_m: 0.7950 - val_loss: 0.4281 - val_acc: 0.8241 - val_f1_m: 0.8241 - val_precision_m: 0.8241 - val_recall_m: 0.8241\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3504 - acc: 0.8283 - f1_m: 0.8283 - precision_m: 0.8283 - recall_m: 0.8283 - val_loss: 0.4037 - val_acc: 0.8363 - val_f1_m: 0.8362 - val_precision_m: 0.8363 - val_recall_m: 0.8363\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3137 - acc: 0.8534 - f1_m: 0.8534 - precision_m: 0.8534 - recall_m: 0.8534 - val_loss: 0.3805 - val_acc: 0.8456 - val_f1_m: 0.8456 - val_precision_m: 0.8456 - val_recall_m: 0.8456\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2779 - acc: 0.8938 - f1_m: 0.8937 - precision_m: 0.8938 - recall_m: 0.8938 - val_loss: 0.3609 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2499 - acc: 0.9127 - f1_m: 0.9127 - precision_m: 0.9127 - recall_m: 0.9127 - val_loss: 0.3480 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2238 - acc: 0.9250 - f1_m: 0.9250 - precision_m: 0.9250 - recall_m: 0.9250 - val_loss: 0.3338 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2029 - acc: 0.9330 - f1_m: 0.9330 - precision_m: 0.9330 - recall_m: 0.9330 - val_loss: 0.3259 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1838 - acc: 0.9410 - f1_m: 0.9410 - precision_m: 0.9410 - recall_m: 0.9410 - val_loss: 0.3236 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1697 - acc: 0.9490 - f1_m: 0.9490 - precision_m: 0.9490 - recall_m: 0.9490 - val_loss: 0.3169 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1545 - acc: 0.9470 - f1_m: 0.9470 - precision_m: 0.9470 - recall_m: 0.9470 - val_loss: 0.3213 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1442 - acc: 0.9516 - f1_m: 0.9516 - precision_m: 0.9516 - recall_m: 0.9516 - val_loss: 0.3180 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1343 - acc: 0.9545 - f1_m: 0.9545 - precision_m: 0.9545 - recall_m: 0.9545 - val_loss: 0.3190 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1276 - acc: 0.9566 - f1_m: 0.9566 - precision_m: 0.9566 - recall_m: 0.9566 - val_loss: 0.3224 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1224 - acc: 0.9573 - f1_m: 0.9573 - precision_m: 0.9573 - recall_m: 0.9573 - val_loss: 0.3234 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1166 - acc: 0.9595 - f1_m: 0.9595 - precision_m: 0.9595 - recall_m: 0.9595 - val_loss: 0.3273 - val_acc: 0.8744 - val_f1_m: 0.8744 - val_precision_m: 0.8744 - val_recall_m: 0.8744\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1115 - acc: 0.9635 - f1_m: 0.9635 - precision_m: 0.9635 - recall_m: 0.9635 - val_loss: 0.3312 - val_acc: 0.8744 - val_f1_m: 0.8744 - val_precision_m: 0.8744 - val_recall_m: 0.8744\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1081 - acc: 0.9611 - f1_m: 0.9611 - precision_m: 0.9611 - recall_m: 0.9611 - val_loss: 0.3342 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1051 - acc: 0.9627 - f1_m: 0.9627 - precision_m: 0.9627 - recall_m: 0.9627 - val_loss: 0.3395 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1022 - acc: 0.9637 - f1_m: 0.9637 - precision_m: 0.9637 - recall_m: 0.9637 - val_loss: 0.3433 - val_acc: 0.8778 - val_f1_m: 0.8778 - val_precision_m: 0.8778 - val_recall_m: 0.8778\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0979 - acc: 0.9631 - f1_m: 0.9631 - precision_m: 0.9631 - recall_m: 0.9631 - val_loss: 0.3495 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0968 - acc: 0.9635 - f1_m: 0.9635 - precision_m: 0.9635 - recall_m: 0.9635 - val_loss: 0.3531 - val_acc: 0.8762 - val_f1_m: 0.8762 - val_precision_m: 0.8762 - val_recall_m: 0.8762\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0938 - acc: 0.9668 - f1_m: 0.9668 - precision_m: 0.9668 - recall_m: 0.9668 - val_loss: 0.3533 - val_acc: 0.8819 - val_f1_m: 0.8819 - val_precision_m: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0938 - acc: 0.9634 - f1_m: 0.9634 - precision_m: 0.9634 - recall_m: 0.9634 - val_loss: 0.3643 - val_acc: 0.8762 - val_f1_m: 0.8762 - val_precision_m: 0.8762 - val_recall_m: 0.8762\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0891 - acc: 0.9684 - f1_m: 0.9684 - precision_m: 0.9684 - recall_m: 0.9684 - val_loss: 0.3649 - val_acc: 0.8800 - val_f1_m: 0.8800 - val_precision_m: 0.8800 - val_recall_m: 0.8800\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0877 - acc: 0.9674 - f1_m: 0.9674 - precision_m: 0.9674 - recall_m: 0.9674 - val_loss: 0.3692 - val_acc: 0.8800 - val_f1_m: 0.8800 - val_precision_m: 0.8800 - val_recall_m: 0.8800\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0869 - acc: 0.9636 - f1_m: 0.9636 - precision_m: 0.9636 - recall_m: 0.9636 - val_loss: 0.3757 - val_acc: 0.8791 - val_f1_m: 0.8791 - val_precision_m: 0.8791 - val_recall_m: 0.8791\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0867 - acc: 0.9654 - f1_m: 0.9654 - precision_m: 0.9654 - recall_m: 0.9654 - val_loss: 0.3789 - val_acc: 0.8791 - val_f1_m: 0.8791 - val_precision_m: 0.8791 - val_recall_m: 0.8791\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0832 - acc: 0.9683 - f1_m: 0.9683 - precision_m: 0.9683 - recall_m: 0.9683 - val_loss: 0.3854 - val_acc: 0.8788 - val_f1_m: 0.8787 - val_precision_m: 0.8788 - val_recall_m: 0.8788\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0830 - acc: 0.9662 - f1_m: 0.9662 - precision_m: 0.9662 - recall_m: 0.9662 - val_loss: 0.3952 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0815 - acc: 0.9684 - f1_m: 0.9684 - precision_m: 0.9684 - recall_m: 0.9684 - val_loss: 0.3973 - val_acc: 0.8778 - val_f1_m: 0.8778 - val_precision_m: 0.8778 - val_recall_m: 0.8778\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0833 - acc: 0.9661 - f1_m: 0.9661 - precision_m: 0.9661 - recall_m: 0.9661 - val_loss: 0.4010 - val_acc: 0.8784 - val_f1_m: 0.8784 - val_precision_m: 0.8784 - val_recall_m: 0.8784\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0816 - acc: 0.9664 - f1_m: 0.9664 - precision_m: 0.9664 - recall_m: 0.9664 - val_loss: 0.4044 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0786 - acc: 0.9681 - f1_m: 0.9681 - precision_m: 0.9681 - recall_m: 0.9681 - val_loss: 0.4096 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0760 - acc: 0.9694 - f1_m: 0.9694 - precision_m: 0.9694 - recall_m: 0.9694 - val_loss: 0.4105 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0775 - acc: 0.9669 - f1_m: 0.9669 - precision_m: 0.9669 - recall_m: 0.9669 - val_loss: 0.4213 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0757 - acc: 0.9695 - f1_m: 0.9695 - precision_m: 0.9695 - recall_m: 0.9695 - val_loss: 0.4256 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0765 - acc: 0.9683 - f1_m: 0.9683 - precision_m: 0.9683 - recall_m: 0.9683 - val_loss: 0.4295 - val_acc: 0.8784 - val_f1_m: 0.8784 - val_precision_m: 0.8784 - val_recall_m: 0.8784\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0778 - acc: 0.9666 - f1_m: 0.9666 - precision_m: 0.9666 - recall_m: 0.9666 - val_loss: 0.4354 - val_acc: 0.8784 - val_f1_m: 0.8784 - val_precision_m: 0.8784 - val_recall_m: 0.8784\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0740 - acc: 0.9688 - f1_m: 0.9688 - precision_m: 0.9688 - recall_m: 0.9688 - val_loss: 0.4353 - val_acc: 0.8797 - val_f1_m: 0.8797 - val_precision_m: 0.8797 - val_recall_m: 0.8797\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0764 - acc: 0.9648 - f1_m: 0.9648 - precision_m: 0.9648 - recall_m: 0.9648 - val_loss: 0.4386 - val_acc: 0.8797 - val_f1_m: 0.8797 - val_precision_m: 0.8797 - val_recall_m: 0.8797\n",
            "4001/4001 [==============================] - 0s 103us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/c3fjznvq\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 7s 550us/step - loss: 0.6727 - acc: 0.6009 - f1_m: 0.6009 - precision_m: 0.6009 - recall_m: 0.6009 - val_loss: 0.6579 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.6455 - acc: 0.6077 - f1_m: 0.6077 - precision_m: 0.6077 - recall_m: 0.6077 - val_loss: 0.6310 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.5982 - acc: 0.6392 - f1_m: 0.6392 - precision_m: 0.6392 - recall_m: 0.6392 - val_loss: 0.5803 - val_acc: 0.6803 - val_f1_m: 0.6803 - val_precision_m: 0.6803 - val_recall_m: 0.6803\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.5229 - acc: 0.7507 - f1_m: 0.7507 - precision_m: 0.7507 - recall_m: 0.7507 - val_loss: 0.5180 - val_acc: 0.7575 - val_f1_m: 0.7575 - val_precision_m: 0.7575 - val_recall_m: 0.7575\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.4326 - acc: 0.8283 - f1_m: 0.8283 - precision_m: 0.8283 - recall_m: 0.8283 - val_loss: 0.4574 - val_acc: 0.7978 - val_f1_m: 0.7978 - val_precision_m: 0.7978 - val_recall_m: 0.7978\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.3431 - acc: 0.8803 - f1_m: 0.8803 - precision_m: 0.8803 - recall_m: 0.8803 - val_loss: 0.4078 - val_acc: 0.8187 - val_f1_m: 0.8187 - val_precision_m: 0.8187 - val_recall_m: 0.8187\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.2626 - acc: 0.9238 - f1_m: 0.9238 - precision_m: 0.9238 - recall_m: 0.9238 - val_loss: 0.3679 - val_acc: 0.8400 - val_f1_m: 0.8400 - val_precision_m: 0.8400 - val_recall_m: 0.8400\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.1922 - acc: 0.9502 - f1_m: 0.9502 - precision_m: 0.9502 - recall_m: 0.9502 - val_loss: 0.3420 - val_acc: 0.8516 - val_f1_m: 0.8516 - val_precision_m: 0.8516 - val_recall_m: 0.8516\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1399 - acc: 0.9671 - f1_m: 0.9671 - precision_m: 0.9671 - recall_m: 0.9671 - val_loss: 0.3278 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1034 - acc: 0.9765 - f1_m: 0.9765 - precision_m: 0.9765 - recall_m: 0.9765 - val_loss: 0.3199 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0756 - acc: 0.9852 - f1_m: 0.9852 - precision_m: 0.9852 - recall_m: 0.9852 - val_loss: 0.3235 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0602 - acc: 0.9884 - f1_m: 0.9884 - precision_m: 0.9884 - recall_m: 0.9884 - val_loss: 0.3346 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0486 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.3420 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0416 - acc: 0.9917 - f1_m: 0.9917 - precision_m: 0.9917 - recall_m: 0.9917 - val_loss: 0.3470 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0343 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3608 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0285 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3762 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0256 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3701 - val_acc: 0.8825 - val_f1_m: 0.8825 - val_precision_m: 0.8825 - val_recall_m: 0.8825\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0229 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3966 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0215 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3949 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0200 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4057 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0183 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4326 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0180 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4147 - val_acc: 0.8819 - val_f1_m: 0.8819 - val_precision_m: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0157 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4485 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0164 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4422 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0157 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4528 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0142 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4590 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0140 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4645 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0127 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4821 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0132 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4854 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0124 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4883 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0126 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5100 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0118 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4941 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0109 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5106 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0108 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5217 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0109 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5204 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0105 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5105 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0108 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5273 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0112 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5262 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0104 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5437 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0109 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5350 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0098 - acc: 0.9963 - f1_m: 0.9963 - precision_m: 0.9963 - recall_m: 0.9963 - val_loss: 0.5403 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0101 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5608 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0102 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5484 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0105 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5513 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0103 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5627 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0102 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5621 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0107 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5538 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0094 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5835 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0100 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5555 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0103 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5710 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "4001/4001 [==============================] - 0s 114us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/sdo8fy64\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 7s 561us/step - loss: 0.6788 - acc: 0.5972 - f1_m: 0.5932 - precision_m: 0.5963 - recall_m: 0.5905 - val_loss: 0.6639 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.6625 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6495 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.6436 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6325 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.6231 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6075 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.5973 - acc: 0.6217 - f1_m: 0.6217 - precision_m: 0.6217 - recall_m: 0.6217 - val_loss: 0.5829 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.5716 - acc: 0.6332 - f1_m: 0.6332 - precision_m: 0.6332 - recall_m: 0.6332 - val_loss: 0.5603 - val_acc: 0.6119 - val_f1_m: 0.6119 - val_precision_m: 0.6119 - val_recall_m: 0.6119\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.5433 - acc: 0.6369 - f1_m: 0.6369 - precision_m: 0.6369 - recall_m: 0.6369 - val_loss: 0.5341 - val_acc: 0.7166 - val_f1_m: 0.7166 - val_precision_m: 0.7166 - val_recall_m: 0.7166\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.5150 - acc: 0.6430 - f1_m: 0.6430 - precision_m: 0.6430 - recall_m: 0.6430 - val_loss: 0.5093 - val_acc: 0.7609 - val_f1_m: 0.7609 - val_precision_m: 0.7609 - val_recall_m: 0.7609\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.4882 - acc: 0.6427 - f1_m: 0.6427 - precision_m: 0.6427 - recall_m: 0.6427 - val_loss: 0.4897 - val_acc: 0.7963 - val_f1_m: 0.7962 - val_precision_m: 0.7963 - val_recall_m: 0.7963\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.4577 - acc: 0.7416 - f1_m: 0.7416 - precision_m: 0.7416 - recall_m: 0.7416 - val_loss: 0.4650 - val_acc: 0.8231 - val_f1_m: 0.8231 - val_precision_m: 0.8231 - val_recall_m: 0.8231\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.4286 - acc: 0.8103 - f1_m: 0.8103 - precision_m: 0.8103 - recall_m: 0.8103 - val_loss: 0.4462 - val_acc: 0.8438 - val_f1_m: 0.8437 - val_precision_m: 0.8438 - val_recall_m: 0.8438\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.4069 - acc: 0.8353 - f1_m: 0.8353 - precision_m: 0.8353 - recall_m: 0.8353 - val_loss: 0.4298 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.3833 - acc: 0.8591 - f1_m: 0.8591 - precision_m: 0.8591 - recall_m: 0.8591 - val_loss: 0.4140 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.3652 - acc: 0.8674 - f1_m: 0.8674 - precision_m: 0.8674 - recall_m: 0.8674 - val_loss: 0.4023 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.3479 - acc: 0.8855 - f1_m: 0.8855 - precision_m: 0.8855 - recall_m: 0.8855 - val_loss: 0.3870 - val_acc: 0.8822 - val_f1_m: 0.8822 - val_precision_m: 0.8822 - val_recall_m: 0.8822\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.3316 - acc: 0.8816 - f1_m: 0.8816 - precision_m: 0.8816 - recall_m: 0.8816 - val_loss: 0.3715 - val_acc: 0.8856 - val_f1_m: 0.8856 - val_precision_m: 0.8856 - val_recall_m: 0.8856\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.3144 - acc: 0.8912 - f1_m: 0.8912 - precision_m: 0.8912 - recall_m: 0.8912 - val_loss: 0.3586 - val_acc: 0.8894 - val_f1_m: 0.8894 - val_precision_m: 0.8894 - val_recall_m: 0.8894\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.2992 - acc: 0.8967 - f1_m: 0.8967 - precision_m: 0.8967 - recall_m: 0.8967 - val_loss: 0.3539 - val_acc: 0.8922 - val_f1_m: 0.8922 - val_precision_m: 0.8922 - val_recall_m: 0.8922\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.2786 - acc: 0.9014 - f1_m: 0.9014 - precision_m: 0.9014 - recall_m: 0.9014 - val_loss: 0.3429 - val_acc: 0.8934 - val_f1_m: 0.8934 - val_precision_m: 0.8934 - val_recall_m: 0.8934\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.2649 - acc: 0.8995 - f1_m: 0.8995 - precision_m: 0.8995 - recall_m: 0.8995 - val_loss: 0.3345 - val_acc: 0.8931 - val_f1_m: 0.8931 - val_precision_m: 0.8931 - val_recall_m: 0.8931\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.2516 - acc: 0.9015 - f1_m: 0.9015 - precision_m: 0.9015 - recall_m: 0.9015 - val_loss: 0.3296 - val_acc: 0.8922 - val_f1_m: 0.8922 - val_precision_m: 0.8922 - val_recall_m: 0.8922\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.2348 - acc: 0.9037 - f1_m: 0.9037 - precision_m: 0.9037 - recall_m: 0.9037 - val_loss: 0.3271 - val_acc: 0.8925 - val_f1_m: 0.8925 - val_precision_m: 0.8925 - val_recall_m: 0.8925\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.2257 - acc: 0.9010 - f1_m: 0.9010 - precision_m: 0.9010 - recall_m: 0.9010 - val_loss: 0.3227 - val_acc: 0.8884 - val_f1_m: 0.8884 - val_precision_m: 0.8884 - val_recall_m: 0.8884\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.2109 - acc: 0.9028 - f1_m: 0.9028 - precision_m: 0.9028 - recall_m: 0.9028 - val_loss: 0.3208 - val_acc: 0.8866 - val_f1_m: 0.8866 - val_precision_m: 0.8866 - val_recall_m: 0.8866\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1939 - acc: 0.9041 - f1_m: 0.9041 - precision_m: 0.9041 - recall_m: 0.9041 - val_loss: 0.3256 - val_acc: 0.8862 - val_f1_m: 0.8862 - val_precision_m: 0.8862 - val_recall_m: 0.8862\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1873 - acc: 0.9027 - f1_m: 0.9027 - precision_m: 0.9027 - recall_m: 0.9027 - val_loss: 0.3288 - val_acc: 0.8844 - val_f1_m: 0.8844 - val_precision_m: 0.8844 - val_recall_m: 0.8844\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1765 - acc: 0.9073 - f1_m: 0.9073 - precision_m: 0.9073 - recall_m: 0.9073 - val_loss: 0.3321 - val_acc: 0.8866 - val_f1_m: 0.8866 - val_precision_m: 0.8866 - val_recall_m: 0.8866\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1724 - acc: 0.9046 - f1_m: 0.9046 - precision_m: 0.9046 - recall_m: 0.9046 - val_loss: 0.3444 - val_acc: 0.8791 - val_f1_m: 0.8791 - val_precision_m: 0.8791 - val_recall_m: 0.8791\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1707 - acc: 0.9045 - f1_m: 0.9045 - precision_m: 0.9045 - recall_m: 0.9045 - val_loss: 0.3443 - val_acc: 0.8841 - val_f1_m: 0.8841 - val_precision_m: 0.8841 - val_recall_m: 0.8841\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1625 - acc: 0.9087 - f1_m: 0.9087 - precision_m: 0.9087 - recall_m: 0.9087 - val_loss: 0.3518 - val_acc: 0.8812 - val_f1_m: 0.8812 - val_precision_m: 0.8812 - val_recall_m: 0.8812\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.1623 - acc: 0.9069 - f1_m: 0.9069 - precision_m: 0.9069 - recall_m: 0.9069 - val_loss: 0.3620 - val_acc: 0.8762 - val_f1_m: 0.8762 - val_precision_m: 0.8762 - val_recall_m: 0.8762\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1602 - acc: 0.9084 - f1_m: 0.9084 - precision_m: 0.9084 - recall_m: 0.9084 - val_loss: 0.3622 - val_acc: 0.8800 - val_f1_m: 0.8800 - val_precision_m: 0.8800 - val_recall_m: 0.8800\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1639 - acc: 0.9033 - f1_m: 0.9033 - precision_m: 0.9033 - recall_m: 0.9033 - val_loss: 0.3654 - val_acc: 0.8831 - val_f1_m: 0.8831 - val_precision_m: 0.8831 - val_recall_m: 0.8831\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1590 - acc: 0.9059 - f1_m: 0.9059 - precision_m: 0.9059 - recall_m: 0.9059 - val_loss: 0.3763 - val_acc: 0.8778 - val_f1_m: 0.8778 - val_precision_m: 0.8778 - val_recall_m: 0.8778\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1534 - acc: 0.9131 - f1_m: 0.9131 - precision_m: 0.9131 - recall_m: 0.9131 - val_loss: 0.3810 - val_acc: 0.8781 - val_f1_m: 0.8781 - val_precision_m: 0.8781 - val_recall_m: 0.8781\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1555 - acc: 0.9091 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 0.3841 - val_acc: 0.8822 - val_f1_m: 0.8822 - val_precision_m: 0.8822 - val_recall_m: 0.8822\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1581 - acc: 0.9029 - f1_m: 0.9029 - precision_m: 0.9029 - recall_m: 0.9029 - val_loss: 0.3920 - val_acc: 0.8791 - val_f1_m: 0.8791 - val_precision_m: 0.8791 - val_recall_m: 0.8791\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1574 - acc: 0.9070 - f1_m: 0.9070 - precision_m: 0.9070 - recall_m: 0.9070 - val_loss: 0.3887 - val_acc: 0.8828 - val_f1_m: 0.8828 - val_precision_m: 0.8828 - val_recall_m: 0.8828\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1553 - acc: 0.9068 - f1_m: 0.9068 - precision_m: 0.9068 - recall_m: 0.9068 - val_loss: 0.4054 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1493 - acc: 0.9125 - f1_m: 0.9125 - precision_m: 0.9125 - recall_m: 0.9125 - val_loss: 0.4008 - val_acc: 0.8822 - val_f1_m: 0.8822 - val_precision_m: 0.8822 - val_recall_m: 0.8822\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1503 - acc: 0.9109 - f1_m: 0.9109 - precision_m: 0.9109 - recall_m: 0.9109 - val_loss: 0.4090 - val_acc: 0.8759 - val_f1_m: 0.8759 - val_precision_m: 0.8759 - val_recall_m: 0.8759\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.1568 - acc: 0.9035 - f1_m: 0.9035 - precision_m: 0.9035 - recall_m: 0.9035 - val_loss: 0.4087 - val_acc: 0.8803 - val_f1_m: 0.8803 - val_precision_m: 0.8803 - val_recall_m: 0.8803\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1522 - acc: 0.9089 - f1_m: 0.9089 - precision_m: 0.9089 - recall_m: 0.9089 - val_loss: 0.4176 - val_acc: 0.8778 - val_f1_m: 0.8778 - val_precision_m: 0.8778 - val_recall_m: 0.8778\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1532 - acc: 0.9060 - f1_m: 0.9060 - precision_m: 0.9060 - recall_m: 0.9060 - val_loss: 0.4254 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1489 - acc: 0.9066 - f1_m: 0.9066 - precision_m: 0.9066 - recall_m: 0.9066 - val_loss: 0.4271 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1492 - acc: 0.9104 - f1_m: 0.9104 - precision_m: 0.9104 - recall_m: 0.9104 - val_loss: 0.4248 - val_acc: 0.8803 - val_f1_m: 0.8803 - val_precision_m: 0.8803 - val_recall_m: 0.8803\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1466 - acc: 0.9148 - f1_m: 0.9148 - precision_m: 0.9148 - recall_m: 0.9148 - val_loss: 0.4321 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1501 - acc: 0.9070 - f1_m: 0.9070 - precision_m: 0.9070 - recall_m: 0.9070 - val_loss: 0.4332 - val_acc: 0.8812 - val_f1_m: 0.8812 - val_precision_m: 0.8812 - val_recall_m: 0.8812\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1515 - acc: 0.9052 - f1_m: 0.9052 - precision_m: 0.9052 - recall_m: 0.9052 - val_loss: 0.4335 - val_acc: 0.8825 - val_f1_m: 0.8825 - val_precision_m: 0.8825 - val_recall_m: 0.8825\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1511 - acc: 0.9065 - f1_m: 0.9065 - precision_m: 0.9065 - recall_m: 0.9065 - val_loss: 0.4454 - val_acc: 0.8788 - val_f1_m: 0.8787 - val_precision_m: 0.8788 - val_recall_m: 0.8788\n",
            "4001/4001 [==============================] - 0s 107us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/oi8xjp43\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 7s 560us/step - loss: 0.6761 - acc: 0.6038 - f1_m: 0.6038 - precision_m: 0.6038 - recall_m: 0.6038 - val_loss: 0.6665 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.6647 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6562 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.6475 - acc: 0.6086 - f1_m: 0.6086 - precision_m: 0.6086 - recall_m: 0.6086 - val_loss: 0.6369 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6139 - acc: 0.6252 - f1_m: 0.6252 - precision_m: 0.6252 - recall_m: 0.6252 - val_loss: 0.6032 - val_acc: 0.6397 - val_f1_m: 0.6397 - val_precision_m: 0.6397 - val_recall_m: 0.6397\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.5628 - acc: 0.7041 - f1_m: 0.7041 - precision_m: 0.7041 - recall_m: 0.7041 - val_loss: 0.5573 - val_acc: 0.7294 - val_f1_m: 0.7294 - val_precision_m: 0.7294 - val_recall_m: 0.7294\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.4950 - acc: 0.7887 - f1_m: 0.7887 - precision_m: 0.7887 - recall_m: 0.7887 - val_loss: 0.5097 - val_acc: 0.7641 - val_f1_m: 0.7641 - val_precision_m: 0.7641 - val_recall_m: 0.7641\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.4263 - acc: 0.8374 - f1_m: 0.8374 - precision_m: 0.8374 - recall_m: 0.8374 - val_loss: 0.4672 - val_acc: 0.7784 - val_f1_m: 0.7784 - val_precision_m: 0.7784 - val_recall_m: 0.7784\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3567 - acc: 0.8714 - f1_m: 0.8714 - precision_m: 0.8714 - recall_m: 0.8714 - val_loss: 0.4315 - val_acc: 0.8003 - val_f1_m: 0.8003 - val_precision_m: 0.8003 - val_recall_m: 0.8003\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.2913 - acc: 0.9045 - f1_m: 0.9045 - precision_m: 0.9045 - recall_m: 0.9045 - val_loss: 0.4016 - val_acc: 0.8194 - val_f1_m: 0.8194 - val_precision_m: 0.8194 - val_recall_m: 0.8194\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2342 - acc: 0.9295 - f1_m: 0.9295 - precision_m: 0.9295 - recall_m: 0.9295 - val_loss: 0.3809 - val_acc: 0.8313 - val_f1_m: 0.8312 - val_precision_m: 0.8313 - val_recall_m: 0.8313\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1890 - acc: 0.9471 - f1_m: 0.9471 - precision_m: 0.9471 - recall_m: 0.9471 - val_loss: 0.3629 - val_acc: 0.8403 - val_f1_m: 0.8403 - val_precision_m: 0.8403 - val_recall_m: 0.8403\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1523 - acc: 0.9589 - f1_m: 0.9589 - precision_m: 0.9589 - recall_m: 0.9589 - val_loss: 0.3555 - val_acc: 0.8475 - val_f1_m: 0.8475 - val_precision_m: 0.8475 - val_recall_m: 0.8475\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1221 - acc: 0.9709 - f1_m: 0.9709 - precision_m: 0.9709 - recall_m: 0.9709 - val_loss: 0.3522 - val_acc: 0.8478 - val_f1_m: 0.8478 - val_precision_m: 0.8478 - val_recall_m: 0.8478\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1013 - acc: 0.9766 - f1_m: 0.9766 - precision_m: 0.9766 - recall_m: 0.9766 - val_loss: 0.3485 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0843 - acc: 0.9799 - f1_m: 0.9799 - precision_m: 0.9799 - recall_m: 0.9799 - val_loss: 0.3503 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0701 - acc: 0.9854 - f1_m: 0.9854 - precision_m: 0.9854 - recall_m: 0.9854 - val_loss: 0.3501 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0616 - acc: 0.9869 - f1_m: 0.9869 - precision_m: 0.9869 - recall_m: 0.9869 - val_loss: 0.3604 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0528 - acc: 0.9891 - f1_m: 0.9891 - precision_m: 0.9891 - recall_m: 0.9891 - val_loss: 0.3630 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0466 - acc: 0.9903 - f1_m: 0.9903 - precision_m: 0.9903 - recall_m: 0.9903 - val_loss: 0.3743 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0420 - acc: 0.9909 - f1_m: 0.9909 - precision_m: 0.9909 - recall_m: 0.9909 - val_loss: 0.3761 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0370 - acc: 0.9926 - f1_m: 0.9926 - precision_m: 0.9926 - recall_m: 0.9926 - val_loss: 0.3873 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0341 - acc: 0.9919 - f1_m: 0.9919 - precision_m: 0.9919 - recall_m: 0.9919 - val_loss: 0.3905 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0301 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.4053 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0278 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.4028 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0257 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4139 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0244 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4202 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0233 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.4343 - val_acc: 0.8509 - val_f1_m: 0.8509 - val_precision_m: 0.8509 - val_recall_m: 0.8509\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0214 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.4316 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0207 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4462 - val_acc: 0.8509 - val_f1_m: 0.8509 - val_precision_m: 0.8509 - val_recall_m: 0.8509\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0188 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4526 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0179 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4577 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0171 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4617 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0169 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4689 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0161 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4774 - val_acc: 0.8525 - val_f1_m: 0.8525 - val_precision_m: 0.8525 - val_recall_m: 0.8525\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0160 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4802 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0140 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4871 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0147 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5009 - val_acc: 0.8484 - val_f1_m: 0.8484 - val_precision_m: 0.8484 - val_recall_m: 0.8484\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0141 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4999 - val_acc: 0.8506 - val_f1_m: 0.8506 - val_precision_m: 0.8506 - val_recall_m: 0.8506\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0144 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5062 - val_acc: 0.8500 - val_f1_m: 0.8500 - val_precision_m: 0.8500 - val_recall_m: 0.8500\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0132 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5090 - val_acc: 0.8503 - val_f1_m: 0.8503 - val_precision_m: 0.8503 - val_recall_m: 0.8503\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0133 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5130 - val_acc: 0.8500 - val_f1_m: 0.8500 - val_precision_m: 0.8500 - val_recall_m: 0.8500\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0137 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5231 - val_acc: 0.8478 - val_f1_m: 0.8478 - val_precision_m: 0.8478 - val_recall_m: 0.8478\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0130 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5290 - val_acc: 0.8494 - val_f1_m: 0.8494 - val_precision_m: 0.8494 - val_recall_m: 0.8494\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0128 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5307 - val_acc: 0.8503 - val_f1_m: 0.8503 - val_precision_m: 0.8503 - val_recall_m: 0.8503\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0121 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5308 - val_acc: 0.8516 - val_f1_m: 0.8516 - val_precision_m: 0.8516 - val_recall_m: 0.8516\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0130 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5434 - val_acc: 0.8475 - val_f1_m: 0.8475 - val_precision_m: 0.8475 - val_recall_m: 0.8475\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0120 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5441 - val_acc: 0.8488 - val_f1_m: 0.8487 - val_precision_m: 0.8488 - val_recall_m: 0.8488\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0124 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5505 - val_acc: 0.8478 - val_f1_m: 0.8478 - val_precision_m: 0.8478 - val_recall_m: 0.8478\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0120 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5498 - val_acc: 0.8497 - val_f1_m: 0.8497 - val_precision_m: 0.8497 - val_recall_m: 0.8497\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0118 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5583 - val_acc: 0.8469 - val_f1_m: 0.8469 - val_precision_m: 0.8469 - val_recall_m: 0.8469\n",
            "4001/4001 [==============================] - 0s 112us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/zhm5m27g\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 8s 590us/step - loss: 0.6781 - acc: 0.5856 - f1_m: 0.5856 - precision_m: 0.5856 - recall_m: 0.5856 - val_loss: 0.6639 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6592 - acc: 0.6073 - f1_m: 0.6073 - precision_m: 0.6073 - recall_m: 0.6073 - val_loss: 0.6498 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6364 - acc: 0.6134 - f1_m: 0.6134 - precision_m: 0.6134 - recall_m: 0.6134 - val_loss: 0.6268 - val_acc: 0.6150 - val_f1_m: 0.6150 - val_precision_m: 0.6150 - val_recall_m: 0.6150\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5991 - acc: 0.6473 - f1_m: 0.6473 - precision_m: 0.6473 - recall_m: 0.6473 - val_loss: 0.5912 - val_acc: 0.6622 - val_f1_m: 0.6623 - val_precision_m: 0.6624 - val_recall_m: 0.6622\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.5488 - acc: 0.7368 - f1_m: 0.7368 - precision_m: 0.7368 - recall_m: 0.7368 - val_loss: 0.5448 - val_acc: 0.7438 - val_f1_m: 0.7437 - val_precision_m: 0.7438 - val_recall_m: 0.7438\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.4853 - acc: 0.8003 - f1_m: 0.8003 - precision_m: 0.8003 - recall_m: 0.8003 - val_loss: 0.4994 - val_acc: 0.7741 - val_f1_m: 0.7741 - val_precision_m: 0.7741 - val_recall_m: 0.7741\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.4219 - acc: 0.8443 - f1_m: 0.8443 - precision_m: 0.8443 - recall_m: 0.8443 - val_loss: 0.4598 - val_acc: 0.7913 - val_f1_m: 0.7912 - val_precision_m: 0.7913 - val_recall_m: 0.7913\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.3580 - acc: 0.8770 - f1_m: 0.8770 - precision_m: 0.8770 - recall_m: 0.8770 - val_loss: 0.4251 - val_acc: 0.8087 - val_f1_m: 0.8087 - val_precision_m: 0.8087 - val_recall_m: 0.8087\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3015 - acc: 0.9028 - f1_m: 0.9028 - precision_m: 0.9028 - recall_m: 0.9028 - val_loss: 0.3966 - val_acc: 0.8231 - val_f1_m: 0.8231 - val_precision_m: 0.8231 - val_recall_m: 0.8231\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2520 - acc: 0.9269 - f1_m: 0.9269 - precision_m: 0.9269 - recall_m: 0.9269 - val_loss: 0.3733 - val_acc: 0.8313 - val_f1_m: 0.8312 - val_precision_m: 0.8313 - val_recall_m: 0.8313\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2071 - acc: 0.9461 - f1_m: 0.9461 - precision_m: 0.9461 - recall_m: 0.9461 - val_loss: 0.3547 - val_acc: 0.8425 - val_f1_m: 0.8425 - val_precision_m: 0.8425 - val_recall_m: 0.8425\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1694 - acc: 0.9604 - f1_m: 0.9604 - precision_m: 0.9604 - recall_m: 0.9604 - val_loss: 0.3429 - val_acc: 0.8459 - val_f1_m: 0.8459 - val_precision_m: 0.8459 - val_recall_m: 0.8459\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1443 - acc: 0.9664 - f1_m: 0.9664 - precision_m: 0.9664 - recall_m: 0.9664 - val_loss: 0.3323 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1172 - acc: 0.9771 - f1_m: 0.9771 - precision_m: 0.9771 - recall_m: 0.9771 - val_loss: 0.3283 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1006 - acc: 0.9798 - f1_m: 0.9798 - precision_m: 0.9798 - recall_m: 0.9798 - val_loss: 0.3331 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0864 - acc: 0.9828 - f1_m: 0.9828 - precision_m: 0.9828 - recall_m: 0.9828 - val_loss: 0.3243 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0754 - acc: 0.9852 - f1_m: 0.9852 - precision_m: 0.9852 - recall_m: 0.9852 - val_loss: 0.3343 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0665 - acc: 0.9879 - f1_m: 0.9879 - precision_m: 0.9879 - recall_m: 0.9879 - val_loss: 0.3343 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0586 - acc: 0.9891 - f1_m: 0.9891 - precision_m: 0.9891 - recall_m: 0.9891 - val_loss: 0.3471 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0526 - acc: 0.9898 - f1_m: 0.9898 - precision_m: 0.9898 - recall_m: 0.9898 - val_loss: 0.3430 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0474 - acc: 0.9909 - f1_m: 0.9909 - precision_m: 0.9909 - recall_m: 0.9909 - val_loss: 0.3575 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0427 - acc: 0.9921 - f1_m: 0.9921 - precision_m: 0.9921 - recall_m: 0.9921 - val_loss: 0.3595 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0393 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.3703 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0366 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3709 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0336 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3840 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0306 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3872 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0294 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3945 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0274 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.4059 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0255 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4040 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0253 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.4120 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0231 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4240 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0223 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4231 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0212 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4365 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0191 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4444 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0189 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4481 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0186 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4549 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0189 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4616 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0185 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4649 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0174 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4761 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0171 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4824 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0163 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4889 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0168 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4890 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0162 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4999 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0155 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5141 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0149 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5068 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0145 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5103 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0149 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5166 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0144 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5360 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0142 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5385 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0132 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5361 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "4001/4001 [==============================] - 0s 107us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/urlvgkyy\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 7s 571us/step - loss: 0.6756 - acc: 0.5941 - f1_m: 0.5941 - precision_m: 0.5941 - recall_m: 0.5941 - val_loss: 0.6643 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6544 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6441 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6201 - acc: 0.6086 - f1_m: 0.6086 - precision_m: 0.6086 - recall_m: 0.6086 - val_loss: 0.6047 - val_acc: 0.6225 - val_f1_m: 0.6225 - val_precision_m: 0.6225 - val_recall_m: 0.6225\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5536 - acc: 0.7047 - f1_m: 0.7047 - precision_m: 0.7047 - recall_m: 0.7047 - val_loss: 0.5427 - val_acc: 0.7456 - val_f1_m: 0.7456 - val_precision_m: 0.7456 - val_recall_m: 0.7456\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.4594 - acc: 0.8292 - f1_m: 0.8292 - precision_m: 0.8292 - recall_m: 0.8292 - val_loss: 0.4760 - val_acc: 0.7837 - val_f1_m: 0.7837 - val_precision_m: 0.7837 - val_recall_m: 0.7837\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3594 - acc: 0.8802 - f1_m: 0.8802 - precision_m: 0.8802 - recall_m: 0.8802 - val_loss: 0.4217 - val_acc: 0.8122 - val_f1_m: 0.8122 - val_precision_m: 0.8122 - val_recall_m: 0.8122\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2707 - acc: 0.9169 - f1_m: 0.9169 - precision_m: 0.9169 - recall_m: 0.9169 - val_loss: 0.3792 - val_acc: 0.8350 - val_f1_m: 0.8350 - val_precision_m: 0.8350 - val_recall_m: 0.8350\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1960 - acc: 0.9452 - f1_m: 0.9452 - precision_m: 0.9452 - recall_m: 0.9452 - val_loss: 0.3507 - val_acc: 0.8494 - val_f1_m: 0.8494 - val_precision_m: 0.8494 - val_recall_m: 0.8494\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1400 - acc: 0.9647 - f1_m: 0.9647 - precision_m: 0.9647 - recall_m: 0.9647 - val_loss: 0.3335 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0994 - acc: 0.9788 - f1_m: 0.9788 - precision_m: 0.9788 - recall_m: 0.9788 - val_loss: 0.3250 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0730 - acc: 0.9857 - f1_m: 0.9857 - precision_m: 0.9857 - recall_m: 0.9857 - val_loss: 0.3247 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0569 - acc: 0.9879 - f1_m: 0.9879 - precision_m: 0.9879 - recall_m: 0.9879 - val_loss: 0.3314 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0438 - acc: 0.9912 - f1_m: 0.9912 - precision_m: 0.9912 - recall_m: 0.9912 - val_loss: 0.3472 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0361 - acc: 0.9926 - f1_m: 0.9926 - precision_m: 0.9926 - recall_m: 0.9926 - val_loss: 0.3375 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0301 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.3468 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0252 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3726 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0231 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.3583 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0197 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3750 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0180 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.3833 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0168 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.3820 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0154 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3977 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0146 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.3991 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0147 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4041 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0140 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4158 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0133 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4107 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0133 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4273 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0126 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4242 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0125 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4420 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0118 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4369 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0119 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4341 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0113 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4535 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0112 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4521 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0109 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4528 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0106 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4508 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0100 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4718 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0108 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4668 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0104 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4702 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4754 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0097 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4782 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0103 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4813 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0102 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4820 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0099 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4946 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0094 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4903 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0096 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4935 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0101 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5026 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0096 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5030 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0093 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5018 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0092 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5075 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0093 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5031 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0096 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5136 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "4001/4001 [==============================] - 1s 126us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/9bvds88h\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 7s 572us/step - loss: 0.6845 - acc: 0.5685 - f1_m: 0.5685 - precision_m: 0.5685 - recall_m: 0.5684 - val_loss: 0.6681 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6705 - acc: 0.6064 - f1_m: 0.6064 - precision_m: 0.6064 - recall_m: 0.6064 - val_loss: 0.6625 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6621 - acc: 0.6072 - f1_m: 0.6072 - precision_m: 0.6072 - recall_m: 0.6072 - val_loss: 0.6530 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6439 - acc: 0.6091 - f1_m: 0.6091 - precision_m: 0.6091 - recall_m: 0.6091 - val_loss: 0.6334 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6146 - acc: 0.6302 - f1_m: 0.6302 - precision_m: 0.6302 - recall_m: 0.6302 - val_loss: 0.6015 - val_acc: 0.6250 - val_f1_m: 0.6250 - val_precision_m: 0.6250 - val_recall_m: 0.6250\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5674 - acc: 0.6937 - f1_m: 0.6937 - precision_m: 0.6937 - recall_m: 0.6937 - val_loss: 0.5587 - val_acc: 0.7081 - val_f1_m: 0.7081 - val_precision_m: 0.7081 - val_recall_m: 0.7081\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.5104 - acc: 0.7506 - f1_m: 0.7506 - precision_m: 0.7506 - recall_m: 0.7506 - val_loss: 0.5134 - val_acc: 0.7675 - val_f1_m: 0.7675 - val_precision_m: 0.7675 - val_recall_m: 0.7675\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4470 - acc: 0.8032 - f1_m: 0.8032 - precision_m: 0.8032 - recall_m: 0.8032 - val_loss: 0.4726 - val_acc: 0.7831 - val_f1_m: 0.7831 - val_precision_m: 0.7831 - val_recall_m: 0.7831\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3852 - acc: 0.8508 - f1_m: 0.8508 - precision_m: 0.8508 - recall_m: 0.8508 - val_loss: 0.4352 - val_acc: 0.8047 - val_f1_m: 0.8047 - val_precision_m: 0.8047 - val_recall_m: 0.8047\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3250 - acc: 0.8843 - f1_m: 0.8843 - precision_m: 0.8843 - recall_m: 0.8843 - val_loss: 0.4033 - val_acc: 0.8234 - val_f1_m: 0.8234 - val_precision_m: 0.8234 - val_recall_m: 0.8234\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2703 - acc: 0.9128 - f1_m: 0.9128 - precision_m: 0.9128 - recall_m: 0.9128 - val_loss: 0.3779 - val_acc: 0.8384 - val_f1_m: 0.8384 - val_precision_m: 0.8384 - val_recall_m: 0.8384\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2255 - acc: 0.9341 - f1_m: 0.9341 - precision_m: 0.9341 - recall_m: 0.9341 - val_loss: 0.3598 - val_acc: 0.8481 - val_f1_m: 0.8481 - val_precision_m: 0.8481 - val_recall_m: 0.8481\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1926 - acc: 0.9473 - f1_m: 0.9473 - precision_m: 0.9473 - recall_m: 0.9473 - val_loss: 0.3437 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1601 - acc: 0.9605 - f1_m: 0.9605 - precision_m: 0.9605 - recall_m: 0.9605 - val_loss: 0.3375 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1320 - acc: 0.9706 - f1_m: 0.9706 - precision_m: 0.9706 - recall_m: 0.9706 - val_loss: 0.3325 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1130 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - val_loss: 0.3387 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0984 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 0.3379 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0858 - acc: 0.9831 - f1_m: 0.9831 - precision_m: 0.9831 - recall_m: 0.9831 - val_loss: 0.3419 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0772 - acc: 0.9842 - f1_m: 0.9842 - precision_m: 0.9842 - recall_m: 0.9842 - val_loss: 0.3529 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0687 - acc: 0.9862 - f1_m: 0.9862 - precision_m: 0.9862 - recall_m: 0.9862 - val_loss: 0.3594 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0612 - acc: 0.9897 - f1_m: 0.9897 - precision_m: 0.9897 - recall_m: 0.9897 - val_loss: 0.3685 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0550 - acc: 0.9899 - f1_m: 0.9899 - precision_m: 0.9899 - recall_m: 0.9899 - val_loss: 0.3810 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0514 - acc: 0.9891 - f1_m: 0.9891 - precision_m: 0.9891 - recall_m: 0.9891 - val_loss: 0.3865 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0449 - acc: 0.9919 - f1_m: 0.9919 - precision_m: 0.9919 - recall_m: 0.9919 - val_loss: 0.3970 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0436 - acc: 0.9925 - f1_m: 0.9925 - precision_m: 0.9925 - recall_m: 0.9925 - val_loss: 0.4066 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0412 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.4084 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0385 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.4281 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0340 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.4341 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0309 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.4486 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0311 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 0.4483 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0296 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.4641 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0276 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4714 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0258 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.4841 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0255 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.4926 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0248 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4987 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0218 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5059 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0215 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5143 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0224 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.5277 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0209 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5310 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0217 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.5455 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0197 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.5423 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0195 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5519 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0192 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.5651 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0181 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5709 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0177 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5782 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0187 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5773 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0167 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5988 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0173 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6166 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0162 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.6071 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0176 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.6028 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "4001/4001 [==============================] - 0s 117us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/7azybxsg\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 8s 603us/step - loss: 0.6718 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6632 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6547 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6455 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6224 - acc: 0.6101 - f1_m: 0.6101 - precision_m: 0.6101 - recall_m: 0.6101 - val_loss: 0.6086 - val_acc: 0.6238 - val_f1_m: 0.6237 - val_precision_m: 0.6238 - val_recall_m: 0.6238\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.5582 - acc: 0.7034 - f1_m: 0.7034 - precision_m: 0.7034 - recall_m: 0.7034 - val_loss: 0.5486 - val_acc: 0.7344 - val_f1_m: 0.7344 - val_precision_m: 0.7344 - val_recall_m: 0.7344\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.4684 - acc: 0.8200 - f1_m: 0.8200 - precision_m: 0.8200 - recall_m: 0.8200 - val_loss: 0.4858 - val_acc: 0.7769 - val_f1_m: 0.7769 - val_precision_m: 0.7769 - val_recall_m: 0.7769\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.3725 - acc: 0.8694 - f1_m: 0.8694 - precision_m: 0.8694 - recall_m: 0.8694 - val_loss: 0.4353 - val_acc: 0.8034 - val_f1_m: 0.8034 - val_precision_m: 0.8034 - val_recall_m: 0.8034\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2855 - acc: 0.9075 - f1_m: 0.9075 - precision_m: 0.9075 - recall_m: 0.9075 - val_loss: 0.3946 - val_acc: 0.8231 - val_f1_m: 0.8231 - val_precision_m: 0.8231 - val_recall_m: 0.8231\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2130 - acc: 0.9365 - f1_m: 0.9365 - precision_m: 0.9365 - recall_m: 0.9365 - val_loss: 0.3666 - val_acc: 0.8356 - val_f1_m: 0.8356 - val_precision_m: 0.8356 - val_recall_m: 0.8356\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1553 - acc: 0.9588 - f1_m: 0.9588 - precision_m: 0.9588 - recall_m: 0.9588 - val_loss: 0.3479 - val_acc: 0.8488 - val_f1_m: 0.8487 - val_precision_m: 0.8488 - val_recall_m: 0.8488\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1155 - acc: 0.9723 - f1_m: 0.9723 - precision_m: 0.9723 - recall_m: 0.9723 - val_loss: 0.3372 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0860 - acc: 0.9799 - f1_m: 0.9799 - precision_m: 0.9799 - recall_m: 0.9799 - val_loss: 0.3336 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0665 - acc: 0.9855 - f1_m: 0.9855 - precision_m: 0.9855 - recall_m: 0.9855 - val_loss: 0.3340 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0527 - acc: 0.9893 - f1_m: 0.9893 - precision_m: 0.9893 - recall_m: 0.9893 - val_loss: 0.3468 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0428 - acc: 0.9909 - f1_m: 0.9909 - precision_m: 0.9909 - recall_m: 0.9909 - val_loss: 0.3444 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0360 - acc: 0.9926 - f1_m: 0.9926 - precision_m: 0.9926 - recall_m: 0.9926 - val_loss: 0.3482 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0314 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.3614 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0262 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3617 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0230 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3726 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0211 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.3738 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0190 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3864 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0174 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3902 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0163 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4004 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0156 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4019 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0149 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4062 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0143 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4219 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0139 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4232 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0128 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4216 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0129 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4412 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0128 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4277 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0123 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4435 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0120 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4424 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0122 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4555 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0124 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4433 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0117 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4627 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0110 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4543 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0105 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4705 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0112 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4622 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0109 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4741 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0104 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4740 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0106 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4740 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0107 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4857 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0107 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4873 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0096 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4848 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0107 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4894 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0100 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5005 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0103 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4998 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0099 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5098 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0101 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4955 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0096 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5147 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0101 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5048 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "4001/4001 [==============================] - 0s 117us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/8spdsuww\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 8s 605us/step - loss: 0.6717 - acc: 0.5948 - f1_m: 0.5948 - precision_m: 0.5948 - recall_m: 0.5948 - val_loss: 0.6572 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.6426 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6284 - val_acc: 0.6125 - val_f1_m: 0.6125 - val_precision_m: 0.6125 - val_recall_m: 0.6125\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.5867 - acc: 0.6504 - f1_m: 0.6504 - precision_m: 0.6504 - recall_m: 0.6504 - val_loss: 0.5677 - val_acc: 0.7103 - val_f1_m: 0.7103 - val_precision_m: 0.7103 - val_recall_m: 0.7103\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.4885 - acc: 0.8084 - f1_m: 0.8084 - precision_m: 0.8084 - recall_m: 0.8084 - val_loss: 0.4907 - val_acc: 0.7772 - val_f1_m: 0.7772 - val_precision_m: 0.7772 - val_recall_m: 0.7772\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.3715 - acc: 0.8777 - f1_m: 0.8777 - precision_m: 0.8777 - recall_m: 0.8777 - val_loss: 0.4257 - val_acc: 0.8069 - val_f1_m: 0.8069 - val_precision_m: 0.8069 - val_recall_m: 0.8069\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.2650 - acc: 0.9196 - f1_m: 0.9196 - precision_m: 0.9196 - recall_m: 0.9196 - val_loss: 0.3798 - val_acc: 0.8241 - val_f1_m: 0.8241 - val_precision_m: 0.8241 - val_recall_m: 0.8241\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1790 - acc: 0.9527 - f1_m: 0.9527 - precision_m: 0.9527 - recall_m: 0.9527 - val_loss: 0.3514 - val_acc: 0.8369 - val_f1_m: 0.8369 - val_precision_m: 0.8369 - val_recall_m: 0.8369\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1196 - acc: 0.9715 - f1_m: 0.9715 - precision_m: 0.9715 - recall_m: 0.9715 - val_loss: 0.3343 - val_acc: 0.8472 - val_f1_m: 0.8472 - val_precision_m: 0.8472 - val_recall_m: 0.8472\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0809 - acc: 0.9828 - f1_m: 0.9828 - precision_m: 0.9828 - recall_m: 0.9828 - val_loss: 0.3376 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0573 - acc: 0.9889 - f1_m: 0.9889 - precision_m: 0.9889 - recall_m: 0.9889 - val_loss: 0.3346 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0415 - acc: 0.9919 - f1_m: 0.9919 - precision_m: 0.9919 - recall_m: 0.9919 - val_loss: 0.3377 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0320 - acc: 0.9927 - f1_m: 0.9927 - precision_m: 0.9927 - recall_m: 0.9927 - val_loss: 0.3446 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0260 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.3561 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0216 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3490 - val_acc: 0.8781 - val_f1_m: 0.8781 - val_precision_m: 0.8781 - val_recall_m: 0.8781\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0192 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3749 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0169 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3822 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0161 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3779 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0154 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3825 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0142 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4045 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0130 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4014 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0127 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4004 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0129 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4083 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0118 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4124 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0117 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4323 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0111 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4230 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0113 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4261 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0109 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4380 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0110 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4467 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0108 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4316 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0098 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.4467 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0100 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4505 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0100 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.4575 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0098 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4549 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0101 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4535 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0100 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4623 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0099 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4857 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0102 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4664 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0101 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4707 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0094 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4734 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0094 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4769 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0096 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4779 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0098 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4849 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0095 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4841 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0092 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4882 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0094 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4913 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0095 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5091 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0096 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4817 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0091 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4968 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0092 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5154 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0090 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4997 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "4001/4001 [==============================] - 0s 114us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/nubdibdc\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 8s 619us/step - loss: 0.6714 - acc: 0.6030 - f1_m: 0.6030 - precision_m: 0.6030 - recall_m: 0.6030 - val_loss: 0.6591 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.6468 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6352 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.6060 - acc: 0.6141 - f1_m: 0.6141 - precision_m: 0.6141 - recall_m: 0.6141 - val_loss: 0.5941 - val_acc: 0.6266 - val_f1_m: 0.6266 - val_precision_m: 0.6266 - val_recall_m: 0.6266\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.5459 - acc: 0.6891 - f1_m: 0.6891 - precision_m: 0.6891 - recall_m: 0.6891 - val_loss: 0.5462 - val_acc: 0.7209 - val_f1_m: 0.7209 - val_precision_m: 0.7209 - val_recall_m: 0.7209\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.4754 - acc: 0.7855 - f1_m: 0.7855 - precision_m: 0.7855 - recall_m: 0.7855 - val_loss: 0.4970 - val_acc: 0.7803 - val_f1_m: 0.7803 - val_precision_m: 0.7803 - val_recall_m: 0.7803\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.3966 - acc: 0.8766 - f1_m: 0.8766 - precision_m: 0.8766 - recall_m: 0.8766 - val_loss: 0.4406 - val_acc: 0.8144 - val_f1_m: 0.8144 - val_precision_m: 0.8144 - val_recall_m: 0.8144\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.3135 - acc: 0.9073 - f1_m: 0.9073 - precision_m: 0.9073 - recall_m: 0.9073 - val_loss: 0.3968 - val_acc: 0.8250 - val_f1_m: 0.8250 - val_precision_m: 0.8250 - val_recall_m: 0.8250\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.2394 - acc: 0.9360 - f1_m: 0.9360 - precision_m: 0.9360 - recall_m: 0.9360 - val_loss: 0.3652 - val_acc: 0.8337 - val_f1_m: 0.8337 - val_precision_m: 0.8337 - val_recall_m: 0.8337\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1802 - acc: 0.9552 - f1_m: 0.9552 - precision_m: 0.9552 - recall_m: 0.9552 - val_loss: 0.3444 - val_acc: 0.8459 - val_f1_m: 0.8459 - val_precision_m: 0.8459 - val_recall_m: 0.8459\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1331 - acc: 0.9697 - f1_m: 0.9697 - precision_m: 0.9697 - recall_m: 0.9697 - val_loss: 0.3308 - val_acc: 0.8500 - val_f1_m: 0.8500 - val_precision_m: 0.8500 - val_recall_m: 0.8500\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.1003 - acc: 0.9767 - f1_m: 0.9767 - precision_m: 0.9767 - recall_m: 0.9767 - val_loss: 0.3235 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0767 - acc: 0.9835 - f1_m: 0.9835 - precision_m: 0.9835 - recall_m: 0.9835 - val_loss: 0.3255 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0591 - acc: 0.9889 - f1_m: 0.9889 - precision_m: 0.9889 - recall_m: 0.9889 - val_loss: 0.3320 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0477 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.3409 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0397 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.3377 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0331 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.3451 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0301 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9932 - recall_m: 0.9932 - val_loss: 0.3658 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0255 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3655 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0242 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3754 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0209 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3861 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0198 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3930 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0182 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3975 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0168 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4050 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0168 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4098 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0158 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4222 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0156 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4232 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0151 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4420 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0157 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4295 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0151 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4450 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0136 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4486 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0128 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4525 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0132 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4594 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0125 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4613 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0128 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4746 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0119 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.4705 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0116 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4813 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0117 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4793 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0119 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4869 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0115 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4969 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0116 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4985 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0105 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5011 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0109 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5041 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0113 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5173 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0103 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5312 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0110 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5227 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0104 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5176 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0110 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5401 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0105 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5273 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0106 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5456 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0107 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5483 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "4001/4001 [==============================] - 0s 124us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/ybjt3ddg\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 8s 608us/step - loss: 0.6799 - acc: 0.5954 - f1_m: 0.5954 - precision_m: 0.5954 - recall_m: 0.5954 - val_loss: 0.6687 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.6650 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6581 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6491 - acc: 0.6071 - f1_m: 0.6071 - precision_m: 0.6071 - recall_m: 0.6071 - val_loss: 0.6414 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6216 - acc: 0.6175 - f1_m: 0.6175 - precision_m: 0.6175 - recall_m: 0.6175 - val_loss: 0.6123 - val_acc: 0.6272 - val_f1_m: 0.6272 - val_precision_m: 0.6272 - val_recall_m: 0.6272\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.5757 - acc: 0.6867 - f1_m: 0.6867 - precision_m: 0.6867 - recall_m: 0.6867 - val_loss: 0.5716 - val_acc: 0.7081 - val_f1_m: 0.7081 - val_precision_m: 0.7081 - val_recall_m: 0.7081\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.5147 - acc: 0.7812 - f1_m: 0.7812 - precision_m: 0.7812 - recall_m: 0.7812 - val_loss: 0.5246 - val_acc: 0.7612 - val_f1_m: 0.7612 - val_precision_m: 0.7612 - val_recall_m: 0.7612\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.4487 - acc: 0.8319 - f1_m: 0.8319 - precision_m: 0.8319 - recall_m: 0.8319 - val_loss: 0.4804 - val_acc: 0.7856 - val_f1_m: 0.7856 - val_precision_m: 0.7856 - val_recall_m: 0.7856\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3806 - acc: 0.8652 - f1_m: 0.8652 - precision_m: 0.8652 - recall_m: 0.8652 - val_loss: 0.4421 - val_acc: 0.7972 - val_f1_m: 0.7972 - val_precision_m: 0.7972 - val_recall_m: 0.7972\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.3191 - acc: 0.8928 - f1_m: 0.8928 - precision_m: 0.8928 - recall_m: 0.8928 - val_loss: 0.4117 - val_acc: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.2630 - acc: 0.9165 - f1_m: 0.9165 - precision_m: 0.9165 - recall_m: 0.9165 - val_loss: 0.3853 - val_acc: 0.8344 - val_f1_m: 0.8344 - val_precision_m: 0.8344 - val_recall_m: 0.8344\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.2173 - acc: 0.9373 - f1_m: 0.9373 - precision_m: 0.9373 - recall_m: 0.9373 - val_loss: 0.3652 - val_acc: 0.8453 - val_f1_m: 0.8453 - val_precision_m: 0.8453 - val_recall_m: 0.8453\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1760 - acc: 0.9520 - f1_m: 0.9520 - precision_m: 0.9520 - recall_m: 0.9520 - val_loss: 0.3518 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1439 - acc: 0.9630 - f1_m: 0.9630 - precision_m: 0.9630 - recall_m: 0.9630 - val_loss: 0.3421 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1190 - acc: 0.9709 - f1_m: 0.9709 - precision_m: 0.9709 - recall_m: 0.9709 - val_loss: 0.3359 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.1013 - acc: 0.9761 - f1_m: 0.9761 - precision_m: 0.9761 - recall_m: 0.9761 - val_loss: 0.3344 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0847 - acc: 0.9798 - f1_m: 0.9798 - precision_m: 0.9798 - recall_m: 0.9798 - val_loss: 0.3352 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0729 - acc: 0.9849 - f1_m: 0.9849 - precision_m: 0.9849 - recall_m: 0.9849 - val_loss: 0.3365 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0626 - acc: 0.9871 - f1_m: 0.9871 - precision_m: 0.9871 - recall_m: 0.9871 - val_loss: 0.3358 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0558 - acc: 0.9883 - f1_m: 0.9883 - precision_m: 0.9883 - recall_m: 0.9883 - val_loss: 0.3433 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0486 - acc: 0.9901 - f1_m: 0.9901 - precision_m: 0.9901 - recall_m: 0.9901 - val_loss: 0.3441 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0445 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 0.3530 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0403 - acc: 0.9914 - f1_m: 0.9914 - precision_m: 0.9914 - recall_m: 0.9914 - val_loss: 0.3556 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0375 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3574 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0329 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3651 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0309 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3733 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0287 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.3740 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0268 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3838 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0250 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3857 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0237 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3913 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0225 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4003 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0210 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4023 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0204 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.4109 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0189 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4158 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0181 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4223 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0170 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4249 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0164 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4314 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0165 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4400 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0163 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4451 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0168 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4429 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0146 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4447 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0146 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4530 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0148 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4658 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0136 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4584 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0125 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4681 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0133 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4692 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0136 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4783 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0125 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4796 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0123 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4852 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0136 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4860 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0131 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4888 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "4001/4001 [==============================] - 0s 121us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/wauvzb78\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 8s 630us/step - loss: 0.6876 - acc: 0.5712 - f1_m: 0.5690 - precision_m: 0.5705 - recall_m: 0.5676 - val_loss: 0.6697 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.6723 - acc: 0.6069 - f1_m: 0.6069 - precision_m: 0.6069 - recall_m: 0.6069 - val_loss: 0.6605 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.6597 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6481 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.6401 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6293 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.6185 - acc: 0.6070 - f1_m: 0.6070 - precision_m: 0.6070 - recall_m: 0.6070 - val_loss: 0.6061 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.5922 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.5817 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.5653 - acc: 0.6070 - f1_m: 0.6070 - precision_m: 0.6070 - recall_m: 0.6070 - val_loss: 0.5561 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.5368 - acc: 0.6108 - f1_m: 0.6108 - precision_m: 0.6108 - recall_m: 0.6108 - val_loss: 0.5318 - val_acc: 0.6197 - val_f1_m: 0.6197 - val_precision_m: 0.6197 - val_recall_m: 0.6197\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.5082 - acc: 0.6346 - f1_m: 0.6346 - precision_m: 0.6346 - recall_m: 0.6346 - val_loss: 0.5031 - val_acc: 0.7750 - val_f1_m: 0.7750 - val_precision_m: 0.7750 - val_recall_m: 0.7750\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.4675 - acc: 0.7048 - f1_m: 0.7048 - precision_m: 0.7048 - recall_m: 0.7048 - val_loss: 0.4740 - val_acc: 0.8263 - val_f1_m: 0.8262 - val_precision_m: 0.8263 - val_recall_m: 0.8263\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.4354 - acc: 0.7923 - f1_m: 0.7923 - precision_m: 0.7923 - recall_m: 0.7923 - val_loss: 0.4481 - val_acc: 0.8375 - val_f1_m: 0.8375 - val_precision_m: 0.8375 - val_recall_m: 0.8375\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.4033 - acc: 0.8430 - f1_m: 0.8430 - precision_m: 0.8430 - recall_m: 0.8430 - val_loss: 0.4264 - val_acc: 0.8484 - val_f1_m: 0.8484 - val_precision_m: 0.8484 - val_recall_m: 0.8484\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.3707 - acc: 0.8635 - f1_m: 0.8635 - precision_m: 0.8635 - recall_m: 0.8635 - val_loss: 0.3992 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.3406 - acc: 0.8736 - f1_m: 0.8736 - precision_m: 0.8736 - recall_m: 0.8736 - val_loss: 0.3794 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.3032 - acc: 0.8881 - f1_m: 0.8881 - precision_m: 0.8881 - recall_m: 0.8881 - val_loss: 0.3588 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2804 - acc: 0.8958 - f1_m: 0.8958 - precision_m: 0.8958 - recall_m: 0.8958 - val_loss: 0.3447 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.2549 - acc: 0.9062 - f1_m: 0.9062 - precision_m: 0.9062 - recall_m: 0.9062 - val_loss: 0.3337 - val_acc: 0.8788 - val_f1_m: 0.8787 - val_precision_m: 0.8788 - val_recall_m: 0.8788\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2350 - acc: 0.9107 - f1_m: 0.9107 - precision_m: 0.9107 - recall_m: 0.9107 - val_loss: 0.3229 - val_acc: 0.8859 - val_f1_m: 0.8859 - val_precision_m: 0.8859 - val_recall_m: 0.8859\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2144 - acc: 0.9131 - f1_m: 0.9131 - precision_m: 0.9131 - recall_m: 0.9131 - val_loss: 0.3187 - val_acc: 0.8819 - val_f1_m: 0.8819 - val_precision_m: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.2045 - acc: 0.9127 - f1_m: 0.9127 - precision_m: 0.9127 - recall_m: 0.9127 - val_loss: 0.3164 - val_acc: 0.8809 - val_f1_m: 0.8809 - val_precision_m: 0.8809 - val_recall_m: 0.8809\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1894 - acc: 0.9183 - f1_m: 0.9183 - precision_m: 0.9183 - recall_m: 0.9183 - val_loss: 0.3133 - val_acc: 0.8838 - val_f1_m: 0.8837 - val_precision_m: 0.8838 - val_recall_m: 0.8838\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1793 - acc: 0.9248 - f1_m: 0.9248 - precision_m: 0.9248 - recall_m: 0.9248 - val_loss: 0.3147 - val_acc: 0.8856 - val_f1_m: 0.8856 - val_precision_m: 0.8856 - val_recall_m: 0.8856\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1673 - acc: 0.9213 - f1_m: 0.9212 - precision_m: 0.9213 - recall_m: 0.9213 - val_loss: 0.3221 - val_acc: 0.8778 - val_f1_m: 0.8778 - val_precision_m: 0.8778 - val_recall_m: 0.8778\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1575 - acc: 0.9206 - f1_m: 0.9206 - precision_m: 0.9206 - recall_m: 0.9206 - val_loss: 0.3249 - val_acc: 0.8819 - val_f1_m: 0.8819 - val_precision_m: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1540 - acc: 0.9180 - f1_m: 0.9180 - precision_m: 0.9180 - recall_m: 0.9180 - val_loss: 0.3304 - val_acc: 0.8825 - val_f1_m: 0.8825 - val_precision_m: 0.8825 - val_recall_m: 0.8825\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1381 - acc: 0.9246 - f1_m: 0.9246 - precision_m: 0.9246 - recall_m: 0.9246 - val_loss: 0.3472 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1313 - acc: 0.9246 - f1_m: 0.9246 - precision_m: 0.9246 - recall_m: 0.9246 - val_loss: 0.3521 - val_acc: 0.8784 - val_f1_m: 0.8784 - val_precision_m: 0.8784 - val_recall_m: 0.8784\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1278 - acc: 0.9259 - f1_m: 0.9259 - precision_m: 0.9259 - recall_m: 0.9259 - val_loss: 0.3550 - val_acc: 0.8816 - val_f1_m: 0.8816 - val_precision_m: 0.8816 - val_recall_m: 0.8816\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1294 - acc: 0.9254 - f1_m: 0.9254 - precision_m: 0.9254 - recall_m: 0.9254 - val_loss: 0.3651 - val_acc: 0.8778 - val_f1_m: 0.8778 - val_precision_m: 0.8778 - val_recall_m: 0.8778\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1274 - acc: 0.9225 - f1_m: 0.9225 - precision_m: 0.9225 - recall_m: 0.9225 - val_loss: 0.3746 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1250 - acc: 0.9245 - f1_m: 0.9245 - precision_m: 0.9245 - recall_m: 0.9245 - val_loss: 0.3781 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1238 - acc: 0.9220 - f1_m: 0.9220 - precision_m: 0.9220 - recall_m: 0.9220 - val_loss: 0.3869 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1221 - acc: 0.9243 - f1_m: 0.9243 - precision_m: 0.9243 - recall_m: 0.9243 - val_loss: 0.3927 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1161 - acc: 0.9296 - f1_m: 0.9296 - precision_m: 0.9296 - recall_m: 0.9296 - val_loss: 0.3988 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1148 - acc: 0.9289 - f1_m: 0.9289 - precision_m: 0.9289 - recall_m: 0.9289 - val_loss: 0.4163 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1110 - acc: 0.9273 - f1_m: 0.9273 - precision_m: 0.9273 - recall_m: 0.9273 - val_loss: 0.4207 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1118 - acc: 0.9240 - f1_m: 0.9240 - precision_m: 0.9240 - recall_m: 0.9240 - val_loss: 0.4288 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1091 - acc: 0.9270 - f1_m: 0.9270 - precision_m: 0.9270 - recall_m: 0.9270 - val_loss: 0.4423 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1087 - acc: 0.9258 - f1_m: 0.9258 - precision_m: 0.9258 - recall_m: 0.9258 - val_loss: 0.4456 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1060 - acc: 0.9285 - f1_m: 0.9285 - precision_m: 0.9285 - recall_m: 0.9285 - val_loss: 0.4509 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1066 - acc: 0.9265 - f1_m: 0.9265 - precision_m: 0.9265 - recall_m: 0.9265 - val_loss: 0.4524 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1072 - acc: 0.9241 - f1_m: 0.9241 - precision_m: 0.9241 - recall_m: 0.9241 - val_loss: 0.4694 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1088 - acc: 0.9263 - f1_m: 0.9262 - precision_m: 0.9263 - recall_m: 0.9263 - val_loss: 0.4678 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1015 - acc: 0.9323 - f1_m: 0.9323 - precision_m: 0.9323 - recall_m: 0.9323 - val_loss: 0.4747 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1048 - acc: 0.9270 - f1_m: 0.9270 - precision_m: 0.9270 - recall_m: 0.9270 - val_loss: 0.4892 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1047 - acc: 0.9263 - f1_m: 0.9262 - precision_m: 0.9263 - recall_m: 0.9263 - val_loss: 0.4870 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1062 - acc: 0.9247 - f1_m: 0.9247 - precision_m: 0.9247 - recall_m: 0.9247 - val_loss: 0.5030 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1026 - acc: 0.9279 - f1_m: 0.9279 - precision_m: 0.9279 - recall_m: 0.9279 - val_loss: 0.4944 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1030 - acc: 0.9270 - f1_m: 0.9270 - precision_m: 0.9270 - recall_m: 0.9270 - val_loss: 0.5121 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1005 - acc: 0.9302 - f1_m: 0.9302 - precision_m: 0.9302 - recall_m: 0.9302 - val_loss: 0.5167 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "4001/4001 [==============================] - 0s 120us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/kgarwj0w\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 8s 634us/step - loss: 0.6828 - acc: 0.5818 - f1_m: 0.5799 - precision_m: 0.5818 - recall_m: 0.5783 - val_loss: 0.6675 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.6717 - acc: 0.6066 - f1_m: 0.6066 - precision_m: 0.6066 - recall_m: 0.6066 - val_loss: 0.6602 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.6596 - acc: 0.6084 - f1_m: 0.6084 - precision_m: 0.6084 - recall_m: 0.6084 - val_loss: 0.6482 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.6436 - acc: 0.6148 - f1_m: 0.6148 - precision_m: 0.6148 - recall_m: 0.6148 - val_loss: 0.6310 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.6205 - acc: 0.6243 - f1_m: 0.6243 - precision_m: 0.6243 - recall_m: 0.6243 - val_loss: 0.6086 - val_acc: 0.6222 - val_f1_m: 0.6222 - val_precision_m: 0.6222 - val_recall_m: 0.6222\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.5960 - acc: 0.6494 - f1_m: 0.6494 - precision_m: 0.6494 - recall_m: 0.6494 - val_loss: 0.5795 - val_acc: 0.6687 - val_f1_m: 0.6687 - val_precision_m: 0.6687 - val_recall_m: 0.6687\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5612 - acc: 0.6823 - f1_m: 0.6823 - precision_m: 0.6823 - recall_m: 0.6823 - val_loss: 0.5494 - val_acc: 0.7438 - val_f1_m: 0.7437 - val_precision_m: 0.7438 - val_recall_m: 0.7438\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5298 - acc: 0.6981 - f1_m: 0.6981 - precision_m: 0.6981 - recall_m: 0.6981 - val_loss: 0.5213 - val_acc: 0.7675 - val_f1_m: 0.7675 - val_precision_m: 0.7675 - val_recall_m: 0.7675\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.4891 - acc: 0.7328 - f1_m: 0.7328 - precision_m: 0.7328 - recall_m: 0.7328 - val_loss: 0.4884 - val_acc: 0.7959 - val_f1_m: 0.7959 - val_precision_m: 0.7959 - val_recall_m: 0.7959\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.4524 - acc: 0.7609 - f1_m: 0.7609 - precision_m: 0.7609 - recall_m: 0.7609 - val_loss: 0.4596 - val_acc: 0.8125 - val_f1_m: 0.8125 - val_precision_m: 0.8125 - val_recall_m: 0.8125\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.4130 - acc: 0.7865 - f1_m: 0.7865 - precision_m: 0.7865 - recall_m: 0.7865 - val_loss: 0.4284 - val_acc: 0.8259 - val_f1_m: 0.8259 - val_precision_m: 0.8259 - val_recall_m: 0.8259\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.3689 - acc: 0.8251 - f1_m: 0.8251 - precision_m: 0.8251 - recall_m: 0.8251 - val_loss: 0.4007 - val_acc: 0.8384 - val_f1_m: 0.8384 - val_precision_m: 0.8384 - val_recall_m: 0.8384\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.3308 - acc: 0.8392 - f1_m: 0.8392 - precision_m: 0.8392 - recall_m: 0.8392 - val_loss: 0.3779 - val_acc: 0.8462 - val_f1_m: 0.8462 - val_precision_m: 0.8462 - val_recall_m: 0.8462\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.2948 - acc: 0.8514 - f1_m: 0.8514 - precision_m: 0.8514 - recall_m: 0.8514 - val_loss: 0.3590 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.2652 - acc: 0.8858 - f1_m: 0.8858 - precision_m: 0.8858 - recall_m: 0.8858 - val_loss: 0.3431 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2496 - acc: 0.8932 - f1_m: 0.8932 - precision_m: 0.8932 - recall_m: 0.8932 - val_loss: 0.3309 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2276 - acc: 0.9027 - f1_m: 0.9027 - precision_m: 0.9027 - recall_m: 0.9027 - val_loss: 0.3224 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2095 - acc: 0.9130 - f1_m: 0.9130 - precision_m: 0.9130 - recall_m: 0.9130 - val_loss: 0.3143 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1918 - acc: 0.9179 - f1_m: 0.9179 - precision_m: 0.9179 - recall_m: 0.9179 - val_loss: 0.3131 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1763 - acc: 0.9225 - f1_m: 0.9225 - precision_m: 0.9225 - recall_m: 0.9225 - val_loss: 0.3167 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1687 - acc: 0.9219 - f1_m: 0.9219 - precision_m: 0.9219 - recall_m: 0.9219 - val_loss: 0.3160 - val_acc: 0.8744 - val_f1_m: 0.8744 - val_precision_m: 0.8744 - val_recall_m: 0.8744\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1576 - acc: 0.9302 - f1_m: 0.9302 - precision_m: 0.9302 - recall_m: 0.9302 - val_loss: 0.3186 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1473 - acc: 0.9277 - f1_m: 0.9277 - precision_m: 0.9277 - recall_m: 0.9277 - val_loss: 0.3246 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1452 - acc: 0.9290 - f1_m: 0.9290 - precision_m: 0.9290 - recall_m: 0.9290 - val_loss: 0.3244 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1360 - acc: 0.9324 - f1_m: 0.9324 - precision_m: 0.9324 - recall_m: 0.9324 - val_loss: 0.3322 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1338 - acc: 0.9307 - f1_m: 0.9307 - precision_m: 0.9307 - recall_m: 0.9307 - val_loss: 0.3365 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1269 - acc: 0.9350 - f1_m: 0.9350 - precision_m: 0.9350 - recall_m: 0.9350 - val_loss: 0.3452 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1286 - acc: 0.9321 - f1_m: 0.9321 - precision_m: 0.9321 - recall_m: 0.9321 - val_loss: 0.3496 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1256 - acc: 0.9342 - f1_m: 0.9342 - precision_m: 0.9342 - recall_m: 0.9342 - val_loss: 0.3554 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1193 - acc: 0.9363 - f1_m: 0.9362 - precision_m: 0.9363 - recall_m: 0.9363 - val_loss: 0.3593 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1164 - acc: 0.9373 - f1_m: 0.9373 - precision_m: 0.9373 - recall_m: 0.9373 - val_loss: 0.3719 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 1s 89us/step - loss: 0.1118 - acc: 0.9398 - f1_m: 0.9398 - precision_m: 0.9398 - recall_m: 0.9398 - val_loss: 0.3755 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 33/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.945948). Check your callbacks.\n",
            "  % delta_t_median)\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.477035). Check your callbacks.\n",
            "  % delta_t_median)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1146 - acc: 0.9372 - f1_m: 0.9372 - precision_m: 0.9372 - recall_m: 0.9372 - val_loss: 0.3794 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1099 - acc: 0.9389 - f1_m: 0.9389 - precision_m: 0.9389 - recall_m: 0.9389 - val_loss: 0.3906 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1074 - acc: 0.9409 - f1_m: 0.9409 - precision_m: 0.9409 - recall_m: 0.9409 - val_loss: 0.3914 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1092 - acc: 0.9392 - f1_m: 0.9392 - precision_m: 0.9392 - recall_m: 0.9392 - val_loss: 0.4014 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1083 - acc: 0.9384 - f1_m: 0.9384 - precision_m: 0.9384 - recall_m: 0.9384 - val_loss: 0.4105 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1079 - acc: 0.9398 - f1_m: 0.9398 - precision_m: 0.9398 - recall_m: 0.9398 - val_loss: 0.4167 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1070 - acc: 0.9383 - f1_m: 0.9383 - precision_m: 0.9383 - recall_m: 0.9383 - val_loss: 0.4119 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1109 - acc: 0.9340 - f1_m: 0.9340 - precision_m: 0.9340 - recall_m: 0.9340 - val_loss: 0.4226 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1052 - acc: 0.9387 - f1_m: 0.9387 - precision_m: 0.9387 - recall_m: 0.9387 - val_loss: 0.4253 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1045 - acc: 0.9409 - f1_m: 0.9409 - precision_m: 0.9409 - recall_m: 0.9409 - val_loss: 0.4278 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1045 - acc: 0.9384 - f1_m: 0.9384 - precision_m: 0.9384 - recall_m: 0.9384 - val_loss: 0.4422 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1064 - acc: 0.9363 - f1_m: 0.9362 - precision_m: 0.9363 - recall_m: 0.9363 - val_loss: 0.4436 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1019 - acc: 0.9400 - f1_m: 0.9400 - precision_m: 0.9400 - recall_m: 0.9400 - val_loss: 0.4497 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1012 - acc: 0.9407 - f1_m: 0.9407 - precision_m: 0.9407 - recall_m: 0.9407 - val_loss: 0.4619 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1013 - acc: 0.9405 - f1_m: 0.9405 - precision_m: 0.9405 - recall_m: 0.9405 - val_loss: 0.4574 - val_acc: 0.8769 - val_f1_m: 0.8769 - val_precision_m: 0.8769 - val_recall_m: 0.8769\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0999 - acc: 0.9427 - f1_m: 0.9427 - precision_m: 0.9427 - recall_m: 0.9427 - val_loss: 0.4664 - val_acc: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1016 - acc: 0.9395 - f1_m: 0.9395 - precision_m: 0.9395 - recall_m: 0.9395 - val_loss: 0.4732 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1033 - acc: 0.9395 - f1_m: 0.9395 - precision_m: 0.9395 - recall_m: 0.9395 - val_loss: 0.4740 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "4001/4001 [==============================] - 0s 117us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/anccauf9\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 8s 639us/step - loss: 0.6751 - acc: 0.5955 - f1_m: 0.5955 - precision_m: 0.5955 - recall_m: 0.5955 - val_loss: 0.6637 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.6541 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6446 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6211 - acc: 0.6116 - f1_m: 0.6116 - precision_m: 0.6116 - recall_m: 0.6116 - val_loss: 0.6058 - val_acc: 0.6306 - val_f1_m: 0.6306 - val_precision_m: 0.6306 - val_recall_m: 0.6306\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.5520 - acc: 0.7242 - f1_m: 0.7242 - precision_m: 0.7242 - recall_m: 0.7242 - val_loss: 0.5408 - val_acc: 0.7419 - val_f1_m: 0.7419 - val_precision_m: 0.7419 - val_recall_m: 0.7419\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.4537 - acc: 0.8351 - f1_m: 0.8351 - precision_m: 0.8351 - recall_m: 0.8351 - val_loss: 0.4747 - val_acc: 0.7837 - val_f1_m: 0.7837 - val_precision_m: 0.7837 - val_recall_m: 0.7837\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3547 - acc: 0.8813 - f1_m: 0.8813 - precision_m: 0.8813 - recall_m: 0.8813 - val_loss: 0.4220 - val_acc: 0.8097 - val_f1_m: 0.8097 - val_precision_m: 0.8097 - val_recall_m: 0.8097\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.2657 - acc: 0.9203 - f1_m: 0.9203 - precision_m: 0.9203 - recall_m: 0.9203 - val_loss: 0.3828 - val_acc: 0.8300 - val_f1_m: 0.8300 - val_precision_m: 0.8300 - val_recall_m: 0.8300\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1946 - acc: 0.9466 - f1_m: 0.9466 - precision_m: 0.9466 - recall_m: 0.9466 - val_loss: 0.3554 - val_acc: 0.8400 - val_f1_m: 0.8400 - val_precision_m: 0.8400 - val_recall_m: 0.8400\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1404 - acc: 0.9645 - f1_m: 0.9645 - precision_m: 0.9645 - recall_m: 0.9645 - val_loss: 0.3407 - val_acc: 0.8503 - val_f1_m: 0.8503 - val_precision_m: 0.8503 - val_recall_m: 0.8503\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1006 - acc: 0.9768 - f1_m: 0.9768 - precision_m: 0.9768 - recall_m: 0.9768 - val_loss: 0.3301 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0745 - acc: 0.9839 - f1_m: 0.9839 - precision_m: 0.9839 - recall_m: 0.9839 - val_loss: 0.3292 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0567 - acc: 0.9886 - f1_m: 0.9886 - precision_m: 0.9886 - recall_m: 0.9886 - val_loss: 0.3332 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0437 - acc: 0.9918 - f1_m: 0.9918 - precision_m: 0.9918 - recall_m: 0.9918 - val_loss: 0.3427 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0358 - acc: 0.9925 - f1_m: 0.9925 - precision_m: 0.9925 - recall_m: 0.9925 - val_loss: 0.3537 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0299 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.3654 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0255 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3575 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0227 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3752 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0200 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.3892 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0181 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3847 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0168 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4018 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0151 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.3989 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0141 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4136 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0146 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4210 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0132 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4196 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0128 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4359 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0126 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4312 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0124 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4388 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0118 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4605 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0117 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4404 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0115 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4573 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0116 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4717 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0116 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4595 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0104 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4680 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0113 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4588 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0102 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4755 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0105 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4783 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0108 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4746 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0104 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4848 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0102 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4846 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0101 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4925 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0105 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4917 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0099 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4936 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0098 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5014 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0099 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5052 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0099 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5040 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0100 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5091 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0099 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5104 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0098 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5146 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0093 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5170 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0095 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5124 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "4001/4001 [==============================] - 1s 126us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/du3w7e7f\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 8s 646us/step - loss: 0.6775 - acc: 0.5940 - f1_m: 0.5940 - precision_m: 0.5940 - recall_m: 0.5940 - val_loss: 0.6634 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.6582 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6492 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.6358 - acc: 0.6120 - f1_m: 0.6120 - precision_m: 0.6120 - recall_m: 0.6120 - val_loss: 0.6236 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.5965 - acc: 0.6553 - f1_m: 0.6553 - precision_m: 0.6553 - recall_m: 0.6553 - val_loss: 0.5824 - val_acc: 0.6713 - val_f1_m: 0.6712 - val_precision_m: 0.6713 - val_recall_m: 0.6713\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.5397 - acc: 0.7280 - f1_m: 0.7280 - precision_m: 0.7280 - recall_m: 0.7280 - val_loss: 0.5362 - val_acc: 0.7438 - val_f1_m: 0.7437 - val_precision_m: 0.7438 - val_recall_m: 0.7438\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.4777 - acc: 0.7865 - f1_m: 0.7865 - precision_m: 0.7865 - recall_m: 0.7865 - val_loss: 0.4895 - val_acc: 0.7744 - val_f1_m: 0.7744 - val_precision_m: 0.7744 - val_recall_m: 0.7744\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.4133 - acc: 0.8334 - f1_m: 0.8334 - precision_m: 0.8334 - recall_m: 0.8334 - val_loss: 0.4482 - val_acc: 0.7997 - val_f1_m: 0.7997 - val_precision_m: 0.7997 - val_recall_m: 0.7997\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.3452 - acc: 0.8799 - f1_m: 0.8799 - precision_m: 0.8799 - recall_m: 0.8799 - val_loss: 0.4110 - val_acc: 0.8203 - val_f1_m: 0.8203 - val_precision_m: 0.8203 - val_recall_m: 0.8203\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.2828 - acc: 0.9175 - f1_m: 0.9175 - precision_m: 0.9175 - recall_m: 0.9175 - val_loss: 0.3814 - val_acc: 0.8297 - val_f1_m: 0.8297 - val_precision_m: 0.8297 - val_recall_m: 0.8297\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.2331 - acc: 0.9323 - f1_m: 0.9323 - precision_m: 0.9323 - recall_m: 0.9323 - val_loss: 0.3570 - val_acc: 0.8450 - val_f1_m: 0.8450 - val_precision_m: 0.8450 - val_recall_m: 0.8450\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1873 - acc: 0.9552 - f1_m: 0.9552 - precision_m: 0.9552 - recall_m: 0.9552 - val_loss: 0.3397 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1505 - acc: 0.9638 - f1_m: 0.9638 - precision_m: 0.9638 - recall_m: 0.9638 - val_loss: 0.3320 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1199 - acc: 0.9738 - f1_m: 0.9737 - precision_m: 0.9738 - recall_m: 0.9738 - val_loss: 0.3313 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0936 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 0.3308 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0796 - acc: 0.9827 - f1_m: 0.9827 - precision_m: 0.9827 - recall_m: 0.9827 - val_loss: 0.3397 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0640 - acc: 0.9876 - f1_m: 0.9876 - precision_m: 0.9876 - recall_m: 0.9876 - val_loss: 0.3437 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0540 - acc: 0.9895 - f1_m: 0.9895 - precision_m: 0.9895 - recall_m: 0.9895 - val_loss: 0.3603 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0462 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.3681 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0407 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.3777 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0347 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.3934 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0309 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.4099 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0277 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.4181 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0254 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.4286 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0235 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4381 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0218 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4494 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0208 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4571 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0202 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4656 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0176 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4861 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0181 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4791 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0179 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4934 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0174 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5181 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0178 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5099 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0152 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5194 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0157 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.5212 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0150 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5340 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0142 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5477 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0151 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5693 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0144 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5596 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0132 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5694 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0138 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5686 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0131 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5854 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0121 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.6067 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0129 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5902 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0123 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6153 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0117 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6137 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0121 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.6232 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0124 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.6287 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0116 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.6446 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0111 - acc: 0.9963 - f1_m: 0.9963 - precision_m: 0.9963 - recall_m: 0.9963 - val_loss: 0.6353 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0118 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.6547 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "4001/4001 [==============================] - 0s 125us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/2euge9dd\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 8s 648us/step - loss: 0.6772 - acc: 0.6013 - f1_m: 0.6013 - precision_m: 0.6013 - recall_m: 0.6013 - val_loss: 0.6676 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.6679 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6614 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.6588 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6507 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.6388 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6306 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.6060 - acc: 0.6200 - f1_m: 0.6200 - precision_m: 0.6200 - recall_m: 0.6200 - val_loss: 0.5977 - val_acc: 0.6412 - val_f1_m: 0.6412 - val_precision_m: 0.6412 - val_recall_m: 0.6412\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.5564 - acc: 0.7095 - f1_m: 0.7095 - precision_m: 0.7095 - recall_m: 0.7095 - val_loss: 0.5537 - val_acc: 0.7294 - val_f1_m: 0.7294 - val_precision_m: 0.7294 - val_recall_m: 0.7294\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.4923 - acc: 0.7959 - f1_m: 0.7959 - precision_m: 0.7959 - recall_m: 0.7959 - val_loss: 0.5068 - val_acc: 0.7594 - val_f1_m: 0.7594 - val_precision_m: 0.7594 - val_recall_m: 0.7594\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.4231 - acc: 0.8402 - f1_m: 0.8402 - precision_m: 0.8402 - recall_m: 0.8402 - val_loss: 0.4640 - val_acc: 0.7863 - val_f1_m: 0.7862 - val_precision_m: 0.7863 - val_recall_m: 0.7863\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.3542 - acc: 0.8731 - f1_m: 0.8731 - precision_m: 0.8731 - recall_m: 0.8731 - val_loss: 0.4284 - val_acc: 0.8056 - val_f1_m: 0.8056 - val_precision_m: 0.8056 - val_recall_m: 0.8056\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2939 - acc: 0.9027 - f1_m: 0.9027 - precision_m: 0.9027 - recall_m: 0.9027 - val_loss: 0.3992 - val_acc: 0.8222 - val_f1_m: 0.8222 - val_precision_m: 0.8222 - val_recall_m: 0.8222\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.2389 - acc: 0.9274 - f1_m: 0.9274 - precision_m: 0.9274 - recall_m: 0.9274 - val_loss: 0.3752 - val_acc: 0.8353 - val_f1_m: 0.8353 - val_precision_m: 0.8353 - val_recall_m: 0.8353\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1906 - acc: 0.9468 - f1_m: 0.9468 - precision_m: 0.9468 - recall_m: 0.9468 - val_loss: 0.3598 - val_acc: 0.8466 - val_f1_m: 0.8466 - val_precision_m: 0.8466 - val_recall_m: 0.8466\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1549 - acc: 0.9564 - f1_m: 0.9564 - precision_m: 0.9564 - recall_m: 0.9564 - val_loss: 0.3556 - val_acc: 0.8475 - val_f1_m: 0.8475 - val_precision_m: 0.8475 - val_recall_m: 0.8475\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1258 - acc: 0.9689 - f1_m: 0.9689 - precision_m: 0.9689 - recall_m: 0.9689 - val_loss: 0.3515 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1040 - acc: 0.9758 - f1_m: 0.9758 - precision_m: 0.9758 - recall_m: 0.9758 - val_loss: 0.3499 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0849 - acc: 0.9809 - f1_m: 0.9809 - precision_m: 0.9809 - recall_m: 0.9809 - val_loss: 0.3516 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0748 - acc: 0.9836 - f1_m: 0.9836 - precision_m: 0.9836 - recall_m: 0.9836 - val_loss: 0.3600 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0611 - acc: 0.9879 - f1_m: 0.9879 - precision_m: 0.9879 - recall_m: 0.9879 - val_loss: 0.3655 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0557 - acc: 0.9895 - f1_m: 0.9895 - precision_m: 0.9895 - recall_m: 0.9895 - val_loss: 0.3697 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0469 - acc: 0.9911 - f1_m: 0.9911 - precision_m: 0.9911 - recall_m: 0.9911 - val_loss: 0.3831 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0426 - acc: 0.9914 - f1_m: 0.9914 - precision_m: 0.9914 - recall_m: 0.9914 - val_loss: 0.3861 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0405 - acc: 0.9913 - f1_m: 0.9913 - precision_m: 0.9913 - recall_m: 0.9913 - val_loss: 0.3968 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0359 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.4022 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0314 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.4110 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0307 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.4213 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0285 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.4313 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0272 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.4308 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0251 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.4430 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0240 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4476 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0219 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4624 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0217 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4614 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0205 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4731 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0196 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.4790 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0192 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4860 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0188 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4883 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0180 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4970 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0173 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4977 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0167 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5118 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0158 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5101 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0160 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5216 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0156 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5261 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0151 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.5352 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0149 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5412 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0143 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5396 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0144 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5468 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0139 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5590 - val_acc: 0.8503 - val_f1_m: 0.8503 - val_precision_m: 0.8503 - val_recall_m: 0.8503\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0131 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5674 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0131 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5642 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0133 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5746 - val_acc: 0.8494 - val_f1_m: 0.8494 - val_precision_m: 0.8494 - val_recall_m: 0.8494\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0136 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5752 - val_acc: 0.8534 - val_f1_m: 0.8534 - val_precision_m: 0.8534 - val_recall_m: 0.8534\n",
            "4001/4001 [==============================] - 0s 124us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/l01aj136\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 9s 669us/step - loss: 0.6743 - acc: 0.5956 - f1_m: 0.5956 - precision_m: 0.5956 - recall_m: 0.5956 - val_loss: 0.6617 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.6484 - acc: 0.6070 - f1_m: 0.6070 - precision_m: 0.6070 - recall_m: 0.6070 - val_loss: 0.6367 - val_acc: 0.6162 - val_f1_m: 0.6162 - val_precision_m: 0.6162 - val_recall_m: 0.6162\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.6079 - acc: 0.6399 - f1_m: 0.6399 - precision_m: 0.6399 - recall_m: 0.6399 - val_loss: 0.5968 - val_acc: 0.6450 - val_f1_m: 0.6450 - val_precision_m: 0.6450 - val_recall_m: 0.6450\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.5448 - acc: 0.7352 - f1_m: 0.7352 - precision_m: 0.7352 - recall_m: 0.7352 - val_loss: 0.5441 - val_acc: 0.7541 - val_f1_m: 0.7541 - val_precision_m: 0.7541 - val_recall_m: 0.7541\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.4613 - acc: 0.8345 - f1_m: 0.8345 - precision_m: 0.8345 - recall_m: 0.8345 - val_loss: 0.4815 - val_acc: 0.7872 - val_f1_m: 0.7872 - val_precision_m: 0.7872 - val_recall_m: 0.7872\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.3664 - acc: 0.8823 - f1_m: 0.8823 - precision_m: 0.8823 - recall_m: 0.8823 - val_loss: 0.4307 - val_acc: 0.8066 - val_f1_m: 0.8066 - val_precision_m: 0.8066 - val_recall_m: 0.8066\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 29us/step - loss: 0.2806 - acc: 0.9141 - f1_m: 0.9141 - precision_m: 0.9141 - recall_m: 0.9141 - val_loss: 0.3926 - val_acc: 0.8197 - val_f1_m: 0.8197 - val_precision_m: 0.8197 - val_recall_m: 0.8197\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.2102 - acc: 0.9441 - f1_m: 0.9441 - precision_m: 0.9441 - recall_m: 0.9441 - val_loss: 0.3629 - val_acc: 0.8306 - val_f1_m: 0.8306 - val_precision_m: 0.8306 - val_recall_m: 0.8306\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1541 - acc: 0.9624 - f1_m: 0.9624 - precision_m: 0.9624 - recall_m: 0.9624 - val_loss: 0.3410 - val_acc: 0.8434 - val_f1_m: 0.8434 - val_precision_m: 0.8434 - val_recall_m: 0.8434\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1129 - acc: 0.9741 - f1_m: 0.9741 - precision_m: 0.9741 - recall_m: 0.9741 - val_loss: 0.3304 - val_acc: 0.8525 - val_f1_m: 0.8525 - val_precision_m: 0.8525 - val_recall_m: 0.8525\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0849 - acc: 0.9815 - f1_m: 0.9815 - precision_m: 0.9815 - recall_m: 0.9815 - val_loss: 0.3221 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0642 - acc: 0.9873 - f1_m: 0.9873 - precision_m: 0.9873 - recall_m: 0.9873 - val_loss: 0.3250 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0505 - acc: 0.9908 - f1_m: 0.9908 - precision_m: 0.9908 - recall_m: 0.9908 - val_loss: 0.3234 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0402 - acc: 0.9927 - f1_m: 0.9927 - precision_m: 0.9927 - recall_m: 0.9927 - val_loss: 0.3325 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0334 - acc: 0.9924 - f1_m: 0.9924 - precision_m: 0.9924 - recall_m: 0.9924 - val_loss: 0.3345 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0285 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.3366 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0245 - acc: 0.9943 - f1_m: 0.9943 - precision_m: 0.9943 - recall_m: 0.9943 - val_loss: 0.3520 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0219 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3452 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0199 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3669 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0183 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3570 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0166 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3742 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0159 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3716 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0153 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3788 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0143 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3780 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0137 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3951 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0132 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.3903 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0131 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3983 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0129 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4029 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0123 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.3986 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0117 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4229 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0118 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4108 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0115 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4160 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0110 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4198 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0110 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4215 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0109 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4285 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0104 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4340 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0103 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4362 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0107 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4367 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0108 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4361 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0103 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4387 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0098 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4438 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0097 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4499 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0098 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4485 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0095 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4475 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0098 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4544 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0098 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4606 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0100 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4656 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0099 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4610 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0103 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4589 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0098 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4752 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "4001/4001 [==============================] - 1s 134us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/g53r9m82\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 9s 702us/step - loss: 0.6729 - acc: 0.5966 - f1_m: 0.5966 - precision_m: 0.5966 - recall_m: 0.5966 - val_loss: 0.6588 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 31us/step - loss: 0.6477 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6337 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.6028 - acc: 0.6272 - f1_m: 0.6272 - precision_m: 0.6272 - recall_m: 0.6272 - val_loss: 0.5840 - val_acc: 0.6797 - val_f1_m: 0.6797 - val_precision_m: 0.6797 - val_recall_m: 0.6797\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.5251 - acc: 0.7456 - f1_m: 0.7456 - precision_m: 0.7456 - recall_m: 0.7456 - val_loss: 0.5189 - val_acc: 0.7725 - val_f1_m: 0.7725 - val_precision_m: 0.7725 - val_recall_m: 0.7725\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.4292 - acc: 0.8392 - f1_m: 0.8392 - precision_m: 0.8392 - recall_m: 0.8392 - val_loss: 0.4543 - val_acc: 0.7969 - val_f1_m: 0.7969 - val_precision_m: 0.7969 - val_recall_m: 0.7969\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.3370 - acc: 0.8852 - f1_m: 0.8852 - precision_m: 0.8852 - recall_m: 0.8852 - val_loss: 0.4030 - val_acc: 0.8247 - val_f1_m: 0.8247 - val_precision_m: 0.8247 - val_recall_m: 0.8247\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.2502 - acc: 0.9267 - f1_m: 0.9267 - precision_m: 0.9267 - recall_m: 0.9267 - val_loss: 0.3623 - val_acc: 0.8456 - val_f1_m: 0.8456 - val_precision_m: 0.8456 - val_recall_m: 0.8456\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.1818 - acc: 0.9523 - f1_m: 0.9523 - precision_m: 0.9523 - recall_m: 0.9523 - val_loss: 0.3370 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.1319 - acc: 0.9686 - f1_m: 0.9686 - precision_m: 0.9686 - recall_m: 0.9686 - val_loss: 0.3213 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0952 - acc: 0.9797 - f1_m: 0.9797 - precision_m: 0.9797 - recall_m: 0.9797 - val_loss: 0.3178 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0696 - acc: 0.9860 - f1_m: 0.9860 - precision_m: 0.9860 - recall_m: 0.9860 - val_loss: 0.3204 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0572 - acc: 0.9877 - f1_m: 0.9877 - precision_m: 0.9877 - recall_m: 0.9877 - val_loss: 0.3240 - val_acc: 0.8822 - val_f1_m: 0.8822 - val_precision_m: 0.8822 - val_recall_m: 0.8822\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0459 - acc: 0.9905 - f1_m: 0.9905 - precision_m: 0.9905 - recall_m: 0.9905 - val_loss: 0.3412 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0354 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3461 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0311 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3495 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0270 - acc: 0.9942 - f1_m: 0.9942 - precision_m: 0.9942 - recall_m: 0.9942 - val_loss: 0.3655 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0244 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.3751 - val_acc: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0215 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3857 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0199 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.3943 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0180 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3997 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0175 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4088 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0168 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4130 - val_acc: 0.8769 - val_f1_m: 0.8769 - val_precision_m: 0.8769 - val_recall_m: 0.8769\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0159 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4242 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0155 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4409 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0145 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4384 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0133 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4394 - val_acc: 0.8788 - val_f1_m: 0.8787 - val_precision_m: 0.8788 - val_recall_m: 0.8788\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0131 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4617 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0136 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4577 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0135 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4746 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0121 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4617 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0129 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4820 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0126 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4737 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0120 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4884 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0110 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4929 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0107 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4970 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0111 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5044 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0113 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5188 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0112 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5159 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0104 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5156 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0103 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5392 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0098 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5367 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0103 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5335 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0100 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5473 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0106 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5451 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0108 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5519 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0098 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5614 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0097 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5697 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0093 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5663 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0094 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5611 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0096 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5784 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "4001/4001 [==============================] - 0s 123us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/2x949u8o\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 9s 684us/step - loss: 0.6813 - acc: 0.5802 - f1_m: 0.5802 - precision_m: 0.5802 - recall_m: 0.5802 - val_loss: 0.6653 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 27us/step - loss: 0.6616 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6521 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.6383 - acc: 0.6080 - f1_m: 0.6080 - precision_m: 0.6080 - recall_m: 0.6080 - val_loss: 0.6261 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.5942 - acc: 0.6416 - f1_m: 0.6416 - precision_m: 0.6416 - recall_m: 0.6416 - val_loss: 0.5814 - val_acc: 0.6616 - val_f1_m: 0.6616 - val_precision_m: 0.6616 - val_recall_m: 0.6616\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.5321 - acc: 0.7257 - f1_m: 0.7257 - precision_m: 0.7257 - recall_m: 0.7257 - val_loss: 0.5269 - val_acc: 0.7584 - val_f1_m: 0.7584 - val_precision_m: 0.7584 - val_recall_m: 0.7584\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.4531 - acc: 0.8179 - f1_m: 0.8179 - precision_m: 0.8179 - recall_m: 0.8179 - val_loss: 0.4691 - val_acc: 0.7928 - val_f1_m: 0.7928 - val_precision_m: 0.7928 - val_recall_m: 0.7928\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.3728 - acc: 0.8628 - f1_m: 0.8628 - precision_m: 0.8628 - recall_m: 0.8628 - val_loss: 0.4235 - val_acc: 0.8213 - val_f1_m: 0.8212 - val_precision_m: 0.8213 - val_recall_m: 0.8213\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2995 - acc: 0.9081 - f1_m: 0.9081 - precision_m: 0.9081 - recall_m: 0.9081 - val_loss: 0.3860 - val_acc: 0.8316 - val_f1_m: 0.8316 - val_precision_m: 0.8316 - val_recall_m: 0.8316\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.2367 - acc: 0.9334 - f1_m: 0.9334 - precision_m: 0.9334 - recall_m: 0.9334 - val_loss: 0.3570 - val_acc: 0.8478 - val_f1_m: 0.8478 - val_precision_m: 0.8478 - val_recall_m: 0.8478\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1876 - acc: 0.9529 - f1_m: 0.9529 - precision_m: 0.9529 - recall_m: 0.9529 - val_loss: 0.3382 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1462 - acc: 0.9682 - f1_m: 0.9682 - precision_m: 0.9682 - recall_m: 0.9682 - val_loss: 0.3242 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1143 - acc: 0.9749 - f1_m: 0.9749 - precision_m: 0.9749 - recall_m: 0.9749 - val_loss: 0.3190 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0888 - acc: 0.9815 - f1_m: 0.9815 - precision_m: 0.9815 - recall_m: 0.9815 - val_loss: 0.3290 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0738 - acc: 0.9848 - f1_m: 0.9848 - precision_m: 0.9848 - recall_m: 0.9848 - val_loss: 0.3313 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0605 - acc: 0.9886 - f1_m: 0.9886 - precision_m: 0.9886 - recall_m: 0.9886 - val_loss: 0.3318 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0513 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.3423 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0454 - acc: 0.9915 - f1_m: 0.9915 - precision_m: 0.9915 - recall_m: 0.9915 - val_loss: 0.3492 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0396 - acc: 0.9918 - f1_m: 0.9918 - precision_m: 0.9918 - recall_m: 0.9918 - val_loss: 0.3670 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0352 - acc: 0.9929 - f1_m: 0.9929 - precision_m: 0.9929 - recall_m: 0.9929 - val_loss: 0.3712 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0322 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3887 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0281 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.3891 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0264 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.4033 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0238 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4131 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0223 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4233 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0206 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4307 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0206 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4477 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0194 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4370 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0184 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4551 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0177 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4720 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0162 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4588 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0157 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4899 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0155 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4949 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0146 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4937 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0142 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4973 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0143 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5066 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0138 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5119 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0138 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5079 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0142 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.5258 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0127 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5255 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0130 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5210 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0126 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5478 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0122 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5507 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0118 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5474 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0116 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5596 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0118 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5741 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0108 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5666 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0113 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5874 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0116 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5778 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0115 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5814 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0115 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5948 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "4001/4001 [==============================] - 0s 124us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/tw1mssfb\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 9s 676us/step - loss: 0.6900 - acc: 0.5429 - f1_m: 0.5429 - precision_m: 0.5429 - recall_m: 0.5429 - val_loss: 0.6796 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.6732 - acc: 0.6077 - f1_m: 0.6077 - precision_m: 0.6077 - recall_m: 0.6077 - val_loss: 0.6668 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6611 - acc: 0.6069 - f1_m: 0.6069 - precision_m: 0.6069 - recall_m: 0.6069 - val_loss: 0.6559 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.6479 - acc: 0.6095 - f1_m: 0.6095 - precision_m: 0.6095 - recall_m: 0.6095 - val_loss: 0.6431 - val_acc: 0.6128 - val_f1_m: 0.6128 - val_precision_m: 0.6128 - val_recall_m: 0.6128\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.6284 - acc: 0.6337 - f1_m: 0.6337 - precision_m: 0.6337 - recall_m: 0.6337 - val_loss: 0.6255 - val_acc: 0.6369 - val_f1_m: 0.6369 - val_precision_m: 0.6369 - val_recall_m: 0.6369\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.6030 - acc: 0.6770 - f1_m: 0.6770 - precision_m: 0.6770 - recall_m: 0.6770 - val_loss: 0.6029 - val_acc: 0.6850 - val_f1_m: 0.6850 - val_precision_m: 0.6850 - val_recall_m: 0.6850\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.5709 - acc: 0.7238 - f1_m: 0.7238 - precision_m: 0.7238 - recall_m: 0.7238 - val_loss: 0.5769 - val_acc: 0.7150 - val_f1_m: 0.7150 - val_precision_m: 0.7150 - val_recall_m: 0.7150\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.5325 - acc: 0.7638 - f1_m: 0.7638 - precision_m: 0.7638 - recall_m: 0.7638 - val_loss: 0.5489 - val_acc: 0.7375 - val_f1_m: 0.7375 - val_precision_m: 0.7375 - val_recall_m: 0.7375\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.4928 - acc: 0.7969 - f1_m: 0.7969 - precision_m: 0.7969 - recall_m: 0.7969 - val_loss: 0.5213 - val_acc: 0.7547 - val_f1_m: 0.7547 - val_precision_m: 0.7547 - val_recall_m: 0.7547\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.4522 - acc: 0.8223 - f1_m: 0.8223 - precision_m: 0.8223 - recall_m: 0.8223 - val_loss: 0.4958 - val_acc: 0.7703 - val_f1_m: 0.7703 - val_precision_m: 0.7703 - val_recall_m: 0.7703\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.4140 - acc: 0.8409 - f1_m: 0.8409 - precision_m: 0.8409 - recall_m: 0.8409 - val_loss: 0.4723 - val_acc: 0.7844 - val_f1_m: 0.7844 - val_precision_m: 0.7844 - val_recall_m: 0.7844\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.3730 - acc: 0.8672 - f1_m: 0.8672 - precision_m: 0.8672 - recall_m: 0.8672 - val_loss: 0.4509 - val_acc: 0.7966 - val_f1_m: 0.7966 - val_precision_m: 0.7966 - val_recall_m: 0.7966\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.3367 - acc: 0.8872 - f1_m: 0.8872 - precision_m: 0.8872 - recall_m: 0.8872 - val_loss: 0.4315 - val_acc: 0.8056 - val_f1_m: 0.8056 - val_precision_m: 0.8056 - val_recall_m: 0.8056\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.3027 - acc: 0.8996 - f1_m: 0.8996 - precision_m: 0.8996 - recall_m: 0.8996 - val_loss: 0.4142 - val_acc: 0.8113 - val_f1_m: 0.8112 - val_precision_m: 0.8113 - val_recall_m: 0.8113\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.2698 - acc: 0.9160 - f1_m: 0.9160 - precision_m: 0.9160 - recall_m: 0.9160 - val_loss: 0.4001 - val_acc: 0.8191 - val_f1_m: 0.8191 - val_precision_m: 0.8191 - val_recall_m: 0.8191\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.2421 - acc: 0.9286 - f1_m: 0.9286 - precision_m: 0.9286 - recall_m: 0.9286 - val_loss: 0.3871 - val_acc: 0.8281 - val_f1_m: 0.8281 - val_precision_m: 0.8281 - val_recall_m: 0.8281\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.2155 - acc: 0.9401 - f1_m: 0.9401 - precision_m: 0.9401 - recall_m: 0.9401 - val_loss: 0.3767 - val_acc: 0.8306 - val_f1_m: 0.8306 - val_precision_m: 0.8306 - val_recall_m: 0.8306\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.1917 - acc: 0.9474 - f1_m: 0.9474 - precision_m: 0.9474 - recall_m: 0.9474 - val_loss: 0.3681 - val_acc: 0.8366 - val_f1_m: 0.8366 - val_precision_m: 0.8366 - val_recall_m: 0.8366\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1702 - acc: 0.9568 - f1_m: 0.9568 - precision_m: 0.9568 - recall_m: 0.9568 - val_loss: 0.3617 - val_acc: 0.8397 - val_f1_m: 0.8397 - val_precision_m: 0.8397 - val_recall_m: 0.8397\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.1548 - acc: 0.9591 - f1_m: 0.9591 - precision_m: 0.9591 - recall_m: 0.9591 - val_loss: 0.3553 - val_acc: 0.8441 - val_f1_m: 0.8441 - val_precision_m: 0.8441 - val_recall_m: 0.8441\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1381 - acc: 0.9652 - f1_m: 0.9652 - precision_m: 0.9652 - recall_m: 0.9652 - val_loss: 0.3526 - val_acc: 0.8466 - val_f1_m: 0.8466 - val_precision_m: 0.8466 - val_recall_m: 0.8466\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.1279 - acc: 0.9678 - f1_m: 0.9678 - precision_m: 0.9678 - recall_m: 0.9678 - val_loss: 0.3482 - val_acc: 0.8475 - val_f1_m: 0.8475 - val_precision_m: 0.8475 - val_recall_m: 0.8475\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.1152 - acc: 0.9735 - f1_m: 0.9735 - precision_m: 0.9735 - recall_m: 0.9735 - val_loss: 0.3459 - val_acc: 0.8491 - val_f1_m: 0.8491 - val_precision_m: 0.8491 - val_recall_m: 0.8491\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.1034 - acc: 0.9757 - f1_m: 0.9757 - precision_m: 0.9757 - recall_m: 0.9757 - val_loss: 0.3459 - val_acc: 0.8497 - val_f1_m: 0.8497 - val_precision_m: 0.8497 - val_recall_m: 0.8497\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0975 - acc: 0.9759 - f1_m: 0.9759 - precision_m: 0.9759 - recall_m: 0.9759 - val_loss: 0.3436 - val_acc: 0.8503 - val_f1_m: 0.8503 - val_precision_m: 0.8503 - val_recall_m: 0.8503\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0895 - acc: 0.9802 - f1_m: 0.9802 - precision_m: 0.9802 - recall_m: 0.9802 - val_loss: 0.3464 - val_acc: 0.8497 - val_f1_m: 0.8497 - val_precision_m: 0.8497 - val_recall_m: 0.8497\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0825 - acc: 0.9817 - f1_m: 0.9817 - precision_m: 0.9817 - recall_m: 0.9817 - val_loss: 0.3450 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0773 - acc: 0.9821 - f1_m: 0.9821 - precision_m: 0.9821 - recall_m: 0.9821 - val_loss: 0.3475 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0695 - acc: 0.9845 - f1_m: 0.9845 - precision_m: 0.9845 - recall_m: 0.9845 - val_loss: 0.3485 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 9us/step - loss: 0.0649 - acc: 0.9851 - f1_m: 0.9851 - precision_m: 0.9851 - recall_m: 0.9851 - val_loss: 0.3534 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0601 - acc: 0.9868 - f1_m: 0.9868 - precision_m: 0.9868 - recall_m: 0.9868 - val_loss: 0.3556 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0561 - acc: 0.9879 - f1_m: 0.9879 - precision_m: 0.9879 - recall_m: 0.9879 - val_loss: 0.3594 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0537 - acc: 0.9890 - f1_m: 0.9890 - precision_m: 0.9890 - recall_m: 0.9890 - val_loss: 0.3655 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0481 - acc: 0.9897 - f1_m: 0.9897 - precision_m: 0.9897 - recall_m: 0.9897 - val_loss: 0.3699 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0453 - acc: 0.9906 - f1_m: 0.9906 - precision_m: 0.9906 - recall_m: 0.9906 - val_loss: 0.3727 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0426 - acc: 0.9904 - f1_m: 0.9904 - precision_m: 0.9904 - recall_m: 0.9904 - val_loss: 0.3778 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0406 - acc: 0.9913 - f1_m: 0.9913 - precision_m: 0.9913 - recall_m: 0.9913 - val_loss: 0.3854 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0376 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.3871 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0359 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.3925 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0338 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.3973 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0322 - acc: 0.9927 - f1_m: 0.9927 - precision_m: 0.9927 - recall_m: 0.9927 - val_loss: 0.4004 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0309 - acc: 0.9924 - f1_m: 0.9924 - precision_m: 0.9924 - recall_m: 0.9924 - val_loss: 0.4013 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0293 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.4074 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 12us/step - loss: 0.0287 - acc: 0.9926 - f1_m: 0.9926 - precision_m: 0.9926 - recall_m: 0.9926 - val_loss: 0.4109 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0281 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.4159 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0269 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.4192 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0259 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9932 - recall_m: 0.9932 - val_loss: 0.4191 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 11us/step - loss: 0.0243 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.4291 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0231 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.4340 - val_acc: 0.8553 - val_f1_m: 0.8553 - val_precision_m: 0.8553 - val_recall_m: 0.8553\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 10us/step - loss: 0.0233 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.4338 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "4001/4001 [==============================] - 1s 138us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/89n5k3mw\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 9s 713us/step - loss: 0.6701 - acc: 0.5964 - f1_m: 0.5964 - precision_m: 0.5964 - recall_m: 0.5964 - val_loss: 0.6550 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 26us/step - loss: 0.6359 - acc: 0.6115 - f1_m: 0.6115 - precision_m: 0.6115 - recall_m: 0.6115 - val_loss: 0.6177 - val_acc: 0.6428 - val_f1_m: 0.6428 - val_precision_m: 0.6428 - val_recall_m: 0.6428\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 26us/step - loss: 0.5690 - acc: 0.6996 - f1_m: 0.6996 - precision_m: 0.6996 - recall_m: 0.6996 - val_loss: 0.5532 - val_acc: 0.7622 - val_f1_m: 0.7622 - val_precision_m: 0.7622 - val_recall_m: 0.7622\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.4689 - acc: 0.8170 - f1_m: 0.8170 - precision_m: 0.8170 - recall_m: 0.8170 - val_loss: 0.4777 - val_acc: 0.7847 - val_f1_m: 0.7847 - val_precision_m: 0.7847 - val_recall_m: 0.7847\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.3597 - acc: 0.8729 - f1_m: 0.8729 - precision_m: 0.8729 - recall_m: 0.8729 - val_loss: 0.4187 - val_acc: 0.8072 - val_f1_m: 0.8072 - val_precision_m: 0.8072 - val_recall_m: 0.8072\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 28us/step - loss: 0.2652 - acc: 0.9135 - f1_m: 0.9135 - precision_m: 0.9135 - recall_m: 0.9135 - val_loss: 0.3751 - val_acc: 0.8313 - val_f1_m: 0.8312 - val_precision_m: 0.8313 - val_recall_m: 0.8313\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1852 - acc: 0.9496 - f1_m: 0.9496 - precision_m: 0.9496 - recall_m: 0.9496 - val_loss: 0.3448 - val_acc: 0.8497 - val_f1_m: 0.8497 - val_precision_m: 0.8497 - val_recall_m: 0.8497\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1288 - acc: 0.9681 - f1_m: 0.9681 - precision_m: 0.9681 - recall_m: 0.9681 - val_loss: 0.3323 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.0872 - acc: 0.9813 - f1_m: 0.9813 - precision_m: 0.9813 - recall_m: 0.9813 - val_loss: 0.3257 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0622 - acc: 0.9866 - f1_m: 0.9866 - precision_m: 0.9866 - recall_m: 0.9866 - val_loss: 0.3289 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0464 - acc: 0.9905 - f1_m: 0.9905 - precision_m: 0.9905 - recall_m: 0.9905 - val_loss: 0.3357 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0358 - acc: 0.9928 - f1_m: 0.9928 - precision_m: 0.9928 - recall_m: 0.9928 - val_loss: 0.3482 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0295 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3712 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0244 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3698 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0214 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3683 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0186 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3932 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0169 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3984 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0167 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4210 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0152 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4117 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0130 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4318 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0133 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4133 - val_acc: 0.8791 - val_f1_m: 0.8791 - val_precision_m: 0.8791 - val_recall_m: 0.8791\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0128 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4531 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0117 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4424 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0120 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4542 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0112 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4520 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0117 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4776 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0114 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4470 - val_acc: 0.8781 - val_f1_m: 0.8781 - val_precision_m: 0.8781 - val_recall_m: 0.8781\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0118 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4889 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0112 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4644 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0114 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4862 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0102 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4790 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0100 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4877 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0103 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5058 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0105 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5053 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0097 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4969 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0101 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5009 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0101 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5235 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0098 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5058 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0102 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5243 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0105 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5171 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0097 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5391 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0094 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5290 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0089 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5278 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0090 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5529 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0091 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5440 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0101 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5454 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0093 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5465 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.0093 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5623 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0090 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5487 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0094 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5587 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "4001/4001 [==============================] - 0s 121us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/z2397el6\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 9s 696us/step - loss: 0.6795 - acc: 0.5786 - f1_m: 0.5786 - precision_m: 0.5786 - recall_m: 0.5786 - val_loss: 0.6685 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.6659 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6591 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.6499 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6405 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6160 - acc: 0.6267 - f1_m: 0.6267 - precision_m: 0.6267 - recall_m: 0.6267 - val_loss: 0.6032 - val_acc: 0.6425 - val_f1_m: 0.6425 - val_precision_m: 0.6425 - val_recall_m: 0.6425\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5554 - acc: 0.7252 - f1_m: 0.7252 - precision_m: 0.7252 - recall_m: 0.7252 - val_loss: 0.5468 - val_acc: 0.7419 - val_f1_m: 0.7419 - val_precision_m: 0.7419 - val_recall_m: 0.7419\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.4688 - acc: 0.8155 - f1_m: 0.8155 - precision_m: 0.8155 - recall_m: 0.8155 - val_loss: 0.4856 - val_acc: 0.7850 - val_f1_m: 0.7850 - val_precision_m: 0.7850 - val_recall_m: 0.7850\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3803 - acc: 0.8576 - f1_m: 0.8576 - precision_m: 0.8576 - recall_m: 0.8576 - val_loss: 0.4361 - val_acc: 0.8050 - val_f1_m: 0.8050 - val_precision_m: 0.8050 - val_recall_m: 0.8050\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3009 - acc: 0.8983 - f1_m: 0.8983 - precision_m: 0.8983 - recall_m: 0.8983 - val_loss: 0.3961 - val_acc: 0.8197 - val_f1_m: 0.8197 - val_precision_m: 0.8197 - val_recall_m: 0.8197\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.2297 - acc: 0.9291 - f1_m: 0.9291 - precision_m: 0.9291 - recall_m: 0.9291 - val_loss: 0.3664 - val_acc: 0.8341 - val_f1_m: 0.8341 - val_precision_m: 0.8341 - val_recall_m: 0.8341\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1710 - acc: 0.9532 - f1_m: 0.9532 - precision_m: 0.9532 - recall_m: 0.9532 - val_loss: 0.3469 - val_acc: 0.8491 - val_f1_m: 0.8491 - val_precision_m: 0.8491 - val_recall_m: 0.8491\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1279 - acc: 0.9677 - f1_m: 0.9677 - precision_m: 0.9677 - recall_m: 0.9677 - val_loss: 0.3340 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0988 - acc: 0.9773 - f1_m: 0.9773 - precision_m: 0.9773 - recall_m: 0.9773 - val_loss: 0.3319 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0754 - acc: 0.9831 - f1_m: 0.9831 - precision_m: 0.9831 - recall_m: 0.9831 - val_loss: 0.3416 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0601 - acc: 0.9881 - f1_m: 0.9881 - precision_m: 0.9881 - recall_m: 0.9881 - val_loss: 0.3398 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0481 - acc: 0.9914 - f1_m: 0.9914 - precision_m: 0.9914 - recall_m: 0.9914 - val_loss: 0.3529 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0404 - acc: 0.9915 - f1_m: 0.9915 - precision_m: 0.9915 - recall_m: 0.9915 - val_loss: 0.3621 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0355 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.3700 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0305 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9932 - recall_m: 0.9932 - val_loss: 0.3812 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0273 - acc: 0.9940 - f1_m: 0.9940 - precision_m: 0.9940 - recall_m: 0.9940 - val_loss: 0.3907 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0238 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.4038 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0219 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4054 - val_acc: 0.8728 - val_f1_m: 0.8728 - val_precision_m: 0.8728 - val_recall_m: 0.8728\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0202 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4186 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0193 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4253 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0179 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4309 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0170 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4453 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0158 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4458 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0160 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4534 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0155 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4632 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0156 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4684 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0147 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4707 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0133 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4782 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0143 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4818 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0135 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4875 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0134 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4966 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0122 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5021 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0131 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5043 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0122 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5158 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0119 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5170 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0117 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5231 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0125 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5324 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0128 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5226 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0120 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.5321 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0109 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5499 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0116 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5437 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0116 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5507 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0110 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5524 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0104 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5569 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0105 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5657 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0104 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5659 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0108 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.5658 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "4001/4001 [==============================] - 1s 131us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/uv3pbngv\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 9s 695us/step - loss: 0.6773 - acc: 0.5930 - f1_m: 0.5930 - precision_m: 0.5930 - recall_m: 0.5930 - val_loss: 0.6663 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.6605 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6529 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.6374 - acc: 0.6091 - f1_m: 0.6091 - precision_m: 0.6091 - recall_m: 0.6091 - val_loss: 0.6261 - val_acc: 0.6131 - val_f1_m: 0.6131 - val_precision_m: 0.6131 - val_recall_m: 0.6131\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.5900 - acc: 0.6609 - f1_m: 0.6609 - precision_m: 0.6609 - recall_m: 0.6609 - val_loss: 0.5757 - val_acc: 0.7087 - val_f1_m: 0.7087 - val_precision_m: 0.7087 - val_recall_m: 0.7087\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.5102 - acc: 0.7828 - f1_m: 0.7828 - precision_m: 0.7828 - recall_m: 0.7828 - val_loss: 0.5135 - val_acc: 0.7634 - val_f1_m: 0.7634 - val_precision_m: 0.7634 - val_recall_m: 0.7634\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.4191 - acc: 0.8472 - f1_m: 0.8472 - precision_m: 0.8472 - recall_m: 0.8472 - val_loss: 0.4579 - val_acc: 0.7837 - val_f1_m: 0.7837 - val_precision_m: 0.7837 - val_recall_m: 0.7837\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.3312 - acc: 0.8837 - f1_m: 0.8837 - precision_m: 0.8837 - recall_m: 0.8837 - val_loss: 0.4158 - val_acc: 0.8041 - val_f1_m: 0.8041 - val_precision_m: 0.8041 - val_recall_m: 0.8041\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.2529 - acc: 0.9197 - f1_m: 0.9197 - precision_m: 0.9197 - recall_m: 0.9197 - val_loss: 0.3823 - val_acc: 0.8203 - val_f1_m: 0.8203 - val_precision_m: 0.8203 - val_recall_m: 0.8203\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1876 - acc: 0.9459 - f1_m: 0.9459 - precision_m: 0.9459 - recall_m: 0.9459 - val_loss: 0.3657 - val_acc: 0.8300 - val_f1_m: 0.8300 - val_precision_m: 0.8300 - val_recall_m: 0.8300\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1389 - acc: 0.9630 - f1_m: 0.9630 - precision_m: 0.9630 - recall_m: 0.9630 - val_loss: 0.3525 - val_acc: 0.8406 - val_f1_m: 0.8406 - val_precision_m: 0.8406 - val_recall_m: 0.8406\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1044 - acc: 0.9742 - f1_m: 0.9742 - precision_m: 0.9742 - recall_m: 0.9742 - val_loss: 0.3468 - val_acc: 0.8491 - val_f1_m: 0.8491 - val_precision_m: 0.8491 - val_recall_m: 0.8491\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0778 - acc: 0.9820 - f1_m: 0.9820 - precision_m: 0.9820 - recall_m: 0.9820 - val_loss: 0.3375 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0599 - acc: 0.9873 - f1_m: 0.9873 - precision_m: 0.9873 - recall_m: 0.9873 - val_loss: 0.3377 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0485 - acc: 0.9895 - f1_m: 0.9895 - precision_m: 0.9895 - recall_m: 0.9895 - val_loss: 0.3637 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0391 - acc: 0.9921 - f1_m: 0.9921 - precision_m: 0.9921 - recall_m: 0.9921 - val_loss: 0.3652 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0321 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.3809 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0272 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3776 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0242 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.3864 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0222 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.3975 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0198 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4052 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0180 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4122 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0167 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4157 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0166 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4220 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0154 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4398 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0155 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4351 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0135 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4488 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0133 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4442 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0125 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4596 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0123 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4611 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0119 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4699 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0121 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4674 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0114 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4749 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0116 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4799 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0115 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4893 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0111 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4888 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0109 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4984 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0107 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4937 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0102 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5094 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0101 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5037 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0103 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5073 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0109 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5172 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0103 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.5160 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0099 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5239 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0110 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.5267 - val_acc: 0.8572 - val_f1_m: 0.8572 - val_precision_m: 0.8572 - val_recall_m: 0.8572\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0099 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5311 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0096 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5240 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0098 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5320 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0093 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5389 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0094 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5530 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 13us/step - loss: 0.0099 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5408 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "4001/4001 [==============================] - 1s 138us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/mknl62rt\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 9s 725us/step - loss: 0.6788 - acc: 0.5922 - f1_m: 0.5915 - precision_m: 0.5920 - recall_m: 0.5911 - val_loss: 0.6625 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 30us/step - loss: 0.6604 - acc: 0.6067 - f1_m: 0.6067 - precision_m: 0.6067 - recall_m: 0.6067 - val_loss: 0.6480 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.6397 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6264 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.6115 - acc: 0.6080 - f1_m: 0.6080 - precision_m: 0.6080 - recall_m: 0.6080 - val_loss: 0.5968 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.5740 - acc: 0.6406 - f1_m: 0.6406 - precision_m: 0.6406 - recall_m: 0.6406 - val_loss: 0.5607 - val_acc: 0.6653 - val_f1_m: 0.6653 - val_precision_m: 0.6653 - val_recall_m: 0.6653\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.5293 - acc: 0.6655 - f1_m: 0.6655 - precision_m: 0.6655 - recall_m: 0.6655 - val_loss: 0.5237 - val_acc: 0.7406 - val_f1_m: 0.7406 - val_precision_m: 0.7406 - val_recall_m: 0.7406\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.4832 - acc: 0.6792 - f1_m: 0.6792 - precision_m: 0.6792 - recall_m: 0.6792 - val_loss: 0.4922 - val_acc: 0.7856 - val_f1_m: 0.7856 - val_precision_m: 0.7856 - val_recall_m: 0.7856\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.4384 - acc: 0.7885 - f1_m: 0.7885 - precision_m: 0.7885 - recall_m: 0.7885 - val_loss: 0.4632 - val_acc: 0.8187 - val_f1_m: 0.8187 - val_precision_m: 0.8187 - val_recall_m: 0.8187\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.3961 - acc: 0.8537 - f1_m: 0.8537 - precision_m: 0.8537 - recall_m: 0.8537 - val_loss: 0.4351 - val_acc: 0.8397 - val_f1_m: 0.8397 - val_precision_m: 0.8397 - val_recall_m: 0.8397\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.3573 - acc: 0.8934 - f1_m: 0.8934 - precision_m: 0.8934 - recall_m: 0.8934 - val_loss: 0.4111 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.3225 - acc: 0.9198 - f1_m: 0.9198 - precision_m: 0.9198 - recall_m: 0.9198 - val_loss: 0.3898 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.2890 - acc: 0.9359 - f1_m: 0.9359 - precision_m: 0.9359 - recall_m: 0.9359 - val_loss: 0.3654 - val_acc: 0.8800 - val_f1_m: 0.8800 - val_precision_m: 0.8800 - val_recall_m: 0.8800\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.2609 - acc: 0.9455 - f1_m: 0.9455 - precision_m: 0.9455 - recall_m: 0.9455 - val_loss: 0.3516 - val_acc: 0.8828 - val_f1_m: 0.8828 - val_precision_m: 0.8828 - val_recall_m: 0.8828\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.2365 - acc: 0.9534 - f1_m: 0.9534 - precision_m: 0.9534 - recall_m: 0.9534 - val_loss: 0.3401 - val_acc: 0.8919 - val_f1_m: 0.8919 - val_precision_m: 0.8919 - val_recall_m: 0.8919\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.2165 - acc: 0.9591 - f1_m: 0.9591 - precision_m: 0.9591 - recall_m: 0.9591 - val_loss: 0.3342 - val_acc: 0.8922 - val_f1_m: 0.8922 - val_precision_m: 0.8922 - val_recall_m: 0.8922\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.1983 - acc: 0.9645 - f1_m: 0.9645 - precision_m: 0.9645 - recall_m: 0.9645 - val_loss: 0.3280 - val_acc: 0.8975 - val_f1_m: 0.8975 - val_precision_m: 0.8975 - val_recall_m: 0.8975\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 1s 107us/step - loss: 0.1900 - acc: 0.9666 - f1_m: 0.9666 - precision_m: 0.9666 - recall_m: 0.9666 - val_loss: 0.3281 - val_acc: 0.9009 - val_f1_m: 0.9009 - val_precision_m: 0.9009 - val_recall_m: 0.9009\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1716 - acc: 0.9666 - f1_m: 0.9666 - precision_m: 0.9666 - recall_m: 0.9666 - val_loss: 0.3201 - val_acc: 0.9009 - val_f1_m: 0.9009 - val_precision_m: 0.9009 - val_recall_m: 0.9009\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.1479 - acc: 0.9706 - f1_m: 0.9706 - precision_m: 0.9706 - recall_m: 0.9706 - val_loss: 0.3228 - val_acc: 0.8947 - val_f1_m: 0.8947 - val_precision_m: 0.8947 - val_recall_m: 0.8947\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1387 - acc: 0.9702 - f1_m: 0.9702 - precision_m: 0.9702 - recall_m: 0.9702 - val_loss: 0.3282 - val_acc: 0.8969 - val_f1_m: 0.8969 - val_precision_m: 0.8969 - val_recall_m: 0.8969\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1302 - acc: 0.9734 - f1_m: 0.9734 - precision_m: 0.9734 - recall_m: 0.9734 - val_loss: 0.3323 - val_acc: 0.8947 - val_f1_m: 0.8947 - val_precision_m: 0.8947 - val_recall_m: 0.8947\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1140 - acc: 0.9726 - f1_m: 0.9726 - precision_m: 0.9726 - recall_m: 0.9726 - val_loss: 0.3392 - val_acc: 0.8909 - val_f1_m: 0.8909 - val_precision_m: 0.8909 - val_recall_m: 0.8909\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.1020 - acc: 0.9758 - f1_m: 0.9758 - precision_m: 0.9758 - recall_m: 0.9758 - val_loss: 0.3509 - val_acc: 0.8900 - val_f1_m: 0.8900 - val_precision_m: 0.8900 - val_recall_m: 0.8900\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0929 - acc: 0.9770 - f1_m: 0.9770 - precision_m: 0.9770 - recall_m: 0.9770 - val_loss: 0.3607 - val_acc: 0.8888 - val_f1_m: 0.8887 - val_precision_m: 0.8888 - val_recall_m: 0.8888\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0889 - acc: 0.9756 - f1_m: 0.9756 - precision_m: 0.9756 - recall_m: 0.9756 - val_loss: 0.3702 - val_acc: 0.8916 - val_f1_m: 0.8916 - val_precision_m: 0.8916 - val_recall_m: 0.8916\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0796 - acc: 0.9777 - f1_m: 0.9777 - precision_m: 0.9777 - recall_m: 0.9777 - val_loss: 0.3865 - val_acc: 0.8859 - val_f1_m: 0.8859 - val_precision_m: 0.8859 - val_recall_m: 0.8859\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0752 - acc: 0.9763 - f1_m: 0.9763 - precision_m: 0.9763 - recall_m: 0.9763 - val_loss: 0.3924 - val_acc: 0.8897 - val_f1_m: 0.8897 - val_precision_m: 0.8897 - val_recall_m: 0.8897\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0729 - acc: 0.9781 - f1_m: 0.9781 - precision_m: 0.9781 - recall_m: 0.9781 - val_loss: 0.4042 - val_acc: 0.8881 - val_f1_m: 0.8881 - val_precision_m: 0.8881 - val_recall_m: 0.8881\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0702 - acc: 0.9766 - f1_m: 0.9766 - precision_m: 0.9766 - recall_m: 0.9766 - val_loss: 0.4134 - val_acc: 0.8881 - val_f1_m: 0.8881 - val_precision_m: 0.8881 - val_recall_m: 0.8881\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.0632 - acc: 0.9795 - f1_m: 0.9795 - precision_m: 0.9795 - recall_m: 0.9795 - val_loss: 0.4244 - val_acc: 0.8872 - val_f1_m: 0.8872 - val_precision_m: 0.8872 - val_recall_m: 0.8872\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0655 - acc: 0.9759 - f1_m: 0.9759 - precision_m: 0.9759 - recall_m: 0.9759 - val_loss: 0.4328 - val_acc: 0.8872 - val_f1_m: 0.8872 - val_precision_m: 0.8872 - val_recall_m: 0.8872\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0612 - acc: 0.9790 - f1_m: 0.9790 - precision_m: 0.9790 - recall_m: 0.9790 - val_loss: 0.4448 - val_acc: 0.8872 - val_f1_m: 0.8872 - val_precision_m: 0.8872 - val_recall_m: 0.8872\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0576 - acc: 0.9795 - f1_m: 0.9795 - precision_m: 0.9795 - recall_m: 0.9795 - val_loss: 0.4548 - val_acc: 0.8834 - val_f1_m: 0.8834 - val_precision_m: 0.8834 - val_recall_m: 0.8834\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0583 - acc: 0.9775 - f1_m: 0.9775 - precision_m: 0.9775 - recall_m: 0.9775 - val_loss: 0.4644 - val_acc: 0.8831 - val_f1_m: 0.8831 - val_precision_m: 0.8831 - val_recall_m: 0.8831\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0581 - acc: 0.9789 - f1_m: 0.9789 - precision_m: 0.9789 - recall_m: 0.9789 - val_loss: 0.4676 - val_acc: 0.8853 - val_f1_m: 0.8853 - val_precision_m: 0.8853 - val_recall_m: 0.8853\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0575 - acc: 0.9796 - f1_m: 0.9796 - precision_m: 0.9796 - recall_m: 0.9796 - val_loss: 0.4810 - val_acc: 0.8812 - val_f1_m: 0.8812 - val_precision_m: 0.8812 - val_recall_m: 0.8812\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0556 - acc: 0.9796 - f1_m: 0.9796 - precision_m: 0.9796 - recall_m: 0.9796 - val_loss: 0.4906 - val_acc: 0.8809 - val_f1_m: 0.8809 - val_precision_m: 0.8809 - val_recall_m: 0.8809\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0558 - acc: 0.9797 - f1_m: 0.9797 - precision_m: 0.9797 - recall_m: 0.9797 - val_loss: 0.4905 - val_acc: 0.8831 - val_f1_m: 0.8831 - val_precision_m: 0.8831 - val_recall_m: 0.8831\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0548 - acc: 0.9799 - f1_m: 0.9799 - precision_m: 0.9799 - recall_m: 0.9799 - val_loss: 0.5014 - val_acc: 0.8797 - val_f1_m: 0.8797 - val_precision_m: 0.8797 - val_recall_m: 0.8797\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0565 - acc: 0.9771 - f1_m: 0.9771 - precision_m: 0.9771 - recall_m: 0.9771 - val_loss: 0.5082 - val_acc: 0.8812 - val_f1_m: 0.8812 - val_precision_m: 0.8812 - val_recall_m: 0.8812\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0539 - acc: 0.9805 - f1_m: 0.9805 - precision_m: 0.9805 - recall_m: 0.9805 - val_loss: 0.5222 - val_acc: 0.8800 - val_f1_m: 0.8800 - val_precision_m: 0.8800 - val_recall_m: 0.8800\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0519 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 0.5211 - val_acc: 0.8803 - val_f1_m: 0.8803 - val_precision_m: 0.8803 - val_recall_m: 0.8803\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0526 - acc: 0.9804 - f1_m: 0.9804 - precision_m: 0.9804 - recall_m: 0.9804 - val_loss: 0.5291 - val_acc: 0.8803 - val_f1_m: 0.8803 - val_precision_m: 0.8803 - val_recall_m: 0.8803\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0498 - acc: 0.9805 - f1_m: 0.9805 - precision_m: 0.9805 - recall_m: 0.9805 - val_loss: 0.5412 - val_acc: 0.8791 - val_f1_m: 0.8791 - val_precision_m: 0.8791 - val_recall_m: 0.8791\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0521 - acc: 0.9797 - f1_m: 0.9797 - precision_m: 0.9797 - recall_m: 0.9797 - val_loss: 0.5488 - val_acc: 0.8809 - val_f1_m: 0.8809 - val_precision_m: 0.8809 - val_recall_m: 0.8809\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0525 - acc: 0.9777 - f1_m: 0.9777 - precision_m: 0.9777 - recall_m: 0.9777 - val_loss: 0.5519 - val_acc: 0.8812 - val_f1_m: 0.8812 - val_precision_m: 0.8812 - val_recall_m: 0.8812\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0486 - acc: 0.9790 - f1_m: 0.9790 - precision_m: 0.9790 - recall_m: 0.9790 - val_loss: 0.5687 - val_acc: 0.8781 - val_f1_m: 0.8781 - val_precision_m: 0.8781 - val_recall_m: 0.8781\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0488 - acc: 0.9799 - f1_m: 0.9799 - precision_m: 0.9799 - recall_m: 0.9799 - val_loss: 0.5761 - val_acc: 0.8794 - val_f1_m: 0.8794 - val_precision_m: 0.8794 - val_recall_m: 0.8794\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0475 - acc: 0.9811 - f1_m: 0.9811 - precision_m: 0.9811 - recall_m: 0.9811 - val_loss: 0.5839 - val_acc: 0.8806 - val_f1_m: 0.8806 - val_precision_m: 0.8806 - val_recall_m: 0.8806\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0468 - acc: 0.9798 - f1_m: 0.9798 - precision_m: 0.9798 - recall_m: 0.9798 - val_loss: 0.5868 - val_acc: 0.8816 - val_f1_m: 0.8816 - val_precision_m: 0.8816 - val_recall_m: 0.8816\n",
            "4001/4001 [==============================] - 1s 127us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/4kxva5s6\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 9s 717us/step - loss: 0.6741 - acc: 0.5933 - f1_m: 0.5933 - precision_m: 0.5933 - recall_m: 0.5933 - val_loss: 0.6622 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.6500 - acc: 0.6070 - f1_m: 0.6070 - precision_m: 0.6070 - recall_m: 0.6070 - val_loss: 0.6378 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.6069 - acc: 0.6312 - f1_m: 0.6312 - precision_m: 0.6312 - recall_m: 0.6312 - val_loss: 0.5905 - val_acc: 0.6897 - val_f1_m: 0.6897 - val_precision_m: 0.6897 - val_recall_m: 0.6897\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.5284 - acc: 0.7682 - f1_m: 0.7682 - precision_m: 0.7682 - recall_m: 0.7682 - val_loss: 0.5225 - val_acc: 0.7591 - val_f1_m: 0.7591 - val_precision_m: 0.7591 - val_recall_m: 0.7591\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.4255 - acc: 0.8428 - f1_m: 0.8428 - precision_m: 0.8428 - recall_m: 0.8428 - val_loss: 0.4612 - val_acc: 0.7881 - val_f1_m: 0.7881 - val_precision_m: 0.7881 - val_recall_m: 0.7881\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.3269 - acc: 0.8878 - f1_m: 0.8878 - precision_m: 0.8878 - recall_m: 0.8878 - val_loss: 0.4114 - val_acc: 0.8103 - val_f1_m: 0.8103 - val_precision_m: 0.8103 - val_recall_m: 0.8103\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.2403 - acc: 0.9257 - f1_m: 0.9257 - precision_m: 0.9257 - recall_m: 0.9257 - val_loss: 0.3773 - val_acc: 0.8259 - val_f1_m: 0.8259 - val_precision_m: 0.8259 - val_recall_m: 0.8259\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1720 - acc: 0.9552 - f1_m: 0.9552 - precision_m: 0.9552 - recall_m: 0.9552 - val_loss: 0.3509 - val_acc: 0.8434 - val_f1_m: 0.8434 - val_precision_m: 0.8434 - val_recall_m: 0.8434\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1216 - acc: 0.9710 - f1_m: 0.9710 - precision_m: 0.9710 - recall_m: 0.9710 - val_loss: 0.3374 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0879 - acc: 0.9816 - f1_m: 0.9816 - precision_m: 0.9816 - recall_m: 0.9816 - val_loss: 0.3315 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0644 - acc: 0.9857 - f1_m: 0.9857 - precision_m: 0.9857 - recall_m: 0.9857 - val_loss: 0.3349 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0506 - acc: 0.9898 - f1_m: 0.9898 - precision_m: 0.9898 - recall_m: 0.9898 - val_loss: 0.3459 - val_acc: 0.8603 - val_f1_m: 0.8603 - val_precision_m: 0.8603 - val_recall_m: 0.8603\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0400 - acc: 0.9917 - f1_m: 0.9917 - precision_m: 0.9917 - recall_m: 0.9917 - val_loss: 0.3451 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0326 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.3483 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0272 - acc: 0.9938 - f1_m: 0.9938 - precision_m: 0.9938 - recall_m: 0.9938 - val_loss: 0.3686 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0243 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9939 - recall_m: 0.9939 - val_loss: 0.3686 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0204 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.3815 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0187 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3894 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0168 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.3960 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0162 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.4111 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0157 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4075 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0146 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4148 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0134 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4177 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0129 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4263 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0123 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4311 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0126 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4407 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0121 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4406 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0113 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4540 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0111 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4512 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0114 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4632 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0104 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4592 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0109 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4778 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0112 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4732 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0110 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4742 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0103 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.4792 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0109 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4941 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0105 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4910 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0107 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4871 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0098 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5083 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0104 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4921 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0104 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5084 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0101 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4985 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0098 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5191 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0095 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5093 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0098 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5313 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0097 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5161 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0092 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5195 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0094 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5364 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0095 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.5258 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0100 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5409 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "4001/4001 [==============================] - 0s 123us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/s4c8cfac\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 10s 747us/step - loss: 0.6700 - acc: 0.6059 - f1_m: 0.6059 - precision_m: 0.6059 - recall_m: 0.6059 - val_loss: 0.6563 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 28us/step - loss: 0.6386 - acc: 0.6077 - f1_m: 0.6077 - precision_m: 0.6077 - recall_m: 0.6077 - val_loss: 0.6203 - val_acc: 0.6119 - val_f1_m: 0.6119 - val_precision_m: 0.6119 - val_recall_m: 0.6119\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.5755 - acc: 0.6616 - f1_m: 0.6616 - precision_m: 0.6616 - recall_m: 0.6616 - val_loss: 0.5566 - val_acc: 0.7322 - val_f1_m: 0.7322 - val_precision_m: 0.7322 - val_recall_m: 0.7322\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.4797 - acc: 0.8080 - f1_m: 0.8080 - precision_m: 0.8080 - recall_m: 0.8080 - val_loss: 0.4844 - val_acc: 0.7847 - val_f1_m: 0.7847 - val_precision_m: 0.7847 - val_recall_m: 0.7847\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.3731 - acc: 0.8699 - f1_m: 0.8699 - precision_m: 0.8699 - recall_m: 0.8699 - val_loss: 0.4222 - val_acc: 0.8081 - val_f1_m: 0.8081 - val_precision_m: 0.8081 - val_recall_m: 0.8081\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.2715 - acc: 0.9152 - f1_m: 0.9152 - precision_m: 0.9152 - recall_m: 0.9152 - val_loss: 0.3751 - val_acc: 0.8328 - val_f1_m: 0.8328 - val_precision_m: 0.8328 - val_recall_m: 0.8328\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1912 - acc: 0.9469 - f1_m: 0.9469 - precision_m: 0.9469 - recall_m: 0.9469 - val_loss: 0.3418 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.1312 - acc: 0.9688 - f1_m: 0.9687 - precision_m: 0.9688 - recall_m: 0.9688 - val_loss: 0.3268 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.0908 - acc: 0.9815 - f1_m: 0.9815 - precision_m: 0.9815 - recall_m: 0.9815 - val_loss: 0.3260 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0663 - acc: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865 - val_loss: 0.3325 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0516 - acc: 0.9899 - f1_m: 0.9899 - precision_m: 0.9899 - recall_m: 0.9899 - val_loss: 0.3333 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0409 - acc: 0.9922 - f1_m: 0.9922 - precision_m: 0.9922 - recall_m: 0.9922 - val_loss: 0.3410 - val_acc: 0.8709 - val_f1_m: 0.8709 - val_precision_m: 0.8709 - val_recall_m: 0.8709\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0339 - acc: 0.9927 - f1_m: 0.9927 - precision_m: 0.9927 - recall_m: 0.9927 - val_loss: 0.3524 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0291 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.3719 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0247 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.3655 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0208 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.3832 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0202 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3888 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0182 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4089 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0170 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4032 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0160 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.3968 - val_acc: 0.8762 - val_f1_m: 0.8762 - val_precision_m: 0.8762 - val_recall_m: 0.8762\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0155 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4269 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0148 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4326 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0142 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4356 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0130 - acc: 0.9964 - f1_m: 0.9964 - precision_m: 0.9964 - recall_m: 0.9964 - val_loss: 0.4498 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0133 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4374 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0133 - acc: 0.9950 - f1_m: 0.9950 - precision_m: 0.9950 - recall_m: 0.9950 - val_loss: 0.4546 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0123 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4620 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0120 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4625 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0115 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4722 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0121 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4685 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0113 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4865 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0113 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4944 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0117 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4869 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0110 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4958 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0104 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5006 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0100 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5025 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0114 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.5308 - val_acc: 0.8497 - val_f1_m: 0.8497 - val_precision_m: 0.8497 - val_recall_m: 0.8497\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0113 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5041 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0104 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5148 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0104 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5265 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0101 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5285 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0095 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5365 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0099 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5313 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.0101 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5500 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0108 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5365 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0103 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5427 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0096 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5548 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0095 - acc: 0.9963 - f1_m: 0.9963 - precision_m: 0.9963 - recall_m: 0.9963 - val_loss: 0.5651 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0099 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5517 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0100 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5559 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "4001/4001 [==============================] - 1s 138us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/zvey2fox\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 9s 738us/step - loss: 0.6863 - acc: 0.5704 - f1_m: 0.5702 - precision_m: 0.5703 - recall_m: 0.5701 - val_loss: 0.6742 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.6726 - acc: 0.6090 - f1_m: 0.6090 - precision_m: 0.6090 - recall_m: 0.6090 - val_loss: 0.6629 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.6608 - acc: 0.6165 - f1_m: 0.6165 - precision_m: 0.6165 - recall_m: 0.6165 - val_loss: 0.6522 - val_acc: 0.6125 - val_f1_m: 0.6125 - val_precision_m: 0.6125 - val_recall_m: 0.6125\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.6455 - acc: 0.6378 - f1_m: 0.6378 - precision_m: 0.6378 - recall_m: 0.6378 - val_loss: 0.6363 - val_acc: 0.6519 - val_f1_m: 0.6519 - val_precision_m: 0.6519 - val_recall_m: 0.6519\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.6190 - acc: 0.6845 - f1_m: 0.6845 - precision_m: 0.6845 - recall_m: 0.6845 - val_loss: 0.6071 - val_acc: 0.7056 - val_f1_m: 0.7056 - val_precision_m: 0.7056 - val_recall_m: 0.7056\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.5813 - acc: 0.7196 - f1_m: 0.7196 - precision_m: 0.7196 - recall_m: 0.7196 - val_loss: 0.5720 - val_acc: 0.7459 - val_f1_m: 0.7459 - val_precision_m: 0.7459 - val_recall_m: 0.7459\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.5373 - acc: 0.7644 - f1_m: 0.7644 - precision_m: 0.7644 - recall_m: 0.7644 - val_loss: 0.5332 - val_acc: 0.7844 - val_f1_m: 0.7844 - val_precision_m: 0.7844 - val_recall_m: 0.7844\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.4892 - acc: 0.8026 - f1_m: 0.8026 - precision_m: 0.8026 - recall_m: 0.8026 - val_loss: 0.4953 - val_acc: 0.7934 - val_f1_m: 0.7934 - val_precision_m: 0.7934 - val_recall_m: 0.7934\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.4379 - acc: 0.8318 - f1_m: 0.8318 - precision_m: 0.8318 - recall_m: 0.8318 - val_loss: 0.4601 - val_acc: 0.8137 - val_f1_m: 0.8137 - val_precision_m: 0.8137 - val_recall_m: 0.8137\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.3874 - acc: 0.8659 - f1_m: 0.8659 - precision_m: 0.8659 - recall_m: 0.8659 - val_loss: 0.4274 - val_acc: 0.8191 - val_f1_m: 0.8191 - val_precision_m: 0.8191 - val_recall_m: 0.8191\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.3320 - acc: 0.8945 - f1_m: 0.8945 - precision_m: 0.8945 - recall_m: 0.8945 - val_loss: 0.3949 - val_acc: 0.8378 - val_f1_m: 0.8378 - val_precision_m: 0.8378 - val_recall_m: 0.8378\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2916 - acc: 0.9097 - f1_m: 0.9097 - precision_m: 0.9097 - recall_m: 0.9097 - val_loss: 0.3757 - val_acc: 0.8366 - val_f1_m: 0.8366 - val_precision_m: 0.8366 - val_recall_m: 0.8366\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.2552 - acc: 0.9284 - f1_m: 0.9284 - precision_m: 0.9284 - recall_m: 0.9284 - val_loss: 0.3592 - val_acc: 0.8403 - val_f1_m: 0.8403 - val_precision_m: 0.8403 - val_recall_m: 0.8403\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.2195 - acc: 0.9431 - f1_m: 0.9431 - precision_m: 0.9431 - recall_m: 0.9431 - val_loss: 0.3388 - val_acc: 0.8506 - val_f1_m: 0.8506 - val_precision_m: 0.8506 - val_recall_m: 0.8506\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1936 - acc: 0.9532 - f1_m: 0.9532 - precision_m: 0.9532 - recall_m: 0.9532 - val_loss: 0.3306 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1736 - acc: 0.9588 - f1_m: 0.9588 - precision_m: 0.9588 - recall_m: 0.9588 - val_loss: 0.3255 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.1538 - acc: 0.9612 - f1_m: 0.9612 - precision_m: 0.9612 - recall_m: 0.9612 - val_loss: 0.3269 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1413 - acc: 0.9680 - f1_m: 0.9680 - precision_m: 0.9680 - recall_m: 0.9680 - val_loss: 0.3244 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1336 - acc: 0.9688 - f1_m: 0.9688 - precision_m: 0.9688 - recall_m: 0.9688 - val_loss: 0.3262 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1190 - acc: 0.9720 - f1_m: 0.9720 - precision_m: 0.9720 - recall_m: 0.9720 - val_loss: 0.3357 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.1096 - acc: 0.9740 - f1_m: 0.9740 - precision_m: 0.9740 - recall_m: 0.9740 - val_loss: 0.3339 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.1058 - acc: 0.9750 - f1_m: 0.9750 - precision_m: 0.9750 - recall_m: 0.9750 - val_loss: 0.3444 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.1003 - acc: 0.9762 - f1_m: 0.9762 - precision_m: 0.9762 - recall_m: 0.9762 - val_loss: 0.3511 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0963 - acc: 0.9756 - f1_m: 0.9756 - precision_m: 0.9756 - recall_m: 0.9756 - val_loss: 0.3543 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0905 - acc: 0.9780 - f1_m: 0.9780 - precision_m: 0.9780 - recall_m: 0.9780 - val_loss: 0.3656 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0881 - acc: 0.9773 - f1_m: 0.9773 - precision_m: 0.9773 - recall_m: 0.9773 - val_loss: 0.3641 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0815 - acc: 0.9817 - f1_m: 0.9817 - precision_m: 0.9817 - recall_m: 0.9817 - val_loss: 0.3842 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0792 - acc: 0.9815 - f1_m: 0.9815 - precision_m: 0.9815 - recall_m: 0.9815 - val_loss: 0.3871 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0763 - acc: 0.9830 - f1_m: 0.9830 - precision_m: 0.9830 - recall_m: 0.9830 - val_loss: 0.3939 - val_acc: 0.8581 - val_f1_m: 0.8581 - val_precision_m: 0.8581 - val_recall_m: 0.8581\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0736 - acc: 0.9834 - f1_m: 0.9834 - precision_m: 0.9834 - recall_m: 0.9834 - val_loss: 0.4077 - val_acc: 0.8544 - val_f1_m: 0.8544 - val_precision_m: 0.8544 - val_recall_m: 0.8544\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0727 - acc: 0.9825 - f1_m: 0.9825 - precision_m: 0.9825 - recall_m: 0.9825 - val_loss: 0.4070 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0681 - acc: 0.9841 - f1_m: 0.9841 - precision_m: 0.9841 - recall_m: 0.9841 - val_loss: 0.4196 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0694 - acc: 0.9826 - f1_m: 0.9826 - precision_m: 0.9826 - recall_m: 0.9826 - val_loss: 0.4321 - val_acc: 0.8550 - val_f1_m: 0.8550 - val_precision_m: 0.8550 - val_recall_m: 0.8550\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0657 - acc: 0.9843 - f1_m: 0.9843 - precision_m: 0.9843 - recall_m: 0.9843 - val_loss: 0.4379 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0619 - acc: 0.9857 - f1_m: 0.9857 - precision_m: 0.9857 - recall_m: 0.9857 - val_loss: 0.4423 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0617 - acc: 0.9851 - f1_m: 0.9851 - precision_m: 0.9851 - recall_m: 0.9851 - val_loss: 0.4523 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0586 - acc: 0.9861 - f1_m: 0.9861 - precision_m: 0.9861 - recall_m: 0.9861 - val_loss: 0.4600 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0601 - acc: 0.9837 - f1_m: 0.9837 - precision_m: 0.9837 - recall_m: 0.9837 - val_loss: 0.4782 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0577 - acc: 0.9854 - f1_m: 0.9854 - precision_m: 0.9854 - recall_m: 0.9854 - val_loss: 0.4868 - val_acc: 0.8525 - val_f1_m: 0.8525 - val_precision_m: 0.8525 - val_recall_m: 0.8525\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0496 - acc: 0.9863 - f1_m: 0.9863 - precision_m: 0.9863 - recall_m: 0.9863 - val_loss: 0.4923 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0515 - acc: 0.9847 - f1_m: 0.9847 - precision_m: 0.9847 - recall_m: 0.9847 - val_loss: 0.5031 - val_acc: 0.8538 - val_f1_m: 0.8537 - val_precision_m: 0.8538 - val_recall_m: 0.8538\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0497 - acc: 0.9851 - f1_m: 0.9851 - precision_m: 0.9851 - recall_m: 0.9851 - val_loss: 0.5120 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0465 - acc: 0.9876 - f1_m: 0.9876 - precision_m: 0.9876 - recall_m: 0.9876 - val_loss: 0.5162 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0477 - acc: 0.9859 - f1_m: 0.9859 - precision_m: 0.9859 - recall_m: 0.9859 - val_loss: 0.5292 - val_acc: 0.8566 - val_f1_m: 0.8566 - val_precision_m: 0.8566 - val_recall_m: 0.8566\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0462 - acc: 0.9862 - f1_m: 0.9862 - precision_m: 0.9862 - recall_m: 0.9862 - val_loss: 0.5415 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0458 - acc: 0.9858 - f1_m: 0.9858 - precision_m: 0.9858 - recall_m: 0.9858 - val_loss: 0.5493 - val_acc: 0.8528 - val_f1_m: 0.8528 - val_precision_m: 0.8528 - val_recall_m: 0.8528\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 15us/step - loss: 0.0440 - acc: 0.9879 - f1_m: 0.9879 - precision_m: 0.9879 - recall_m: 0.9879 - val_loss: 0.5524 - val_acc: 0.8547 - val_f1_m: 0.8547 - val_precision_m: 0.8547 - val_recall_m: 0.8547\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0439 - acc: 0.9878 - f1_m: 0.9878 - precision_m: 0.9878 - recall_m: 0.9878 - val_loss: 0.5582 - val_acc: 0.8562 - val_f1_m: 0.8562 - val_precision_m: 0.8562 - val_recall_m: 0.8562\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0428 - acc: 0.9887 - f1_m: 0.9887 - precision_m: 0.9887 - recall_m: 0.9887 - val_loss: 0.5914 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 14us/step - loss: 0.0419 - acc: 0.9888 - f1_m: 0.9888 - precision_m: 0.9888 - recall_m: 0.9888 - val_loss: 0.5915 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "4001/4001 [==============================] - 1s 149us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/mwxh8m5b\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 10s 759us/step - loss: 0.6782 - acc: 0.5843 - f1_m: 0.5843 - precision_m: 0.5845 - recall_m: 0.5840 - val_loss: 0.6637 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.6616 - acc: 0.6086 - f1_m: 0.6086 - precision_m: 0.6086 - recall_m: 0.6086 - val_loss: 0.6500 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.6391 - acc: 0.6180 - f1_m: 0.6180 - precision_m: 0.6180 - recall_m: 0.6180 - val_loss: 0.6259 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.6109 - acc: 0.6387 - f1_m: 0.6387 - precision_m: 0.6387 - recall_m: 0.6387 - val_loss: 0.5960 - val_acc: 0.6516 - val_f1_m: 0.6516 - val_precision_m: 0.6516 - val_recall_m: 0.6516\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.5712 - acc: 0.6523 - f1_m: 0.6523 - precision_m: 0.6523 - recall_m: 0.6523 - val_loss: 0.5604 - val_acc: 0.7144 - val_f1_m: 0.7144 - val_precision_m: 0.7144 - val_recall_m: 0.7144\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.5303 - acc: 0.6685 - f1_m: 0.6685 - precision_m: 0.6685 - recall_m: 0.6685 - val_loss: 0.5270 - val_acc: 0.7350 - val_f1_m: 0.7350 - val_precision_m: 0.7350 - val_recall_m: 0.7350\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.4858 - acc: 0.7130 - f1_m: 0.7130 - precision_m: 0.7130 - recall_m: 0.7130 - val_loss: 0.4910 - val_acc: 0.7772 - val_f1_m: 0.7772 - val_precision_m: 0.7772 - val_recall_m: 0.7772\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.4412 - acc: 0.7516 - f1_m: 0.7516 - precision_m: 0.7516 - recall_m: 0.7516 - val_loss: 0.4602 - val_acc: 0.8013 - val_f1_m: 0.8012 - val_precision_m: 0.8013 - val_recall_m: 0.8013\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.3897 - acc: 0.8429 - f1_m: 0.8429 - precision_m: 0.8429 - recall_m: 0.8429 - val_loss: 0.4246 - val_acc: 0.8263 - val_f1_m: 0.8262 - val_precision_m: 0.8263 - val_recall_m: 0.8263\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.3398 - acc: 0.8838 - f1_m: 0.8838 - precision_m: 0.8838 - recall_m: 0.8838 - val_loss: 0.3961 - val_acc: 0.8394 - val_f1_m: 0.8394 - val_precision_m: 0.8394 - val_recall_m: 0.8394\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.2907 - acc: 0.9098 - f1_m: 0.9098 - precision_m: 0.9098 - recall_m: 0.9098 - val_loss: 0.3720 - val_acc: 0.8531 - val_f1_m: 0.8531 - val_precision_m: 0.8531 - val_recall_m: 0.8531\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.2576 - acc: 0.9309 - f1_m: 0.9309 - precision_m: 0.9309 - recall_m: 0.9309 - val_loss: 0.3536 - val_acc: 0.8588 - val_f1_m: 0.8587 - val_precision_m: 0.8588 - val_recall_m: 0.8588\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.2263 - acc: 0.9439 - f1_m: 0.9439 - precision_m: 0.9439 - recall_m: 0.9439 - val_loss: 0.3383 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.2032 - acc: 0.9528 - f1_m: 0.9528 - precision_m: 0.9528 - recall_m: 0.9528 - val_loss: 0.3278 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.1825 - acc: 0.9617 - f1_m: 0.9617 - precision_m: 0.9617 - recall_m: 0.9617 - val_loss: 0.3238 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.1618 - acc: 0.9665 - f1_m: 0.9665 - precision_m: 0.9665 - recall_m: 0.9665 - val_loss: 0.3212 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1518 - acc: 0.9713 - f1_m: 0.9712 - precision_m: 0.9713 - recall_m: 0.9713 - val_loss: 0.3182 - val_acc: 0.8844 - val_f1_m: 0.8844 - val_precision_m: 0.8844 - val_recall_m: 0.8844\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1411 - acc: 0.9752 - f1_m: 0.9752 - precision_m: 0.9752 - recall_m: 0.9752 - val_loss: 0.3204 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1288 - acc: 0.9754 - f1_m: 0.9754 - precision_m: 0.9754 - recall_m: 0.9754 - val_loss: 0.3254 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.1153 - acc: 0.9774 - f1_m: 0.9774 - precision_m: 0.9774 - recall_m: 0.9774 - val_loss: 0.3293 - val_acc: 0.8856 - val_f1_m: 0.8856 - val_precision_m: 0.8856 - val_recall_m: 0.8856\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.1093 - acc: 0.9805 - f1_m: 0.9805 - precision_m: 0.9805 - recall_m: 0.9805 - val_loss: 0.3333 - val_acc: 0.8912 - val_f1_m: 0.8912 - val_precision_m: 0.8912 - val_recall_m: 0.8912\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1022 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 0.3434 - val_acc: 0.8781 - val_f1_m: 0.8781 - val_precision_m: 0.8781 - val_recall_m: 0.8781\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0987 - acc: 0.9823 - f1_m: 0.9823 - precision_m: 0.9823 - recall_m: 0.9823 - val_loss: 0.3488 - val_acc: 0.8856 - val_f1_m: 0.8856 - val_precision_m: 0.8856 - val_recall_m: 0.8856\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0950 - acc: 0.9804 - f1_m: 0.9804 - precision_m: 0.9804 - recall_m: 0.9804 - val_loss: 0.3599 - val_acc: 0.8803 - val_f1_m: 0.8803 - val_precision_m: 0.8803 - val_recall_m: 0.8803\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0835 - acc: 0.9843 - f1_m: 0.9843 - precision_m: 0.9843 - recall_m: 0.9843 - val_loss: 0.3647 - val_acc: 0.8866 - val_f1_m: 0.8866 - val_precision_m: 0.8866 - val_recall_m: 0.8866\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0837 - acc: 0.9828 - f1_m: 0.9828 - precision_m: 0.9828 - recall_m: 0.9828 - val_loss: 0.3744 - val_acc: 0.8847 - val_f1_m: 0.8847 - val_precision_m: 0.8847 - val_recall_m: 0.8847\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0733 - acc: 0.9841 - f1_m: 0.9841 - precision_m: 0.9841 - recall_m: 0.9841 - val_loss: 0.3857 - val_acc: 0.8847 - val_f1_m: 0.8847 - val_precision_m: 0.8847 - val_recall_m: 0.8847\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0700 - acc: 0.9823 - f1_m: 0.9823 - precision_m: 0.9823 - recall_m: 0.9823 - val_loss: 0.3976 - val_acc: 0.8806 - val_f1_m: 0.8806 - val_precision_m: 0.8806 - val_recall_m: 0.8806\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0661 - acc: 0.9852 - f1_m: 0.9852 - precision_m: 0.9852 - recall_m: 0.9852 - val_loss: 0.4083 - val_acc: 0.8828 - val_f1_m: 0.8828 - val_precision_m: 0.8828 - val_recall_m: 0.8828\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0633 - acc: 0.9854 - f1_m: 0.9854 - precision_m: 0.9854 - recall_m: 0.9854 - val_loss: 0.4160 - val_acc: 0.8806 - val_f1_m: 0.8806 - val_precision_m: 0.8806 - val_recall_m: 0.8806\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0571 - acc: 0.9855 - f1_m: 0.9855 - precision_m: 0.9855 - recall_m: 0.9855 - val_loss: 0.4254 - val_acc: 0.8828 - val_f1_m: 0.8828 - val_precision_m: 0.8828 - val_recall_m: 0.8828\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0536 - acc: 0.9868 - f1_m: 0.9868 - precision_m: 0.9868 - recall_m: 0.9868 - val_loss: 0.4432 - val_acc: 0.8800 - val_f1_m: 0.8800 - val_precision_m: 0.8800 - val_recall_m: 0.8800\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0545 - acc: 0.9853 - f1_m: 0.9853 - precision_m: 0.9853 - recall_m: 0.9853 - val_loss: 0.4452 - val_acc: 0.8841 - val_f1_m: 0.8841 - val_precision_m: 0.8841 - val_recall_m: 0.8841\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0507 - acc: 0.9872 - f1_m: 0.9872 - precision_m: 0.9872 - recall_m: 0.9872 - val_loss: 0.4651 - val_acc: 0.8769 - val_f1_m: 0.8769 - val_precision_m: 0.8769 - val_recall_m: 0.8769\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0507 - acc: 0.9872 - f1_m: 0.9872 - precision_m: 0.9872 - recall_m: 0.9872 - val_loss: 0.4714 - val_acc: 0.8809 - val_f1_m: 0.8809 - val_precision_m: 0.8809 - val_recall_m: 0.8809\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0484 - acc: 0.9877 - f1_m: 0.9877 - precision_m: 0.9877 - recall_m: 0.9877 - val_loss: 0.4747 - val_acc: 0.8819 - val_f1_m: 0.8819 - val_precision_m: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0488 - acc: 0.9863 - f1_m: 0.9863 - precision_m: 0.9863 - recall_m: 0.9863 - val_loss: 0.4977 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0479 - acc: 0.9870 - f1_m: 0.9870 - precision_m: 0.9870 - recall_m: 0.9870 - val_loss: 0.4962 - val_acc: 0.8809 - val_f1_m: 0.8809 - val_precision_m: 0.8809 - val_recall_m: 0.8809\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0455 - acc: 0.9875 - f1_m: 0.9875 - precision_m: 0.9875 - recall_m: 0.9875 - val_loss: 0.5062 - val_acc: 0.8803 - val_f1_m: 0.8803 - val_precision_m: 0.8803 - val_recall_m: 0.8803\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0442 - acc: 0.9873 - f1_m: 0.9873 - precision_m: 0.9873 - recall_m: 0.9873 - val_loss: 0.5123 - val_acc: 0.8791 - val_f1_m: 0.8791 - val_precision_m: 0.8791 - val_recall_m: 0.8791\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0438 - acc: 0.9878 - f1_m: 0.9878 - precision_m: 0.9878 - recall_m: 0.9878 - val_loss: 0.5266 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0432 - acc: 0.9877 - f1_m: 0.9877 - precision_m: 0.9877 - recall_m: 0.9877 - val_loss: 0.5287 - val_acc: 0.8800 - val_f1_m: 0.8800 - val_precision_m: 0.8800 - val_recall_m: 0.8800\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0440 - acc: 0.9861 - f1_m: 0.9861 - precision_m: 0.9861 - recall_m: 0.9861 - val_loss: 0.5419 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0414 - acc: 0.9877 - f1_m: 0.9877 - precision_m: 0.9877 - recall_m: 0.9877 - val_loss: 0.5456 - val_acc: 0.8781 - val_f1_m: 0.8781 - val_precision_m: 0.8781 - val_recall_m: 0.8781\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0412 - acc: 0.9852 - f1_m: 0.9852 - precision_m: 0.9852 - recall_m: 0.9852 - val_loss: 0.5527 - val_acc: 0.8806 - val_f1_m: 0.8806 - val_precision_m: 0.8806 - val_recall_m: 0.8806\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0401 - acc: 0.9880 - f1_m: 0.9880 - precision_m: 0.9880 - recall_m: 0.9880 - val_loss: 0.5619 - val_acc: 0.8822 - val_f1_m: 0.8822 - val_precision_m: 0.8822 - val_recall_m: 0.8822\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0418 - acc: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865 - val_loss: 0.5712 - val_acc: 0.8791 - val_f1_m: 0.8791 - val_precision_m: 0.8791 - val_recall_m: 0.8791\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0395 - acc: 0.9879 - f1_m: 0.9879 - precision_m: 0.9879 - recall_m: 0.9879 - val_loss: 0.5708 - val_acc: 0.8803 - val_f1_m: 0.8803 - val_precision_m: 0.8803 - val_recall_m: 0.8803\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0391 - acc: 0.9880 - f1_m: 0.9880 - precision_m: 0.9880 - recall_m: 0.9880 - val_loss: 0.5827 - val_acc: 0.8788 - val_f1_m: 0.8787 - val_precision_m: 0.8788 - val_recall_m: 0.8788\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0377 - acc: 0.9878 - f1_m: 0.9878 - precision_m: 0.9878 - recall_m: 0.9878 - val_loss: 0.5911 - val_acc: 0.8794 - val_f1_m: 0.8794 - val_precision_m: 0.8794 - val_recall_m: 0.8794\n",
            "4001/4001 [==============================] - 1s 139us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/don0agwj\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 10s 775us/step - loss: 0.6784 - acc: 0.5882 - f1_m: 0.5879 - precision_m: 0.5881 - recall_m: 0.5878 - val_loss: 0.6623 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.6580 - acc: 0.6076 - f1_m: 0.6076 - precision_m: 0.6076 - recall_m: 0.6076 - val_loss: 0.6452 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.6339 - acc: 0.6176 - f1_m: 0.6176 - precision_m: 0.6176 - recall_m: 0.6176 - val_loss: 0.6188 - val_acc: 0.6169 - val_f1_m: 0.6169 - val_precision_m: 0.6169 - val_recall_m: 0.6169\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.5966 - acc: 0.6506 - f1_m: 0.6506 - precision_m: 0.6506 - recall_m: 0.6506 - val_loss: 0.5786 - val_acc: 0.6803 - val_f1_m: 0.6803 - val_precision_m: 0.6803 - val_recall_m: 0.6803\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.5450 - acc: 0.6988 - f1_m: 0.6988 - precision_m: 0.6988 - recall_m: 0.6988 - val_loss: 0.5371 - val_acc: 0.7309 - val_f1_m: 0.7309 - val_precision_m: 0.7309 - val_recall_m: 0.7309\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.4879 - acc: 0.7531 - f1_m: 0.7531 - precision_m: 0.7531 - recall_m: 0.7531 - val_loss: 0.4927 - val_acc: 0.7884 - val_f1_m: 0.7884 - val_precision_m: 0.7884 - val_recall_m: 0.7884\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.4315 - acc: 0.7767 - f1_m: 0.7767 - precision_m: 0.7767 - recall_m: 0.7767 - val_loss: 0.4558 - val_acc: 0.8134 - val_f1_m: 0.8134 - val_precision_m: 0.8134 - val_recall_m: 0.8134\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.3798 - acc: 0.8404 - f1_m: 0.8404 - precision_m: 0.8404 - recall_m: 0.8404 - val_loss: 0.4200 - val_acc: 0.8278 - val_f1_m: 0.8278 - val_precision_m: 0.8278 - val_recall_m: 0.8278\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.3285 - acc: 0.8918 - f1_m: 0.8918 - precision_m: 0.8918 - recall_m: 0.8918 - val_loss: 0.3899 - val_acc: 0.8444 - val_f1_m: 0.8444 - val_precision_m: 0.8444 - val_recall_m: 0.8444\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.2782 - acc: 0.9227 - f1_m: 0.9227 - precision_m: 0.9227 - recall_m: 0.9227 - val_loss: 0.3610 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.2371 - acc: 0.9416 - f1_m: 0.9416 - precision_m: 0.9416 - recall_m: 0.9416 - val_loss: 0.3382 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.2001 - acc: 0.9544 - f1_m: 0.9544 - precision_m: 0.9544 - recall_m: 0.9544 - val_loss: 0.3256 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1699 - acc: 0.9622 - f1_m: 0.9622 - precision_m: 0.9622 - recall_m: 0.9622 - val_loss: 0.3169 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1452 - acc: 0.9716 - f1_m: 0.9716 - precision_m: 0.9716 - recall_m: 0.9716 - val_loss: 0.3110 - val_acc: 0.8797 - val_f1_m: 0.8797 - val_precision_m: 0.8797 - val_recall_m: 0.8797\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.1209 - acc: 0.9748 - f1_m: 0.9748 - precision_m: 0.9748 - recall_m: 0.9748 - val_loss: 0.3146 - val_acc: 0.8816 - val_f1_m: 0.8816 - val_precision_m: 0.8816 - val_recall_m: 0.8816\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.1037 - acc: 0.9812 - f1_m: 0.9812 - precision_m: 0.9812 - recall_m: 0.9812 - val_loss: 0.3235 - val_acc: 0.8816 - val_f1_m: 0.8816 - val_precision_m: 0.8816 - val_recall_m: 0.8816\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0924 - acc: 0.9837 - f1_m: 0.9837 - precision_m: 0.9837 - recall_m: 0.9837 - val_loss: 0.3331 - val_acc: 0.8759 - val_f1_m: 0.8759 - val_precision_m: 0.8759 - val_recall_m: 0.8759\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0821 - acc: 0.9846 - f1_m: 0.9846 - precision_m: 0.9846 - recall_m: 0.9846 - val_loss: 0.3370 - val_acc: 0.8806 - val_f1_m: 0.8806 - val_precision_m: 0.8806 - val_recall_m: 0.8806\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0741 - acc: 0.9858 - f1_m: 0.9858 - precision_m: 0.9858 - recall_m: 0.9858 - val_loss: 0.3461 - val_acc: 0.8812 - val_f1_m: 0.8812 - val_precision_m: 0.8812 - val_recall_m: 0.8812\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0671 - acc: 0.9880 - f1_m: 0.9880 - precision_m: 0.9880 - recall_m: 0.9880 - val_loss: 0.3530 - val_acc: 0.8853 - val_f1_m: 0.8853 - val_precision_m: 0.8853 - val_recall_m: 0.8853\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0599 - acc: 0.9884 - f1_m: 0.9884 - precision_m: 0.9884 - recall_m: 0.9884 - val_loss: 0.3664 - val_acc: 0.8806 - val_f1_m: 0.8806 - val_precision_m: 0.8806 - val_recall_m: 0.8806\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0565 - acc: 0.9895 - f1_m: 0.9895 - precision_m: 0.9895 - recall_m: 0.9895 - val_loss: 0.3758 - val_acc: 0.8838 - val_f1_m: 0.8837 - val_precision_m: 0.8838 - val_recall_m: 0.8838\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.0520 - acc: 0.9902 - f1_m: 0.9902 - precision_m: 0.9902 - recall_m: 0.9902 - val_loss: 0.3919 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0470 - acc: 0.9915 - f1_m: 0.9915 - precision_m: 0.9915 - recall_m: 0.9915 - val_loss: 0.3991 - val_acc: 0.8791 - val_f1_m: 0.8791 - val_precision_m: 0.8791 - val_recall_m: 0.8791\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0492 - acc: 0.9888 - f1_m: 0.9887 - precision_m: 0.9888 - recall_m: 0.9888 - val_loss: 0.4090 - val_acc: 0.8778 - val_f1_m: 0.8778 - val_precision_m: 0.8778 - val_recall_m: 0.8778\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0442 - acc: 0.9912 - f1_m: 0.9912 - precision_m: 0.9912 - recall_m: 0.9912 - val_loss: 0.4176 - val_acc: 0.8781 - val_f1_m: 0.8781 - val_precision_m: 0.8781 - val_recall_m: 0.8781\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0422 - acc: 0.9908 - f1_m: 0.9908 - precision_m: 0.9908 - recall_m: 0.9908 - val_loss: 0.4227 - val_acc: 0.8803 - val_f1_m: 0.8803 - val_precision_m: 0.8803 - val_recall_m: 0.8803\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0423 - acc: 0.9913 - f1_m: 0.9912 - precision_m: 0.9913 - recall_m: 0.9913 - val_loss: 0.4348 - val_acc: 0.8759 - val_f1_m: 0.8759 - val_precision_m: 0.8759 - val_recall_m: 0.8759\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0391 - acc: 0.9912 - f1_m: 0.9912 - precision_m: 0.9912 - recall_m: 0.9912 - val_loss: 0.4464 - val_acc: 0.8784 - val_f1_m: 0.8784 - val_precision_m: 0.8784 - val_recall_m: 0.8784\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0381 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.4579 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0374 - acc: 0.9909 - f1_m: 0.9909 - precision_m: 0.9909 - recall_m: 0.9909 - val_loss: 0.4619 - val_acc: 0.8822 - val_f1_m: 0.8822 - val_precision_m: 0.8822 - val_recall_m: 0.8822\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0362 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.4665 - val_acc: 0.8819 - val_f1_m: 0.8819 - val_precision_m: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0369 - acc: 0.9912 - f1_m: 0.9912 - precision_m: 0.9912 - recall_m: 0.9912 - val_loss: 0.4792 - val_acc: 0.8772 - val_f1_m: 0.8772 - val_precision_m: 0.8772 - val_recall_m: 0.8772\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.0352 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.4838 - val_acc: 0.8781 - val_f1_m: 0.8781 - val_precision_m: 0.8781 - val_recall_m: 0.8781\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0339 - acc: 0.9912 - f1_m: 0.9912 - precision_m: 0.9912 - recall_m: 0.9912 - val_loss: 0.4925 - val_acc: 0.8769 - val_f1_m: 0.8769 - val_precision_m: 0.8769 - val_recall_m: 0.8769\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0339 - acc: 0.9927 - f1_m: 0.9927 - precision_m: 0.9927 - recall_m: 0.9927 - val_loss: 0.5037 - val_acc: 0.8747 - val_f1_m: 0.8747 - val_precision_m: 0.8747 - val_recall_m: 0.8747\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0332 - acc: 0.9924 - f1_m: 0.9924 - precision_m: 0.9924 - recall_m: 0.9924 - val_loss: 0.5134 - val_acc: 0.8756 - val_f1_m: 0.8756 - val_precision_m: 0.8756 - val_recall_m: 0.8756\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0328 - acc: 0.9927 - f1_m: 0.9927 - precision_m: 0.9927 - recall_m: 0.9927 - val_loss: 0.5205 - val_acc: 0.8753 - val_f1_m: 0.8753 - val_precision_m: 0.8753 - val_recall_m: 0.8753\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0315 - acc: 0.9913 - f1_m: 0.9913 - precision_m: 0.9913 - recall_m: 0.9913 - val_loss: 0.5239 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0292 - acc: 0.9931 - f1_m: 0.9931 - precision_m: 0.9931 - recall_m: 0.9931 - val_loss: 0.5225 - val_acc: 0.8828 - val_f1_m: 0.8828 - val_precision_m: 0.8828 - val_recall_m: 0.8828\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0283 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.5426 - val_acc: 0.8759 - val_f1_m: 0.8759 - val_precision_m: 0.8759 - val_recall_m: 0.8759\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0285 - acc: 0.9920 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920 - val_loss: 0.5598 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0251 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.5638 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0263 - acc: 0.9922 - f1_m: 0.9922 - precision_m: 0.9922 - recall_m: 0.9922 - val_loss: 0.5733 - val_acc: 0.8759 - val_f1_m: 0.8759 - val_precision_m: 0.8759 - val_recall_m: 0.8759\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0247 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.5714 - val_acc: 0.8791 - val_f1_m: 0.8791 - val_precision_m: 0.8791 - val_recall_m: 0.8791\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0243 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 0.5906 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0244 - acc: 0.9923 - f1_m: 0.9923 - precision_m: 0.9923 - recall_m: 0.9923 - val_loss: 0.5955 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0240 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.6094 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0241 - acc: 0.9924 - f1_m: 0.9924 - precision_m: 0.9924 - recall_m: 0.9924 - val_loss: 0.6065 - val_acc: 0.8769 - val_f1_m: 0.8769 - val_precision_m: 0.8769 - val_recall_m: 0.8769\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0231 - acc: 0.9941 - f1_m: 0.9941 - precision_m: 0.9941 - recall_m: 0.9941 - val_loss: 0.6244 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "4001/4001 [==============================] - 1s 142us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/1pr3n24m\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 10s 778us/step - loss: 0.6696 - acc: 0.6011 - f1_m: 0.6011 - precision_m: 0.6011 - recall_m: 0.6011 - val_loss: 0.6559 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 26us/step - loss: 0.6323 - acc: 0.6080 - f1_m: 0.6080 - precision_m: 0.6080 - recall_m: 0.6080 - val_loss: 0.6139 - val_acc: 0.6412 - val_f1_m: 0.6412 - val_precision_m: 0.6412 - val_recall_m: 0.6412\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.5562 - acc: 0.7175 - f1_m: 0.7175 - precision_m: 0.7175 - recall_m: 0.7175 - val_loss: 0.5385 - val_acc: 0.7538 - val_f1_m: 0.7537 - val_precision_m: 0.7538 - val_recall_m: 0.7538\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.4410 - acc: 0.8416 - f1_m: 0.8416 - precision_m: 0.8416 - recall_m: 0.8416 - val_loss: 0.4601 - val_acc: 0.7881 - val_f1_m: 0.7881 - val_precision_m: 0.7881 - val_recall_m: 0.7881\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 26us/step - loss: 0.3197 - acc: 0.8957 - f1_m: 0.8957 - precision_m: 0.8957 - recall_m: 0.8957 - val_loss: 0.4026 - val_acc: 0.8150 - val_f1_m: 0.8150 - val_precision_m: 0.8150 - val_recall_m: 0.8150\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.2179 - acc: 0.9381 - f1_m: 0.9381 - precision_m: 0.9381 - recall_m: 0.9381 - val_loss: 0.3591 - val_acc: 0.8334 - val_f1_m: 0.8334 - val_precision_m: 0.8334 - val_recall_m: 0.8334\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.1410 - acc: 0.9641 - f1_m: 0.9641 - precision_m: 0.9641 - recall_m: 0.9641 - val_loss: 0.3322 - val_acc: 0.8519 - val_f1_m: 0.8519 - val_precision_m: 0.8519 - val_recall_m: 0.8519\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.0913 - acc: 0.9795 - f1_m: 0.9795 - precision_m: 0.9795 - recall_m: 0.9795 - val_loss: 0.3219 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0606 - acc: 0.9873 - f1_m: 0.9873 - precision_m: 0.9873 - recall_m: 0.9873 - val_loss: 0.3252 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0428 - acc: 0.9912 - f1_m: 0.9912 - precision_m: 0.9912 - recall_m: 0.9912 - val_loss: 0.3290 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0317 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9932 - recall_m: 0.9932 - val_loss: 0.3410 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.0258 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3495 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0214 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3471 - val_acc: 0.8744 - val_f1_m: 0.8744 - val_precision_m: 0.8744 - val_recall_m: 0.8744\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.0191 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.3632 - val_acc: 0.8681 - val_f1_m: 0.8681 - val_precision_m: 0.8681 - val_recall_m: 0.8681\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0166 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.3695 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0157 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3795 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0149 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.3962 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0138 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.3863 - val_acc: 0.8741 - val_f1_m: 0.8741 - val_precision_m: 0.8741 - val_recall_m: 0.8741\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0126 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.3902 - val_acc: 0.8744 - val_f1_m: 0.8744 - val_precision_m: 0.8744 - val_recall_m: 0.8744\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0119 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4013 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.0120 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4099 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0118 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4234 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0116 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4130 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0112 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4300 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0106 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4195 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0108 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4367 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0107 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4402 - val_acc: 0.8675 - val_f1_m: 0.8675 - val_precision_m: 0.8675 - val_recall_m: 0.8675\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0107 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4441 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0105 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4390 - val_acc: 0.8706 - val_f1_m: 0.8706 - val_precision_m: 0.8706 - val_recall_m: 0.8706\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0110 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4479 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0105 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4613 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0104 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.4385 - val_acc: 0.8762 - val_f1_m: 0.8762 - val_precision_m: 0.8762 - val_recall_m: 0.8762\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0111 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4859 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0103 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4415 - val_acc: 0.8775 - val_f1_m: 0.8775 - val_precision_m: 0.8775 - val_recall_m: 0.8775\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0104 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4752 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0098 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4586 - val_acc: 0.8734 - val_f1_m: 0.8734 - val_precision_m: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0098 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4802 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.0102 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4650 - val_acc: 0.8712 - val_f1_m: 0.8712 - val_precision_m: 0.8712 - val_recall_m: 0.8712\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0102 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4753 - val_acc: 0.8666 - val_f1_m: 0.8666 - val_precision_m: 0.8666 - val_recall_m: 0.8666\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0092 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4815 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.0095 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4767 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0093 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4838 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0097 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4856 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0101 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.4912 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0100 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.4761 - val_acc: 0.8731 - val_f1_m: 0.8731 - val_precision_m: 0.8731 - val_recall_m: 0.8731\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0093 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5061 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.0093 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4875 - val_acc: 0.8684 - val_f1_m: 0.8684 - val_precision_m: 0.8684 - val_recall_m: 0.8684\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0095 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5043 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0088 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962 - val_loss: 0.4931 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0103 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4924 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "4001/4001 [==============================] - 1s 138us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/611l5tjr\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 10s 784us/step - loss: 0.6739 - acc: 0.5989 - f1_m: 0.5989 - precision_m: 0.5989 - recall_m: 0.5989 - val_loss: 0.6610 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.6546 - acc: 0.6068 - f1_m: 0.6068 - precision_m: 0.6068 - recall_m: 0.6068 - val_loss: 0.6426 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.6236 - acc: 0.6104 - f1_m: 0.6104 - precision_m: 0.6104 - recall_m: 0.6104 - val_loss: 0.6092 - val_acc: 0.6131 - val_f1_m: 0.6131 - val_precision_m: 0.6131 - val_recall_m: 0.6131\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.5726 - acc: 0.6660 - f1_m: 0.6660 - precision_m: 0.6660 - recall_m: 0.6660 - val_loss: 0.5613 - val_acc: 0.7266 - val_f1_m: 0.7266 - val_precision_m: 0.7266 - val_recall_m: 0.7266\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.5029 - acc: 0.7758 - f1_m: 0.7758 - precision_m: 0.7758 - recall_m: 0.7758 - val_loss: 0.5045 - val_acc: 0.7775 - val_f1_m: 0.7775 - val_precision_m: 0.7775 - val_recall_m: 0.7775\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.4266 - acc: 0.8357 - f1_m: 0.8357 - precision_m: 0.8357 - recall_m: 0.8357 - val_loss: 0.4560 - val_acc: 0.7925 - val_f1_m: 0.7925 - val_precision_m: 0.7925 - val_recall_m: 0.7925\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.3501 - acc: 0.8820 - f1_m: 0.8820 - precision_m: 0.8820 - recall_m: 0.8820 - val_loss: 0.4151 - val_acc: 0.8141 - val_f1_m: 0.8141 - val_precision_m: 0.8141 - val_recall_m: 0.8141\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.2851 - acc: 0.9098 - f1_m: 0.9098 - precision_m: 0.9098 - recall_m: 0.9098 - val_loss: 0.3803 - val_acc: 0.8309 - val_f1_m: 0.8309 - val_precision_m: 0.8309 - val_recall_m: 0.8309\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.2248 - acc: 0.9392 - f1_m: 0.9392 - precision_m: 0.9392 - recall_m: 0.9392 - val_loss: 0.3543 - val_acc: 0.8484 - val_f1_m: 0.8484 - val_precision_m: 0.8484 - val_recall_m: 0.8484\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 25us/step - loss: 0.1786 - acc: 0.9553 - f1_m: 0.9553 - precision_m: 0.9553 - recall_m: 0.9553 - val_loss: 0.3375 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.1424 - acc: 0.9673 - f1_m: 0.9673 - precision_m: 0.9673 - recall_m: 0.9673 - val_loss: 0.3275 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.1156 - acc: 0.9758 - f1_m: 0.9758 - precision_m: 0.9758 - recall_m: 0.9758 - val_loss: 0.3212 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0922 - acc: 0.9814 - f1_m: 0.9814 - precision_m: 0.9814 - recall_m: 0.9814 - val_loss: 0.3213 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0783 - acc: 0.9848 - f1_m: 0.9848 - precision_m: 0.9848 - recall_m: 0.9848 - val_loss: 0.3310 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0634 - acc: 0.9880 - f1_m: 0.9880 - precision_m: 0.9880 - recall_m: 0.9880 - val_loss: 0.3285 - val_acc: 0.8738 - val_f1_m: 0.8737 - val_precision_m: 0.8738 - val_recall_m: 0.8738\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0546 - acc: 0.9893 - f1_m: 0.9893 - precision_m: 0.9893 - recall_m: 0.9893 - val_loss: 0.3357 - val_acc: 0.8766 - val_f1_m: 0.8766 - val_precision_m: 0.8766 - val_recall_m: 0.8766\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0467 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.3513 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0421 - acc: 0.9916 - f1_m: 0.9916 - precision_m: 0.9916 - recall_m: 0.9916 - val_loss: 0.3568 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0367 - acc: 0.9937 - f1_m: 0.9937 - precision_m: 0.9937 - recall_m: 0.9937 - val_loss: 0.3711 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0336 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3776 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0298 - acc: 0.9934 - f1_m: 0.9934 - precision_m: 0.9934 - recall_m: 0.9934 - val_loss: 0.3833 - val_acc: 0.8716 - val_f1_m: 0.8716 - val_precision_m: 0.8716 - val_recall_m: 0.8716\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0262 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4032 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0244 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4011 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0242 - acc: 0.9946 - f1_m: 0.9946 - precision_m: 0.9946 - recall_m: 0.9946 - val_loss: 0.4152 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0225 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4291 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0209 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9944 - recall_m: 0.9944 - val_loss: 0.4289 - val_acc: 0.8703 - val_f1_m: 0.8703 - val_precision_m: 0.8703 - val_recall_m: 0.8703\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0199 - acc: 0.9949 - f1_m: 0.9949 - precision_m: 0.9949 - recall_m: 0.9949 - val_loss: 0.4511 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0187 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4413 - val_acc: 0.8691 - val_f1_m: 0.8691 - val_precision_m: 0.8691 - val_recall_m: 0.8691\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0176 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4561 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0169 - acc: 0.9945 - f1_m: 0.9945 - precision_m: 0.9945 - recall_m: 0.9945 - val_loss: 0.4612 - val_acc: 0.8678 - val_f1_m: 0.8678 - val_precision_m: 0.8678 - val_recall_m: 0.8678\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0160 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4774 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0165 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4682 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0153 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4866 - val_acc: 0.8622 - val_f1_m: 0.8622 - val_precision_m: 0.8622 - val_recall_m: 0.8622\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0152 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4912 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0151 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4953 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0153 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5026 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0140 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5072 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0136 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5153 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0131 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5131 - val_acc: 0.8669 - val_f1_m: 0.8669 - val_precision_m: 0.8669 - val_recall_m: 0.8669\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0133 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5295 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0140 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5400 - val_acc: 0.8584 - val_f1_m: 0.8584 - val_precision_m: 0.8584 - val_recall_m: 0.8584\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0129 - acc: 0.9963 - f1_m: 0.9963 - precision_m: 0.9963 - recall_m: 0.9963 - val_loss: 0.5410 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0121 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5495 - val_acc: 0.8591 - val_f1_m: 0.8591 - val_precision_m: 0.8591 - val_recall_m: 0.8591\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0128 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5506 - val_acc: 0.8597 - val_f1_m: 0.8597 - val_precision_m: 0.8597 - val_recall_m: 0.8597\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0121 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5515 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0125 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5687 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 16us/step - loss: 0.0116 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.5776 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0125 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5765 - val_acc: 0.8594 - val_f1_m: 0.8594 - val_precision_m: 0.8594 - val_recall_m: 0.8594\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 17us/step - loss: 0.0118 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5829 - val_acc: 0.8575 - val_f1_m: 0.8575 - val_precision_m: 0.8575 - val_recall_m: 0.8575\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0116 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5877 - val_acc: 0.8578 - val_f1_m: 0.8578 - val_precision_m: 0.8578 - val_recall_m: 0.8578\n",
            "4001/4001 [==============================] - 1s 130us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jeremy/troll-detection+/runs/b9i9dyu6\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 12800 samples, validate on 3200 samples\n",
            "Epoch 1/50\n",
            "12800/12800 [==============================] - 10s 798us/step - loss: 0.6760 - acc: 0.5929 - f1_m: 0.5929 - precision_m: 0.5929 - recall_m: 0.5929 - val_loss: 0.6612 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 2/50\n",
            "12800/12800 [==============================] - 0s 26us/step - loss: 0.6517 - acc: 0.6070 - f1_m: 0.6070 - precision_m: 0.6070 - recall_m: 0.6070 - val_loss: 0.6393 - val_acc: 0.6116 - val_f1_m: 0.6116 - val_precision_m: 0.6116 - val_recall_m: 0.6116\n",
            "Epoch 3/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.6109 - acc: 0.6310 - f1_m: 0.6310 - precision_m: 0.6310 - recall_m: 0.6310 - val_loss: 0.5927 - val_acc: 0.6797 - val_f1_m: 0.6797 - val_precision_m: 0.6797 - val_recall_m: 0.6797\n",
            "Epoch 4/50\n",
            "12800/12800 [==============================] - 0s 26us/step - loss: 0.5356 - acc: 0.7445 - f1_m: 0.7445 - precision_m: 0.7445 - recall_m: 0.7445 - val_loss: 0.5275 - val_acc: 0.7569 - val_f1_m: 0.7569 - val_precision_m: 0.7569 - val_recall_m: 0.7569\n",
            "Epoch 5/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.4417 - acc: 0.8296 - f1_m: 0.8296 - precision_m: 0.8296 - recall_m: 0.8296 - val_loss: 0.4644 - val_acc: 0.7909 - val_f1_m: 0.7909 - val_precision_m: 0.7909 - val_recall_m: 0.7909\n",
            "Epoch 6/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.3456 - acc: 0.8803 - f1_m: 0.8803 - precision_m: 0.8803 - recall_m: 0.8803 - val_loss: 0.4127 - val_acc: 0.8141 - val_f1_m: 0.8141 - val_precision_m: 0.8141 - val_recall_m: 0.8141\n",
            "Epoch 7/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.2538 - acc: 0.9236 - f1_m: 0.9236 - precision_m: 0.9236 - recall_m: 0.9236 - val_loss: 0.3709 - val_acc: 0.8334 - val_f1_m: 0.8334 - val_precision_m: 0.8334 - val_recall_m: 0.8334\n",
            "Epoch 8/50\n",
            "12800/12800 [==============================] - 0s 23us/step - loss: 0.1836 - acc: 0.9520 - f1_m: 0.9520 - precision_m: 0.9520 - recall_m: 0.9520 - val_loss: 0.3441 - val_acc: 0.8484 - val_f1_m: 0.8484 - val_precision_m: 0.8484 - val_recall_m: 0.8484\n",
            "Epoch 9/50\n",
            "12800/12800 [==============================] - 0s 24us/step - loss: 0.1313 - acc: 0.9685 - f1_m: 0.9685 - precision_m: 0.9685 - recall_m: 0.9685 - val_loss: 0.3336 - val_acc: 0.8541 - val_f1_m: 0.8541 - val_precision_m: 0.8541 - val_recall_m: 0.8541\n",
            "Epoch 10/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0946 - acc: 0.9788 - f1_m: 0.9787 - precision_m: 0.9788 - recall_m: 0.9788 - val_loss: 0.3248 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 11/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0716 - acc: 0.9835 - f1_m: 0.9835 - precision_m: 0.9835 - recall_m: 0.9835 - val_loss: 0.3339 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 12/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0545 - acc: 0.9882 - f1_m: 0.9882 - precision_m: 0.9882 - recall_m: 0.9882 - val_loss: 0.3342 - val_acc: 0.8700 - val_f1_m: 0.8700 - val_precision_m: 0.8700 - val_recall_m: 0.8700\n",
            "Epoch 13/50\n",
            "12800/12800 [==============================] - 0s 18us/step - loss: 0.0440 - acc: 0.9913 - f1_m: 0.9913 - precision_m: 0.9913 - recall_m: 0.9913 - val_loss: 0.3369 - val_acc: 0.8744 - val_f1_m: 0.8744 - val_precision_m: 0.8744 - val_recall_m: 0.8744\n",
            "Epoch 14/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0369 - acc: 0.9925 - f1_m: 0.9925 - precision_m: 0.9925 - recall_m: 0.9925 - val_loss: 0.3580 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 15/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0320 - acc: 0.9933 - f1_m: 0.9933 - precision_m: 0.9933 - recall_m: 0.9933 - val_loss: 0.3543 - val_acc: 0.8725 - val_f1_m: 0.8725 - val_precision_m: 0.8725 - val_recall_m: 0.8725\n",
            "Epoch 16/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0288 - acc: 0.9935 - f1_m: 0.9935 - precision_m: 0.9935 - recall_m: 0.9935 - val_loss: 0.3641 - val_acc: 0.8672 - val_f1_m: 0.8672 - val_precision_m: 0.8672 - val_recall_m: 0.8672\n",
            "Epoch 17/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0250 - acc: 0.9938 - f1_m: 0.9938 - precision_m: 0.9938 - recall_m: 0.9938 - val_loss: 0.3735 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 18/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0218 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.3855 - val_acc: 0.8662 - val_f1_m: 0.8662 - val_precision_m: 0.8662 - val_recall_m: 0.8662\n",
            "Epoch 19/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0210 - acc: 0.9947 - f1_m: 0.9947 - precision_m: 0.9947 - recall_m: 0.9947 - val_loss: 0.3964 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 20/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0184 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.3986 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 21/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0177 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4172 - val_acc: 0.8647 - val_f1_m: 0.8647 - val_precision_m: 0.8647 - val_recall_m: 0.8647\n",
            "Epoch 22/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0178 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4134 - val_acc: 0.8722 - val_f1_m: 0.8722 - val_precision_m: 0.8722 - val_recall_m: 0.8722\n",
            "Epoch 23/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0160 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9951 - recall_m: 0.9951 - val_loss: 0.4300 - val_acc: 0.8656 - val_f1_m: 0.8656 - val_precision_m: 0.8656 - val_recall_m: 0.8656\n",
            "Epoch 24/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0153 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4263 - val_acc: 0.8719 - val_f1_m: 0.8719 - val_precision_m: 0.8719 - val_recall_m: 0.8719\n",
            "Epoch 25/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0146 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4492 - val_acc: 0.8619 - val_f1_m: 0.8619 - val_precision_m: 0.8619 - val_recall_m: 0.8619\n",
            "Epoch 26/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0144 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.4486 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 27/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0135 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.4465 - val_acc: 0.8688 - val_f1_m: 0.8687 - val_precision_m: 0.8688 - val_recall_m: 0.8688\n",
            "Epoch 28/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0134 - acc: 0.9948 - f1_m: 0.9948 - precision_m: 0.9948 - recall_m: 0.9948 - val_loss: 0.4634 - val_acc: 0.8638 - val_f1_m: 0.8637 - val_precision_m: 0.8638 - val_recall_m: 0.8638\n",
            "Epoch 29/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0119 - acc: 0.9959 - f1_m: 0.9959 - precision_m: 0.9959 - recall_m: 0.9959 - val_loss: 0.4583 - val_acc: 0.8694 - val_f1_m: 0.8694 - val_precision_m: 0.8694 - val_recall_m: 0.8694\n",
            "Epoch 30/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0121 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4706 - val_acc: 0.8644 - val_f1_m: 0.8644 - val_precision_m: 0.8644 - val_recall_m: 0.8644\n",
            "Epoch 31/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0120 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.4706 - val_acc: 0.8650 - val_f1_m: 0.8650 - val_precision_m: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 32/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0119 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4899 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 33/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0113 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.4855 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 34/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0118 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.4972 - val_acc: 0.8628 - val_f1_m: 0.8628 - val_precision_m: 0.8628 - val_recall_m: 0.8628\n",
            "Epoch 35/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0119 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.4856 - val_acc: 0.8697 - val_f1_m: 0.8697 - val_precision_m: 0.8697 - val_recall_m: 0.8697\n",
            "Epoch 36/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0113 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5220 - val_acc: 0.8569 - val_f1_m: 0.8569 - val_precision_m: 0.8569 - val_recall_m: 0.8569\n",
            "Epoch 37/50\n",
            "12800/12800 [==============================] - 0s 22us/step - loss: 0.0112 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5023 - val_acc: 0.8659 - val_f1_m: 0.8659 - val_precision_m: 0.8659 - val_recall_m: 0.8659\n",
            "Epoch 38/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0115 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5186 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 39/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0112 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5181 - val_acc: 0.8616 - val_f1_m: 0.8616 - val_precision_m: 0.8616 - val_recall_m: 0.8616\n",
            "Epoch 40/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0103 - acc: 0.9958 - f1_m: 0.9958 - precision_m: 0.9958 - recall_m: 0.9958 - val_loss: 0.5168 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 41/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0107 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5247 - val_acc: 0.8634 - val_f1_m: 0.8634 - val_precision_m: 0.8634 - val_recall_m: 0.8634\n",
            "Epoch 42/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0102 - acc: 0.9952 - f1_m: 0.9952 - precision_m: 0.9952 - recall_m: 0.9952 - val_loss: 0.5225 - val_acc: 0.8653 - val_f1_m: 0.8653 - val_precision_m: 0.8653 - val_recall_m: 0.8653\n",
            "Epoch 43/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0099 - acc: 0.9957 - f1_m: 0.9957 - precision_m: 0.9957 - recall_m: 0.9957 - val_loss: 0.5302 - val_acc: 0.8631 - val_f1_m: 0.8631 - val_precision_m: 0.8631 - val_recall_m: 0.8631\n",
            "Epoch 44/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0098 - acc: 0.9956 - f1_m: 0.9956 - precision_m: 0.9956 - recall_m: 0.9956 - val_loss: 0.5544 - val_acc: 0.8559 - val_f1_m: 0.8559 - val_precision_m: 0.8559 - val_recall_m: 0.8559\n",
            "Epoch 45/50\n",
            "12800/12800 [==============================] - 0s 19us/step - loss: 0.0101 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5392 - val_acc: 0.8612 - val_f1_m: 0.8612 - val_precision_m: 0.8612 - val_recall_m: 0.8612\n",
            "Epoch 46/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0101 - acc: 0.9954 - f1_m: 0.9954 - precision_m: 0.9954 - recall_m: 0.9954 - val_loss: 0.5389 - val_acc: 0.8641 - val_f1_m: 0.8641 - val_precision_m: 0.8641 - val_recall_m: 0.8641\n",
            "Epoch 47/50\n",
            "12800/12800 [==============================] - 0s 21us/step - loss: 0.0102 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9961 - recall_m: 0.9961 - val_loss: 0.5601 - val_acc: 0.8556 - val_f1_m: 0.8556 - val_precision_m: 0.8556 - val_recall_m: 0.8556\n",
            "Epoch 48/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0096 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9960 - recall_m: 0.9960 - val_loss: 0.5473 - val_acc: 0.8625 - val_f1_m: 0.8625 - val_precision_m: 0.8625 - val_recall_m: 0.8625\n",
            "Epoch 49/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0101 - acc: 0.9955 - f1_m: 0.9955 - precision_m: 0.9955 - recall_m: 0.9955 - val_loss: 0.5584 - val_acc: 0.8609 - val_f1_m: 0.8609 - val_precision_m: 0.8609 - val_recall_m: 0.8609\n",
            "Epoch 50/50\n",
            "12800/12800 [==============================] - 0s 20us/step - loss: 0.0100 - acc: 0.9953 - f1_m: 0.9953 - precision_m: 0.9953 - recall_m: 0.9953 - val_loss: 0.5686 - val_acc: 0.8606 - val_f1_m: 0.8606 - val_precision_m: 0.8606 - val_recall_m: 0.8606\n",
            "4001/4001 [==============================] - 1s 141us/step\n",
            "\n",
            "*** Finished! ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z7yKlp3aCa9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}